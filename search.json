[{"title":"本地虚拟机记录","path":"/2026/01/21/归档/本地虚拟机信息记录/","content":"Redis： MySQL： Centos# 重启樱花映射docker restart natfrp-service # 强制同步时间sudo systemctl restart chronyd parallels@10.211.55.15 zhang...1997 # Redis 日志位置redis.log /home/parallels/app/redis/log/redis.log mysql:账号：centos密码：centos redis:防火墙：关闭防火墙：sudo systemctl stop firewalld 永久关闭防火墙： sudo systemctl disable firewalld 防火墙状态：sudo firewall-cmd --state Jdk 1.8291 wget https://repo.huaweicloud.com/java/jdk/8u202-b08/jdk-8u202-linux-x64.tar.gz 292 mkdir -p /usr/java/293 tar -zxvf jdk-8u202-linux-x64.tar.gz -C /usr/java/294 vim /etc/profile295 source /etc/profile296 java -version linux01 ssh linux01@10.211.55.16 linux01 mysql、redis redis.log: /home/linux01/log 关闭防火墙：sudo ufw disable 永久关闭防火墙： sudo systemctl stop ufwsudo systemctl disable ufw mysql账号：linux01密码：linux01 15虚拟机Redis安装在CentOS上手动安装Redis的步骤如下： 安装依赖Redis是由C语言开发的，因此首先需要确保服务器已经安装了GCC编译器。可以通过以下命令查看机器是否安装了GCC：gcc -v如果没有安装，可以通过以下命令进行安装：sudo yum install -y gcc 下载并解压Redis安装包下载Redis安装包，可以选择直接通过浏览器下载，或者使用wget命令在终端中下载。以下是一个使用wget命令下载Redis安装包的示例：wget https://download.redis.io/releases/redis-6.2.6.tar.gz解压下载的文件：tar -zxvf redis-6.2.6.tar.gz 编译安装进入解压后的Redis目录：cd redis-6.2.6使用make命令进行编译：make编译完成后，使用make install命令进行安装，可以指定安装目录：make install PREFIX=/usr/local/redis 配置Redis将Redis的配置文件（redis.conf）复制到安装目录：cp /root/redis-6.2.6/redis.conf /usr/local/redis/bin/修改redis.conf配置文件以支持后台运行：vi /usr/local/redis/bin/redis.conf将daemonize的值从no修改为yes：daemonize yes 启动Redis服务前台启动进入Redis安装目录并启动服务：cd /usr/local/redis./redis-server后台启动创建Redis的工作目录：mkdir /usr/local/redis/log编辑配置文件，添加日志文件路径：vim /usr/local/redis/bin/redis.conf添加以下内容：logfile /usr/local/redis/log/redis.log启动Redis服务：./redis-server ./redis.conf 设置开机自启动创建systemd服务文件：vim /lib/systemd/system/redis.service添加以下内容： [Unit]Description=Redis ServerAfter=network.target[Service]Type=forkingExecStart=/usr/local/redis/bin/redis-server /usr/local/redis/bin/redis.confExecStop=/usr/local/redis/bin/redis-cli shutdownRestart=always[Install]WantedBy=multi-user.target 启动Redis服务并设置开机自启： systemctl start redissystemctl enable redis 验证安装通过Redis客户端连接并测试：.redis-cli使用ping命令测试连接：ping通过以上步骤，你可以在CentOS上成功手动安装并配置Redis。 MySQL安装1. 更新系统确保系统是最新的： sudo dnf update -y 2. 添加 MySQL 官方 DNF 仓库CentOS Stream 9 使用 dnf 作为包管理器，我们需要添加 MySQL 官方仓库： 下载适用于 EL9 的 MySQL Yum 仓库 RPM： sudo dnf install -y wgetwget https://dev.mysql.com/get/mysql80-community-release-el9-5.noarch.rpm 注意：这是截至 2025 年 2 月的最新版本。如果链接失效，请访问 MySQL 官方下载页面 获取最新 RPM。 安装 RPM： sudo rpm -Uvh mysql80-community-release-el9-5.noarch.rpm 更新 DNF 缓存： sudo dnf makecache 3. 安装 MySQL 8.0.41CentOS Stream 9 的默认仓库可能不直接提供 8.0.41，但 MySQL 官方仓库会有多个版本。检查可用版本： dnf --showduplicates list mysql-community-server 输出类似： mysql-community-server.x86_64 8.0.41-1.el9 mysql80-communitymysql-community-server.x86_64 8.0.40-1.el9 mysql80-community 如果 8.0.41 可用，安装指定版本： sudo dnf install -y mysql-community-server-8.0.41-1.el9 如果没有列出 8.0.41，默认安装最新版本： sudo dnf install -y mysql-community-server 4. 启动 MySQL 服务安装完成后，启动服务并设置开机自启： sudo systemctl start mysqldsudo systemctl enable mysqld 检查状态： sudo systemctl status mysqld 5. 获取临时密码MySQL 首次安装会生成一个临时 root 密码，查看日志： sudo grep temporary password /var/log/mysqld.log 记下密码（例如 abcd1234!xyz）。 – Lk(wE0fZxypJ0 修改密码级别 6. 配置 MySQL使用临时密码登录： mysql -u root -p 修改 root 密码： ALTER USER root@localhost IDENTIFIED BY 你的新密码;FLUSH PRIVILEGES;EXIT; 7. 验证安装检查版本： mysql -u root -p -e SELECT VERSION(); 输出应包含 8.0.41（或你安装的版本）。 如果 8.0.41 不可用：手动安装如果 MySQL 官方 EL9 仓库没有 8.0.41，可以手动下载 RPM 包： 访问 MySQL 官方档案。 选择 8.0.41，下载适用于 EL9 的包（例如 mysql-community-server-8.0.41-1.el9.x86_64.rpm）。 安装：sudo dnf install -y ./mysql-community-server-8.0.41-1.el9.x86_64.rpm 如果缺少依赖，运行：sudo dnf install -y -f 解决依赖问题CentOS Stream 9 不提供 OpenSSL 1.0.2（libcrypto.so.10 和 libssl.so.10），而 MySQL 8.0.41 的 EL7 包依赖这些库。如果你坚持使用 el7 包（不推荐），需要手动安装兼容性库，但这在 Stream 9 上非常复杂且不稳定。建议： 使用 EL9 版本的 MySQL 8.0.41（如上所述）。 或选择更新的 MySQL 版本（8.0.x 的最新版已适配 EL9 的 OpenSSL）。 开启远程连接（可选）如果需要远程访问： 编辑配置文件： sudo vim /etc/my.cnf.d/mysql-server.cnf 在 [mysqld] 下添加： bind-address = 0.0.0.0 配置用户权限： CREATE USER centos@% IDENTIFIED BY centos;GRANT ALL PRIVILEGES ON *.* TO centos@%;FLUSH PRIVILEGES; 重启服务： sudo systemctl restart mysqld 开放防火墙： sudo firewall-cmd --add-port=3306/tcp --permanentsudo firewall-cmd --reload 注意事项 CentOS Stream 9 是滚动更新的发行版，库版本较新，与 EL7 包不完全兼容。 如果仍想用 8.0.41 的 EL7 包，建议切换到 CentOS 7 系统。 遇到任何错误（例如依赖或启动失败），请提供具体输出，我会帮你解决。 现在你可以尝试安装了！需要进一步帮助吗？ mysql workbench# 更新系统sudo dnf update -y# 安装 EPELsudo dnf install -y epel-release# 安装 unixODBCsudo dnf install -y unixODBC# 安装 proj（如果 EPEL 提供合适的版本）sudo dnf install -y proj-libs proj-devel# 如果需要手动安装 proj-8.2.1wget https://dl.fedoraproject.org/pub/epel/9/Everything/x86_64/Packages/p/proj-8.2.1-1.el9.x86_64.rpmsudo dnf install -y ./proj-8.2.1-1.el9.x86_64.rpm# 安装 MySQL Workbenchsudo dnf install -y mysql-workbench-community-8.0.41-1.el9.x86_64.rpm 16、17虚拟机依赖： sudo apt-get install libhiredis-devsudo apt-get install liblua5.1-devsudo apt-get install libjemalloc-devsudo apt-get install gcc pkg-config MySQL安装在 Ubuntu 24.04 上安装 MySQL 数据库非常简单，我将为你提供逐步指导。以下是安装和基本配置的步骤： 1. 更新软件包列表首先，确保你的系统软件包列表是最新的。打开终端，运行以下命令： sudo apt update sudo apt upgrade -y 2. 安装 MySQL Server在 Ubuntu 24.04 上，MySQL 的默认版本通常可以通过包管理器安装。运行以下命令来安装 MySQL Server： sudo apt install mysql-server -y 安装完成后，MySQL 服务会自动启动。你可以通过以下命令检查它是否运行： sudo systemctl status mysql 如果显示 “active (running)”，说明服务已成功启动。 3. 运行安全配置脚本安装完成后，建议运行 MySQL 提供的安全配置脚本，以增强数据库的安全性： sudo mysql_secure_installation 系统会提示你设置 root 用户的密码（如果还未设置）。 接下来会询问是否移除匿名用户、禁止远程 root 登录、删除测试数据库等，建议根据需求选择（通常选 “Y” 以提高安全性）。 4. 登录 MySQL安装完成后，可以使用以下命令登录 MySQL： sudo mysql -u root -p 输入你在上一步设置的 root 密码。如果未设置密码，可以直接以 root 用户身份进入（视安装时的默认配置）。 5. （可选）设置 root 用户密码如果默认情况下 root 用户没有密码或你想更改密码，可以在 MySQL 命令行中运行： ALTER USER root@localhost IDENTIFIED WITH mysql_native_password BY 你的密码;FLUSH PRIVILEGES;EXIT; 将“你的密码”替换为你想要设置的密码。 6. 验证安装再次登录 MySQL 并运行以下命令，确认版本： mysql -u root -p 进入后： SHOW VARIABLES LIKE version; 这会显示当前安装的 MySQL 版本。 7. 基本管理命令 启动 MySQL 服务：sudo systemctl start mysql 停止 MySQL 服务：sudo systemctl stop mysql 重启 MySQL 服务：sudo systemctl restart mysql 默认安装位置：varlibmysql which mysql MySQL-- 查看当前密码策略SHOW VARIABLES LIKE validate_password%;-- 更改密码策略为低级别SET GLOBAL validate_password.policy = LOW;-- 或者，如果您想要完全禁用密码验证（不推荐），可以使用：-- SET GLOBAL validate_password.policy = OFF;-- 如果需要，还可以调整其他密码策略参数，例如：-- SET GLOBAL validate_password.length = 6; -- 设置最小密码长度 Redis注意事项 PIDFile 必须与 redis.conf 中的 pidfile 一致。 Typeforking 匹配 daemonize yes 设置。 Redis主从+哨兵在您的三台虚拟机（10.211.55.15 CentOS Stream 9，10.211.55.16 和 10.211.55.17 Ubuntu 24 LTS）上已经部署了 Redis，现在要配置 Redis 哨兵模式（Sentinel），这是一个非常好的高可用性方案。Redis 哨兵模式可以监控主从节点，并在主节点故障时自动切换到从节点。以下是详细的配置步骤： 前提假设 三台服务器都已经安装了 Redis（假设版本一致，比如 Redis 6.x 或 7.x）。 Redis 主节点（Master）部署在 10.211.55.15，从节点（Slave）部署在 10.211.55.16 和 10.211.55.17。 Sentinel 将在这三台服务器上都部署，以实现高可用监控。 如果您的部署计划不同（如主从分配不同），请告诉我，我会调整方案。 配置步骤1. 配置 Redis 主从复制首先需要设置一个主节点和两个从节点。 在主节点 (10.211.55.15) 上配置 Redis编辑 Redis 配置文件（通常在 /etc/redis.conf 或 /etc/redis/redis.conf，具体路径取决于安装方式）： # 确保绑定本地 IP（或 0.0.0.0 允许外部访问）bind 10.211.55.15# 设置端口（默认 6379，可自定义）port 6379# 可选：设置密码（增强安全性）requirepass yourpassword# 后台运行daemonize yes 启动 Redis： redis-server /etc/redis.conf 在从节点 (10.211.55.16 和 10.211.55.17) 上配置 Redis编辑从节点的 Redis 配置文件： # 绑定本地 IPbind 10.211.55.16 # 或 10.211.55.17# 设置端口port 6379# 设置为主节点的从节点replicaof 10.211.55.15 6379# 如果主节点设置了密码masterauth yourpassword# 后台运行daemonize yes 分别在两台从节点上启动 Redis： redis-server /etc/redis.conf 验证主从同步：在主节点上运行 redis-cli，输入： INFO REPLICATION 可以看到从节点信息。确保从节点已连接。 2. 配置 Redis SentinelRedis Sentinel 需要单独的配置文件，通常命名为 sentinel.conf，并在每台服务器上运行一个 Sentinel 实例。 创建 Sentinel 配置文件在每台服务器上创建一个 sentinel.conf 文件（例如放在 /etc/redis/sentinel.conf），内容如下： # Sentinel 监听端口（默认 26379）port 26379# 后台运行daemonize yes# 监控的主节点信息sentinel monitor mymaster 10.211.55.15 6379 2# 如果主节点有密码sentinel auth-pass mymaster yourpassword# 主节点宕机判断时间（单位：毫秒，默认 30000，即 30 秒）sentinel down-after-milliseconds mymaster 30000# 故障转移后并行同步从节点的数量sentinel parallel-syncs mymaster 1# 故障转移超时时间（单位：毫秒，默认 180000，即 3 分钟）sentinel failover-timeout mymaster 180000 说明： sentinel monitor mymaster 主节点IP 端口 法定人数：mymaster 是主节点的别名，2 表示至少 2 个 Sentinel 同意才能触发故障转移。 每台服务器的 sentinel.conf 配置相同。 启动 Sentinel在每台服务器上启动 Sentinel： redis-sentinel /etc/redis/sentinel.conf 启动后，Sentinel 会自动发现主节点和从节点，并开始监控。 3. 验证 Sentinel 工作状态在任意一台服务器上，使用 redis-cli 连接 Sentinel（默认端口 26379）： redis-cli -h 10.211.55.15 -p 26379 输入以下命令： SENTINEL masters 查看主节点状态。 SENTINEL slaves mymaster 查看从节点状态。 4. 测试故障转移 在主节点 (10.211.55.15) 上停止 Redis：redis-cli -h 10.211.55.15 shutdown 等待几秒后，检查 Sentinel 日志（通常在 sentinel.conf 指定的日志文件中）或重新运行 SENTINEL masters，确认主节点已切换到 10.211.55.16 或 10.211.55.17。 原主节点恢复后会自动变为从节点。 手动故障主节点 SENTINEL failover mymaster # mymaster 是主节点的名称 注意事项 防火墙配置： 确保主从节点的 6379 端口和 Sentinel 的 26379 端口在三台服务器之间互通。 CentOS Stream 9：firewall-cmd --add-port=6379/tcp --permanentfirewall-cmd --add-port=26379/tcp --permanentfirewall-cmd --reload Ubuntu 24 LTS：ufw allow 6379/tcpufw allow 26379/tcp 网络延迟： 由于是本地虚拟机，网络延迟应该很低，但如果在生产环境，需确保网络稳定。 版本一致性： 确保三台服务器的 Redis 和 Sentinel 版本一致，避免兼容性问题。 下一步如果您已经按照上述步骤配置完成，可以告诉我测试结果，或者如果有任何报错，我可以帮您排查。如果您想调整配置（比如更改主节点、端口等），也请随时告诉我！ MySQL主从同步 ShardingSphere好的，您决定使用 ShardingSphere 并基于 Java 的 Spring Boot 应用来实现读写分离，这是个很不错的选择。您的三台服务器（10.211.55.15 CentOS Stream 9，10.211.55.16 和 10.211.55.17 Ubuntu 24 LTS）已经部署了 MySQL 8.0.41，但尚未配置主从同步。我们需要先完成 MySQL 的主从同步配置，然后在 Spring Boot 中引入 ShardingSphere-JDBC 来实现读写分离。以下是详细步骤： 第一步：配置 MySQL 主从同步我们将 10.211.55.15 设置为主节点 (Master)，10.211.55.16 和 10.211.55.17 设置为从节点 (Slave)。 1. 配置主节点 (10.211.55.15)编辑 MySQL 配置文件： CentOS Stream 9 通常是 /etc/my.cnf： [mysqld]server-id = 1bind-address = 0.0.0.0 # 或 10.211.55.15，允许外部访问log_bin = mysql-bin # 启用二进制日志binlog_format = ROW # MySQL 8.0 默认推荐 ROW 格式 重启 MySQL： systemctl restart mysqldsystemctl status mysqld 创建复制用户： mysql -u root -pCREATE USER repl@10.211.55.% IDENTIFIED WITH mysql_native_password BY Repl@1234;GRANT REPLICATION SLAVE ON *.* TO repl@10.211.55.%;FLUSH PRIVILEGES;SHOW MASTER STATUS; 记录 File（如 mysql-bin.000001）和 Position（如 156）。 2. 配置从节点 (10.211.55.16)编辑 MySQL 配置文件（Ubuntu 通常是 /etc/mysql/my.cnf 或 /etc/mysql/mysql.conf.d/mysqld.cnf）： 16是：/etc/mysql/mysql.conf.d/mysqld.cnf [mysqld]server-id = 2bind-address = 0.0.0.0 # 或 10.211.55.16relay_log = mysql-relay-binread_only = 1 # 从节点只读 重启 MySQL： systemctl restart mysqlsystemctl status mysql 连接主节点： mysql -u root -pCHANGE REPLICATION SOURCE TO SOURCE_HOST = 10.211.55.15, SOURCE_USER = repl, SOURCE_PASSWORD = Repl@1234, SOURCE_LOG_FILE = mysql-bin.000001, SOURCE_LOG_POS = 156;`START REPLICA; SHOW REPLICA STATUS\\G` 确认 Replica_IO_Running 和 Replica_SQL_Running 均为 Yes。 3. 配置从节点 (10.211.55.17)与 10.211.55.16 类似，配置文件中设置： [mysqld]server-id = 3bind-address = 0.0.0.0relay_log = mysql-relay-binread_only = 1 重启并连接主节点（参数与 10.211.55.16 相同，只是 server-id 不同），然后检查同步状态。 4. 防火墙设置 CentOS：firewall-cmd --add-port=3306/tcp --permanentfirewall-cmd --reload Ubuntu：ufw allow 3306/tcpufw status 5. 测试主从同步在主节点创建测试数据： CREATE DATABASE test_db;USE test_db;CREATE TABLE users (id INT AUTO_INCREMENT PRIMARY KEY, name VARCHAR(50));INSERT INTO users (name) VALUES (Alice), (Bob); 在从节点检查： USE test_db;SELECT * FROM users; 若能看到数据，同步成功。 第二步：在 Spring Boot 中引入 ShardingSphere-JDBC1. 创建 Spring Boot 项目使用 Spring Initializr 创建项目，添加以下依赖： Spring Web Spring Data JPA MySQL Driver 2. 添加 ShardingSphere-JDBC 依赖编辑 pom.xml： dependencies !-- Spring Boot 基础依赖 -- dependency groupIdorg.springframework.boot/groupId artifactIdspring-boot-starter-web/artifactId /dependency dependency groupIdorg.springframework.boot/groupId artifactIdspring-boot-starter-data-jpa/artifactId /dependency dependency groupIdcom.mysql/groupId artifactIdmysql-connector-j/artifactId version8.0.33/version !-- 与 MySQL 8.0.41 兼容 -- /dependency !-- ShardingSphere-JDBC -- dependency groupIdorg.apache.shardingsphere/groupId artifactIdshardingsphere-jdbc-core-spring-boot-starter/artifactId version5.4.1/version !-- 截至 2025 年 3 月最新版本可能更高，检查官网 -- /dependency/dependencies 3. 配置 application.yml在 src/main/resources/application.yml 中添加： spring: shardingsphere: datasource: names: master, slave1, slave2 master: type: com.zaxxer.hikari.HikariDataSource driver-class-name: com.mysql.cj.jdbc.Driver jdbc-url: jdbc:mysql://10.211.55.15:3306/test_db?useSSL=falseserverTimezone=UTC username: root password: your_root_password slave1: type: com.zaxxer.hikari.HikariDataSource driver-class-name: com.mysql.cj.jdbc.Driver jdbc-url: jdbc:mysql://10.211.55.16:3306/test_db?useSSL=falseserverTimezone=UTC username: root password: your_root_password slave2: type: com.zaxxer.hikari.HikariDataSource driver-class-name: com.mysql.cj.jdbc.Driver jdbc-url: jdbc:mysql://10.211.55.17:3306/test_db?useSSL=falseserverTimezone=UTC username: root password: your_root_password rules: master-slave: master-data-source-name: master slave-data-source-names: slave1, slave2 load-balance-algorithm-type: ROUND_ROBIN # 读请求轮询分发 props: sql-show: true # 显示 SQL 日志，便于调试 jpa: hibernate: ddl-auto: update # 自动建表 show-sql: true 4. 创建实体类在 src/main/java/com/example/demo/entity 下创建 User.java： package com.example.demo.entity;import javax.persistence.Entity;import javax.persistence.GeneratedValue;import javax.persistence.GenerationType;import javax.persistence.Id;@Entitypublic class User @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; private String name; // Getters 和 Setters public Long getId() return id; public void setId(Long id) this.id = id; public String getName() return name; public void setName(String name) this.name = name; 5. 创建 Repository在 src/main/java/com/example/demo/repository 下创建 UserRepository.java： package com.example.demo.repository;import com.example.demo.entity.User;import org.springframework.data.jpa.repository.JpaRepository;public interface UserRepository extends JpaRepositoryUser, Long 6. 创建 Controller在 src/main/java/com/example/demo/controller 下创建 UserController.java： package com.example.demo.controller;import com.example.demo.entity.User;import com.example.demo.repository.UserRepository;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.*;import java.util.List;@RestController@RequestMapping(/users)public class UserController @Autowired private UserRepository userRepository; @PostMapping public User addUser(@RequestBody User user) return userRepository.save(user); // 写操作，走主库 @GetMapping public ListUser getUsers() return userRepository.findAll(); // 读操作，走从库 7. 运行应用启动 Spring Boot： mvn spring-boot:run 8. 测试读写分离 添加用户（写操作，走主库）：curl -X POST http://localhost:8080/users -H Content-Type:application/json -d name:Charlie 获取用户列表（读操作，走从库）：curl http://localhost:8080/users 观察日志，确认写操作发往 10.211.55.15，读操作分发到 10.211.55.16 或 10.211.55.17。 注意事项 密码替换：将 your_root_password 替换为实际的 MySQL root 密码。 数据库权限：确保 test_db 在从节点已同步，或者在主节点创建后等待同步完成。 依赖版本：ShardingSphere 版本可能更新，建议访问 官网 获取最新版。 日志调试：若读写分离未生效，检查日志输出，确保数据源正确加载。 下一步请按照上述步骤配置并测试。如果主从同步或 Spring Boot 集成过程中遇到问题（比如同步失败、连接错误），告诉我具体报错，我会帮您排查！完成后，您可以进一步优化负载均衡策略或添加更多功能。有什么具体需求吗？"},{"title":"需要掌握以下知识","path":"/2026/01/21/归档/需要掌握以下知识/","content":"导入数据 匹配规则3.生成报告和数据 作为一名三年经验的 Java 开发人员，你需要掌握以下知识： Java 基础知识：掌握 Java 的基本语法、面向对象编程、常用数据结构和算法等，能够熟练使用 Java 语言进行开发。 Java Web 开发框架：熟悉 Spring、SpringMVC 和 MyBatis 等主流的 Java Web 开发框架，能够使用这些框架进行 Web 应用程序的开发。 数据库知识：熟悉关系型数据库和 NoSQL 数据库的使用，掌握 SQL 语言和数据库设计的基本知识。 Web 前端技术：熟悉 HTML、CSS、JavaScript、jQuery 等前端开发技术，能够与前端开发人员协同工作，完成 Web 应用程序的前后端分离开发。 网络编程知识：熟悉 TCPIP 协议、HTTP 协议等网络编程相关的知识，能够使用 Java 进行网络编程开发。 分布式系统开发：了解分布式系统的基本概念和原理，熟悉 Spring Cloud、Dubbo 等分布式系统开发框架，能够进行分布式系统的设计和开发。 微服务架构：了解微服务架构的基本概念和原理，熟悉 Spring Boot、Spring Cloud 等微服务开发框架，能够进行微服务的设计和开发。 工具和技术：掌握 Maven、Git、Jenkins 等常用的工具和技术，能够进行代码管理、构建和部署。 技术栈扩展：根据自身的兴趣和职业发展需求，了解其他的 Java 技术栈，例如大数据处理、人工智能、区块链等，不断扩展自己的技术领域。 除了以上技术知识，你还需要具备良好的团队协作能力、学习能力和解决问题的能力，能够快速适应不同的项目需求和开发环境，不断提升自己的技术水平和职业素养。","tags":["学习"]},{"title":"Transactional注解","path":"/2026/01/21/归档/事务问题/","content":"方法A中调用B后再调用C,三个方法中均有插入数据后再查询数据 B方法的注解：@Transactional(propagationPropagation.REQUIRES_NEW) –不管是否存在事务,都创建一个新的事务,原来的挂起,新的执行完毕,继续执行老的事务 C方法的注解：@Transactional(propagationPropagation.REQUIRED) –如果有事务,那么加入事务,没有的话新建一个 1、当方法B或者C报错时，A、B、C方法都回滚 2、当方法A、B、C异常被捕获时，A、B、C事务不回滚（a、b、c均入库） 3、当方法BC执行后，方法A报错时，A、C事务回滚，B事务不回滚（b数据入库） A方法向表中添加数据a，在查询该表能得到数据a B方法向表中添加数据b，再查询该表能得到数据b C方法向表中添加数据c，再查询该表能得到数据a，b，c 带有注解@Transactional(propagationPropagation.REQUIRES_NEW)的方法走完之后，数据就会被提交入库 另外需要注意方法内部调用@Transactional(propagationPropagation.REQUIRES_NEW)注解不生效，比如A和B都在同一个方法中，A调用B，B方法是此注解，则不生效。同样，AOP拦截也拦截不到B public enum Propagation REQUIRED(0), SUPPORTS(1), MANDATORY(2), REQUIRES_NEW(3), NOT_SUPPORTED(4), NEVER(5), NESTED(6); private final int value; private Propagation(int value) this.value = value; public int value() return this.value; 七种事物传播类型 默认为：REQUIRED","categories":["数据库"]},{"title":"Sql小技巧","path":"/2026/01/21/归档/分页查询/","content":"MySQL 并不是跳过 offset 行，而是取 offset+N 行，然后返回放弃前 offset 行，返回 N 行。 # 反例（耗时129.570s）select * from task_result LIMIT 20000000, 10;# 正例（耗时5.114s）SELECT a.* FROM task_result a, (select id from task_result LIMIT 20000000, 10) b where a.id = b.id;# 说明task_result表为生产环境的一个表，总数据量为3400万，id为主键，偏移量达到2000万 获取一条数据时的Limit 1在很多情况下我们已知数据仅存在一条，此时我们应该告知数据库只用查一条，否则将会转化为全表扫描 # 反例（耗时2424.612s）select * from task_result where unique_key = ebbf420b65d95573db7669f21fa3be3e_861414030800727_48;# 正例（耗时1.036s）select * from task_result where unique_key = ebbf420b65d95573db7669f21fa3be3e_861414030800727_48 LIMIT 1;# 说明task_result表为生产环境的一个表，总数据量为3400万，where条件非索引字段，数据所在行为第19486条记录 批量插入# 反例INSERT into person(name,age) values(A,24)INSERT into person(name,age) values(B,24)INSERT into person(name,age) values(C,24)# 正例INSERT into person(name,age) values(A,24),(B,24),(C,24);# 说明比较常规，就不多做说明了 https://juejin.im/post/5ea16dede51d45470b4ffc5b?utm_source=gold_browser_extension","tags":["mysql"],"categories":["数据库"]},{"title":"单例模式","path":"/2026/01/21/归档/单例模式/","content":"1. 最简单的单例模式：package com.example.demo.JUC.thread;/** * @author huapeng.zhang * @version 1.0 * @date 2020/9/17 18:28 */public class SingletomDemo private static SingletomDemo singletomDemo = null; private SingletomDemo() System.out.println(Thread.currentThread().getName() + \\t 我是构造方法SingletomDemo()！); public static SingletomDemo getInstance() if (singletomDemo == null) singletomDemo = new SingletomDemo(); return singletomDemo; public static void main(String[] args) // 单线程 System.out.println(SingletomDemo.getInstance() == SingletomDemo.getInstance()); System.out.println(SingletomDemo.getInstance() == SingletomDemo.getInstance()); System.out.println(SingletomDemo.getInstance() == SingletomDemo.getInstance()); 在单线程的情况下，打印结果如下： 可以看到，虽然我们一共调用了六次getInstance()， 但是只打印了一次构造方法输出内容，也就是只调用了一个构造函数，所获得的对象地址自然是一样的。 2. 多线程下的单例模式我们对main()方法做一下改造，改造后的代码如下： public static void main(String[] args) // 改为多线程后 可能多次调用构造函数 for (int i = 0; i 10; i++) new Thread(() - SingletomDemo.getInstance(); , String.valueOf(i)).start(); 打印结果为： 多次执行下可以看到打印的次数是不同的。 可以对getInstance()方法添加synchronized加锁，保证只生成一个实例。 private static synchronized SingletomDemo getInstance() if (singletomDemo == null) singletomDemo = new SingletomDemo(); return singletomDemo; 再次执行程序发现只打印了一次构造方法输出函数，还有另外一种方法就是DCL：double check locks双端检测模式模式也可以达到同样的目的。 3.DCL + 单例模式我们再次对getInstance()方法进行改造，代码如下： // DCL模式(double check locks双端检测模式)private static SingletomDemo getInstance() if (singletomDemo == null) synchronized (SingletomDemo.class) if (singletomDemo == null) singletomDemo = new SingletomDemo(); return singletomDemo; 当我们的单例模式写到这种程度的时候，基本可以应对99%的情况，但是由于指令排序的存在，还是有可能会出现问题。 memory = allocate(); //1.分配对象内存空间instance(memory); //2.初始化对象instance = memory; //3.设置instance指向刚分配的内存地址，此时instance!=null 步骤2、3不存在数据依赖，所以由于指令重排的关系，可能会出现： memory = allocate(); //1.分配对象内存空间instance = memory; //3.设置instance指向刚分配的内存地址，此时instance!=nullinstance(memory); //2.初始化对象 4.Volatile + 单例模式我们在声明 singletomDemo时，加上Volatile关键字修饰，就可以达到完美的效果。 最终代码： package com.example.demo.JUC.thread;/** * @author huapeng.zhang * @version 1.0 * @date 2020/9/17 18:28 */public class SingletomDemo private static volatile SingletomDemo singletomDemo = null; private SingletomDemo() System.out.println(Thread.currentThread().getName() + \\t 我是构造方法SingletomDemo()！); // DCL模式(double check locks双端检测模式) private static SingletomDemo getInstance() if (singletomDemo == null) synchronized (SingletomDemo.class) if (singletomDemo == null) singletomDemo = new SingletomDemo(); return singletomDemo; public static void main(String[] args) // 单线程// System.out.println(SingletomDemo.getInstance() == SingletomDemo.getInstance());// System.out.println(SingletomDemo.getInstance() == SingletomDemo.getInstance());// System.out.println(SingletomDemo.getInstance() == SingletomDemo.getInstance());// 改为多线程后 可能多次调用构造函数// 可以在 getInstance上加SYNC解决问题 for (int i = 0; i 10; i++) new Thread(() - SingletomDemo.getInstance(); , String.valueOf(i)).start();","tags":["demo"],"categories":["学习笔记"]},{"title":"反射","path":"/2026/01/21/归档/反射获取父类字段/","content":"Class? superclass = itfBaseBO.getClass();while (!superclass.getName().equals(ExpandDomain.class.getName())) superclass = superclass.getSuperclass();","tags":["demo"],"categories":["学习笔记"]},{"title":"卡米救砖","path":"/2026/01/21/归档/卡米救砖记录/","content":"TWRP 清空data时，不会清空datamedia分区 清空data能解决大部分问题，所以不用操心download twrp打开mtp 可以移动文件 adb也可以 fastboot 关于卡刷后导致的卡重启、打开应用无响应、掉帧频繁，等等一切的疑难杂症，请尝试→→进入Rec-高级-文件管理删除以下4项文件夹（文件）来解决①↴↴/data/dalvik-cache/②↴↴/data/system/package cache/③↴↴/data/system/locksettings.db④↴↴/data/system/locksettings.db-jourmal- - - - - - - -由于卡刷后会累积一些用以上方法都无法清除掉的BUG，每每卡刷都会累积更多，还是建议全清后用线刷方式，前提要备份好无冲突的数据！————————注：↴↴❶若要替换系统软件，先卸掉已刷入的模块重启后即可（无刷入模块除外）- - - - - - - -❷若遇到设置锁屏密码卡住、安装失败-999的问题，自行登录谷歌账号 或者电脑上用adb工具箱执行一下以下命令就行了，fastboot状态下执行fastboot erase frp"},{"title":"MySQL查询","path":"/2026/01/21/归档/同步不同服务的MySQL数据表/","content":"1. 首先要保证本地的MySQL服务支持FEDERATED引擎。输入：SHOW ENGINES;如下 FEDERATED 行的Support为YES则表示开启了FEDERATED。如果为 NO 则表示未开启。如果 FEDERATED 没有开启的话 要启用。 2.启用 FEDERATED在MySQL的配置文件安装目录下的my.ini或my.cnf 加上 一行 `FEDERATED` 3.建表建表一般应的是InnoDB引擎，这里需要修改一下 改为 ENGINE=FEDERATED 从原表导出表结构SQL，然后修改 ENGINE = InnoDB-ENGINE=FEDERATED CONNECTION=mysql://用户名:密码@IP:PORT/库名/表名 然后打开这张表，可以看到远程表里的数据已经同步到了这张表。","tags":["utils"],"categories":["数据库"]},{"title":"开发日志","path":"/2026/01/21/归档/开发日志/","content":"备份部分代码MainActivity.java 实用源生安卓来处理模糊，但是还是慢 package com.li.ying; import android.graphics.Bitmap; import android.graphics.BitmapFactory; import android.os.Bundle; import androidx.annotation.NonNull; import androidx.annotation.Nullable; import io.flutter.embedding.android.FlutterActivity; import io.flutter.embedding.engine.FlutterEngine; import io.flutter.plugin.common.MethodCall; import io.flutter.plugin.common.MethodChannel; import android.renderscript.*; import java.io.File; import java.io.FileOutputStream; import java.io.IOException; public class MainActivity extends FlutterActivity private static final String CHANNEL = image_processing; @Override public void configureFlutterEngine(@NonNull FlutterEngine flutterEngine) super.configureFlutterEngine(flutterEngine); new MethodChannel(flutterEngine.getDartExecutor().getBinaryMessenger(), CHANNEL) .setMethodCallHandler( (call, result) - if (call.method.equals(blurImage)) String imagePath = call.argument(imagePath); int radius = call.argument(radius); try result.success(blurImage(imagePath, radius)); catch (IOException e) throw new RuntimeException(e); else result.notImplemented(); ); private String blurImage(String imagePath, int radius) throws IOException Bitmap bitmap = BitmapFactory.decodeFile(imagePath); RenderScript rs = RenderScript.create(this); Allocation input = Allocation.createFromBitmap(rs, bitmap); Allocation output = Allocation.createTyped(rs, input.getType()); ScriptIntrinsicBlur script = ScriptIntrinsicBlur.create(rs, Element.U8_4(rs)); // 多次应用高斯模糊 for (int i = 0; i 5; i++) script.setRadius(radius); script.setInput(input); script.forEach(output); output.copyTo(bitmap); input.copyFrom(bitmap); rs.destroy(); File outputDir = getCacheDir(); File outputFile = File.createTempFile(blurred_, .png, outputDir); FileOutputStream out = new FileOutputStream(outputFile); bitmap.compress(Bitmap.CompressFormat.PNG, 100, out); out.close(); return outputFile.getAbsolutePath(); main.dart调用源生安卓 // static const platform = MethodChannel(image_processing); // // 这种方法 调用了安卓原生代码 速度更快 但是快不过缩小图片模糊 // 并且radius最大25 模糊效果不尽人意 // File? _blurredImage; // // Futurevoid _blurImage(String imagePath) async // try // final String blurredImagePath = await platform.invokeMethod( // blurImage, // imagePath: imagePath, radius: 25, // ); // setState(() // _blurredImage = File(blurredImagePath); // ); // on PlatformException catch (e) // print(Failed to blur image: $e.message.); // //"},{"path":"/2026/01/21/归档/Redis大Key/","content":"日常业务运行过程中，Redis 实例经常因各种 Big keys Hot Keys 的问题未及时处理，导致服务性能下降、访问超时、用户体验变差，甚至可能造成实例大范围故障 。 这篇文章，我们聊聊生产环境，如何应对 Redis 大 Key 问题。 1 什么是大 key大 Key 具体表现为 Redis 中的 Key 对应的 Value 很大，占用 Redis 空间比较大，本质上是大 Value 问题。 对于 Redis 中不同的数据结构类型，常见示例如下所示： 对于 String 类型的 Value 值，值超过 10MB（数据值太大）。 对于 Set 类型的 Value 值，含有的成员数量为 10000 个（成员数量多）。 对于 List 类型的 Value 值，含有的成员数量为 10000 个（成员数量多）。 对于 Hash 格式的 Value 值，含有的成员数量 1000 个，但所有成员变量的总 Value 值大小为 1000 MB（成员总的体积过大）。 在 Redis 的实际应用中，大 Key 问题的定义和评判标准并非固定不变，而是需要结合具体业务场景和性能需求进行综合考量。 例如，在高并发、低延迟的敏感场景下，即使 10 KB 的数据也可能被视为大 Key；而在低并发、高吞吐量的离线处理环境中，大 Key 的阈值可能放宽至 100 KB 甚至更高。 因此，在 Redis 的设计和使用过程中，应该基于业务特性和性能指标来制定合理的大 Key 评估标准。 2 大 key 有什么影响Redis 是单线程执行命令 ，当前面的任务完成不了，那后面的命令就会阻塞，从而导致如下的结果： 1、请求响应时间上升，超时阻塞。 Redis 是单线程架构，操作大 Key 耗时较长，可能造成请求阻塞。 2、同步中断或主从切换 内存不足时，对大 Key 进行驱逐操作或者 rename 一个大 Key，容易长时间阻塞主库，进而可能引发同步中断或主从切换。 3、网络拥塞 一个大 Key 占用空间是 1MB，每秒访问1000 次，就有1000 MB 的流量，可能造成实例或局域网的带宽被占满，自身服务变慢，同时影响其他服务。 4、内存使用不均匀 在 Redis 集群架构中，某个数据分片的内存使用率远超其他数据分片，内存资源无法达到均衡。另外，Redis 内存可能达到 maxmemory 参数定义的上限，导致重要的 Key 被逐出，甚至引发内存溢出。 需要强调的是： 对于 Java 应用来讲，高并发场景 大 Key 问题容易导致应用服务器 CPU Load 内存占用飙高。 如图，这个一个非常标准的通过 redisTemplate 查询用户缓存信息的方法。 但当用户 DTO 对象占用内存大小达到 300k ~ 500k 时，并发高情况下，海量 UserDTO 对象会在新生代产生，对象序列化 和 GC 线程会大量占用 CPU 资源，导致 CPU Load 飙高 ，最终应用线程大面积阻塞。 3 大 key 是如何产生的1、错误的技术选型 比如使用 String 类型的 Key 存放大体积二进制文件型数据，从而造成 key 对应的 value 值特别大 ； 2、List 、Set 数据类型数据未清理 如图，我们经常使用 Redis List 作为消息队列，在实际使用中经常出现如下问题：生产者发送消息过快，但消费者消费消息速度低，导致数据堆积占用大量内存空间 。 3、数据没有合理做分片 业务上线前，对业务分析不准确，没有对 Key 中的成员进行合理的拆分，造成个别 Key 中的成员数量过多。 4 如何找到大 key01 bigkeys 命令执行 redis-cli 命令时带上–bigkeys 选项，对整个数据库中的键值对大小情况进行统计分析，统计每种数据类型的键值对个数以及平均大小。 此外，这个命令执行后，会输出每种数据类型中最大的 bigkey 的信息： 对于 String 类型来说，会输出最大 bigkey 的字节长度 对于集合类型来说，会输出最大 bigkey 的元素个数 bigkeys 是通过扫描数据库来查找的，在执行的过程中，会对 Redis 实例的性能产生影响。 主从集群，建议在从节点上执行该命令，避免阻塞主节点。 没有从节点情况下，在 Redis 实例业务压力的低峰阶段进行扫描查询，以免影响到实例的正常运行。 02 监控平台公有云或者公司内部架构部门一般都有监控平台，可以可视化分析 Redis 服务监控指标。 如下图是阿里云的 Redis 监控大 Key 分析界面 。 假如是架构部门自己的监控平台，可以添加 Redis 的 Key 监控统计。 下图是UMP 监控平台的设计思路： 流程如下： 1、业务系统引入通 UMP SDK ，当业务系统运行时，SDK 会将日志文件（JVM、TP 、HeatBeat）写到磁盘 ； 2、FileBeat 读取日志文件，发送到 Kafka ； 3、UMP 计算服务 从 Kafka 中获取消息，根据消息类型，执行分析逻辑（JVM、TP 、HeatBeat ）； 4、计算完成之后，指标结果数据存储到 Hbase，MySQL 用于存储元数据，Redis 用于存储临时计算数据 ； 5、研发人员登录控制台查看监控信息 ，核心的监控数据存储在 Hbase 中，通过 HighChart 组件渲染。 UMP 可以对应用端的 Redis 操作实现全面的监控，包括命令超时、Key大小、使用频率等关键指标。 5 如何解决大 key 问题1、清理无效的数据 主要针对 list 和 set 这种类型，在使用的过程中，list 和 set 中对应的内容不断增加，需要定时的对 list 和 set 进行清理。 2、压缩对应的大 Key 的 Value 通过序列化或者压缩的方法对 value 进行压缩，使其变为较小的 value，但是如果压缩之后如果对应的 value 还是特别大的话，就需要使用拆分的方法进行解决。 3、针对大 Key 进行拆分 通过将 BigKey 拆分成多个小 Key 的键值对，并且拆分后的对应的 value 大小和拆分成的成员数量比较合理，然后进行存储即可，在获取的时候通过 get 不同的 key 或是用 mget 批量获取存储的键值对。 4、实时监控 Redis 内存、带宽及 Key 增长变化趋势 通过监控系统，监控 Redis 中的内存占用大小和网络带宽的占用大小，以及固定时间内的内存占用增长率，当超过设定的阈值的时候，进行报警通知处理。"},{"title":"Spring Boot Admin","path":"/2026/01/21/归档/Spring Boot Admin/","content":"服务端配置新建一个SpringBoot项目 pom.xml !--如果不需要鉴权 可以不加Security依赖--dependency groupIdorg.springframework.boot/groupId artifactIdspring-boot-starter-web/artifactId /dependency dependency groupIdde.codecentric/groupId artifactIdspring-boot-admin-starter-server/artifactId /dependencydependency groupIdorg.springframework.boot/groupId artifactIdspring-boot-starter-security/artifactId /dependency application.properties # 端口server.port=20000 server.servlet.context-path=/admin 启动类加上 @EnableAdminServer注解 如果不需要鉴权 到这里就结束了，运行项目，然后访问localhost:20000/admin就可以看到SBA的UI 非必须项 引入Security，开启认证登录，下面是一个简单的样例 @Configuration(proxyBeanMethods = false) public class SecuritySecureConfig extends WebSecurityConfigurerAdapter private final AdminServerProperties adminServer; public SecuritySecureConfig(AdminServerProperties adminServer) this.adminServer = adminServer; @Override protected void configure(HttpSecurity http) throws Exception SavedRequestAwareAuthenticationSuccessHandler successHandler = new SavedRequestAwareAuthenticationSuccessHandler(); successHandler.setTargetUrlParameter(redirectTo); successHandler.setDefaultTargetUrl(this.adminServer.path(/)); http.authorizeRequests() .antMatchers(this.adminServer.path(/assets/**)).permitAll() .antMatchers(this.adminServer.path(/login)).permitAll() .anyRequest().authenticated() .and() .formLogin().loginPage(this.adminServer.path(/login)).successHandler(successHandler).and() .logout().logoutUrl(this.adminServer.path(/logout)).and() .httpBasic().and() .csrf() .csrfTokenRepository(CookieCsrfTokenRepository.withHttpOnlyFalse()) .ignoringRequestMatchers( new AntPathRequestMatcher(this.adminServer.path(/instances), HttpMethod.POST.toString()), new AntPathRequestMatcher(this.adminServer.path(/instances/*), HttpMethod.DELETE.toString()), new AntPathRequestMatcher(this.adminServer.path(/actuator/**)) ) .and() .rememberMe().key(UUID.randomUUID().toString()).tokenValiditySeconds(1209600); @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception auth.inMemoryAuthentication().withUser(user).password(nooppasswd).roles(USER); 运行项目，然后访问localhost:20000/admin需要登录","tags":["日常记录"],"categories":["java"]},{"title":"Springboot","path":"/2026/01/21/归档/Springboot返回html/","content":"Springboot返回html 注：Springboot的版本2.1.3.RELEASE List-1 application.properties文件 server.port=8080#url中，项目的前缀server.servlet.context-path=/projectspring.mvc.view.prefix=/spring.mvc.view.suffix=.html 整体结构如下图1所示，html要放在static下，不是templates下 图１ List-2 HelloController的内容如下 import lombok.extern.slf4j.Slf4j;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;@Slf4j@Controllerpublic class HelloController @RequestMapping(value = /hello) public String index() log.info(收到请求); return html/hello; List-3 启动springboot，之后在浏览器中输入 #返回index.html的内容http://localhost:8080/project/#返回hello.html的内容http://localhost:8080/project/hello 网上很多关于模板的（Thymeleaf 、FreeMarker 等），但是我不需要，我只需要纯的html。 index.html是springboot的默认welcome page。 Reference https://www.jianshu.com/p/eb4c0fc2dfc4 https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#boot-features-spring-mvc-static-content https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#boot-features-spring-mvc-welcome-page ​ (adsbygoogle window.adsbygoogle || []).push({});","tags":["基础"]},{"title":"StringToInteger","path":"/2026/01/21/归档/StringToInteger/","content":"String 转 Integer1.Integer的parseInt方法String string = 123;int value = Integer.parseInt(string);System.out.println(stringToInt----------+value);结果：StringToInt----------123 2.Integer的valueOf方法String string = 123;Integer value = Integer.valueOf(string);System.out.println(stringToInt1----------+value);结果：StringToInt1----------123 以上两种方法都是可行的。 但是会有特殊的情况，比如： String string = abc;int value = Integer.parseInt(string);System.out.println(stringToInt----------+value);结果：Exception in thread main java.lang.NumberFormatException: For input string: abc\tat java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)\tat java.lang.Integer.parseInt(Integer.java:580)\tat java.lang.Integer.parseInt(Integer.java:615)\tat com.hand.todo.infra.util.StringToInt.stringToInt(StringToInt.java:16)\tat com.hand.todo.infra.util.StringToInt.main(StringToInt.java:10) 使用stringToInt1()也会返回同样的错误。 public static Integer valueOf(String s) throws NumberFormatException return Integer.valueOf(parseInt(s, 10)); valueOf()调用了parseInt()，所以返回同样的错误是正常的。 按照正常的逻辑来说，我们需要对这个错误进行处理，比如： String string = abc;int value = 0;try value = Integer.parseInt(string); catch (NumberFormatException e) e.printStackTrace();System.out.println(StringToInt----------+value);结果：java.lang.NumberFormatException: For input string: abc\tat java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)\tat java.lang.Integer.parseInt(Integer.java:580)\tat java.lang.Integer.parseInt(Integer.java:615)\tat com.hand.todo.infra.util.StringToInt.stringToInt(StringToInt.java:18)\tat com.hand.todo.infra.util.StringToInt.main(StringToInt.java:10)StringToInt----------0 可以看到，虽然依然报错，但是程序还是继续执行了。 然后回到主题。 3.Guava 的 Ints 结合 Java8 的 OptionalString string = abc;Integer value = Optional.ofNullable(string) .map(Ints::tryParse) .orElse(0); System.out.println(StringToInt2---------- + value); 结果：StringToInt2----------0 可以在转换失败的时候为他设置默认值： String string = abc;Integer value = Optional.ofNullable(string) .map(Ints::tryParse) .orElse(100); System.out.println(StringToInt2---------- + value); 结果：StringToInt2----------100 写在末尾：之所以写这么详细是因为最开始的时候我很菜，看别人写的文档都很简单，虽然可以解决问题，但是却不解其意，所以写的啰嗦一点，对新手比较友好。 ​","categories":["java"]},{"title":"Ubuntu","path":"/2026/01/21/归档/Ubuntu/","content":"NETDATA1. 安装编译环境sudo apt install zlib1g-dev gcc make git autoconf autogen automake pkg-config uuid-dev 2. 克隆项目git clone https://github.com/firehol/netdata.git --depth=1 3. 安装netdatahttps://www.cnblogs.com/beile/p/12875395.html官方：https://learn.netdata.cloud/docs/agent/packaging/installer/methods/offline./netdata-installer.sh 然后访问 IP:19999 NGINX1. 安装Nginxsudo suapt-get install nginx如果是Centos 浏览器地址栏输入 IP看到如下页面表示已经安装好了Nginx，如果有域名，输入域名也是同样的效果（前提是已经给域名添加了解析） 2.Nginx 转发端口我已经在服务器上安装了netdata服务，端口为19999,但是通过Nginx访问服务器时默认是80端口，所以需要做一些配置，在我们输入域名的时候访问不同的端口。 # nginx.conf里包含\tinclude /etc/nginx/conf.d/*.conf; 所以可以在/etc/nginx/conf.d 文件夹下新增一个配置文件server listen 80; server_name IP; location / client_max_body_size 3000m; proxy_next_upstream http_502 http_504 error timeout invalid_header; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Real-PORT $remote_port; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:19999; proxy_redirect default; proxy_connect_timeout 3000; 这样 当我们在浏览器地址栏输入 域名时 就会自动跳转到netdata的主页 3. 反向代理+负载均衡 # 实际服务upstream web_servers server 192.168.139.128:9001;\tserver 192.168.139.128:9002;server # 代理端口\tlisten 10086;\tserver_name 192.168.139.128;\tlocation / proxy_pass http://web_servers; proxy_set_header Host $host:$server_port;\t# 可以部署两个服务 9001、9002 发布时，等上一个成功发布后，启动第二个。# 未验证# 加上systemclt管理Java服务# 负载均衡的方式：https://mp.weixin.qq.com/s/yJyEwPkLD0V9G0451gbZYg# 1.轮询；2.权重；3.ip_hash；4.fair；5.url_hash 时区- https://blog.csdn.net/weixin_44109450/article/details/124259338 - Githubsudo vim /etc/hosts 140.82.112.4 github.com 199.232.69.194 github.global.ssl.fastly.net 内网穿透1. https://doc.natfrp.com/#/frpc/service/systemd2. Item2https://zhuanlan.zhihu.com/p/550022490 青龙# 进入青龙容器docker exec -it qinglong bash 使用systemctl管理服务https://www.jianshu.com/p/2deb0b79cb10# 路径/etc/systemd/system# 日志journalctl -u 服务名 Arthashttps://arthas.aliyun.com/doc/quick-start.html#_2-%E5%90%AF%E5%8A%A8-arthas[arthas@588425]$ watch net.lab1024.smartadmin.module.business.project.service.ProjectBaiscService queryProjects returnObjPress Q or Ctrl+C to abort.Affect(class count: 2 , method count: 2) cost in 170 ms, listenerId: 1method=net.lab1024.smartadmin.module.business.project.service.ProjectBaiscService.queryProjects location=AtExitts=2022-11-28 20:11:49; [cost=37.212667ms] result=@ResponseDTO[ code=@Integer[1], msg=@String[操作成功!], success=@Boolean[true], data=@ArrayList[isEmpty=false;size=13],]method=net.lab1024.smartadmin.module.business.project.service.ProjectBaiscService$$EnhancerBySpringCGLIB$$2f00139f.queryProjects location=AtExitts=2022-11-28 20:11:49; [cost=94.21994ms] result=@ResponseDTO[ code=@Integer[1], msg=@String[操作成功!], success=@Boolean[true], data=@ArrayList[isEmpty=false;size=13],] Prometheus# prometheuswget https://github.com/prometheus/prometheus/releases/download/v2.40.4/prometheus-2.40.4.linux-amd64.tar.gztar -zxvf prometheus-2.40.4.linux-amd64.tar.gzsudo mv prometheus-2.40.4.linux-amd64 /usr/local/prometheusvim /usr/lib/systemd/system/prometheus.service[Unit]Description=prometheusAfter=network.target [Service]User=prometheusGroup=prometheusWorkingDirectory=/usr/local/prometheusExecStart=/usr/local/prometheus/prometheus[Install]WantedBy=multi-user.target# 启动并开启自启systemctl daemon-reloadsystemctl enable --now prometheus cd ~/gitee_go/deoloylstar -zxf output.tar.gzcd targetpid=`ps -ef|grep xxx|grep -v grep|awk print $2`if [ $pid ]then kill -15 $pid finohup java -jar xxx.jar --server.port=8090 # Ubuntu sh脚本不支持for循环 这里会报错for((i=1;i=10;i++));do new_pid=`ps -ef|grep xxx|grep -v grep|awk print $2` if [ ! $new_pid ] then echo starting...... sleep 10 else echo Deploy Success break; fidone echo alias python=/usr/bin/python3 ~/.bash_profile","tags":["系统集成"]},{"path":"/2026/01/21/归档/WIKI/","content":"Media2Doc安装部署 安装依赖 pip install arkitect --index-url https://pypi.org/simplepip install -r requirements.txt 可能出现的问题： arkitect 版本报错 ERROR: Could not find a version that satisfies the requirement arkitect==0.2.3 (from versions: 0.0.1, 0.1.0.dev0, 0.1.1, 0.1.2, 0.1.3, 0.1.4, 0.1.5, 0.1.6, 0.1.7, 0.1.8, 0.1.9, 0.1.10, 0.1.11)ERROR: No matching distribution found for arkitect==0.2.3 需要升级Python，使用Python3.11可以正常安装依赖"},{"title":"WHEN YOU HAVE A NEW PC","path":"/2026/01/21/归档/WHEN YOU HAVE A NEW PC/","content":"WHEN YOU HAVE A NEW PCJava环境配置1. 安装​\t提前新建两个文件夹，jdk，jre，默认路径也可以 ​\t安装jdk-8u111-windows-x64.exe ​\t设置jdk、jre的路径 2. 配置环境变量​\t右键此电脑 - 属性 - 高级系统设置 - 环境变量 - 系统变量(S) ​\t只有系统变量才是全局的。 新建\tCLASSPATH\t.;新建\tJAVA_HOME\tjdk路径修改\tpath 添加 %JAVA_HOME%\\bin;测试\tjava -version javac -version Maven环境配置 解压apache-maven-3.3.9.rar 到指定的目录。 修改配置文件（压缩包已修改过）。 GIT 工具1. 配置用户信息# 用户级git config --global user.name fairygit config --global user.email fairy@gmail.com# 仓库级 local可以省略git config --local user.name 张华朋26190git config --local user.email huapeng.zhang@going-link.com# 使配置不生效git config --global --unset user.name 2. 生成SSH密钥ssh-keygen -t rsa -C email //Email可选，会在key中生成你的邮箱信息 一直回车就行 ​\t生成的key文件 C:\\Users\\你的用户名\\.ssh\\id_rsa.pub ​\t用文本编辑器打开，复制到GIT上。 3. 上传项目到GITcd 项目文件加夹git initgit remote add origin git@github.com:fairyeye/StudyJava.gitgit add .git commit -m Initial commitgit push -u origin master MySQL 安装安装https://www.runoob.com/mysql/mysql-install.html 修改初始密码 MySQL版本5.7.6版本以前用户可以使用如下命令： mysql SET PASSWORD = PASSWORD(your pwd); MySQL版本5.7.6版本开始的用户可以使用如下命令： mysql ALTER USER USER() IDENTIFIED BY your pwd; 登录报错 https://www.cnblogs.com/lifan1998/p/9177731.html 去图标​\t管理员运行 去图标.bat 文件。 谷歌访问助手​\t谷歌浏览器 - 更多工具 - 扩展程序 - 开发者模式(打开) 。 ​\t拖动 谷歌访问助手.crx 到谷歌浏览器中。 软件安装清单 IDEA： Chrome： uTools： Typora： Another Redis Desktop Manager：很好看的Redis客户端 XShell：好看 好用 tabby-terminal：https://github.com/Eugeny/tabby/releases/tag/v1.0.164 Shadowsocks：小飞机 Windows Termial:Windows终端 nvm: Windows切换node版本 n：Mac切换node版本 https://github.com/tj/n npm install -g n pyenv：切换python版本 Invoke-WebRequest -UseBasicParsing -Uri “https://raw.githubusercontent.com/pyenv-win/pyenv-win/master/pyenv-win/install-pyenv-win.ps1“ -OutFile “.install-pyenv-win.ps1”; ”.install-pyenv-win.ps1” Redis图形化页面： Tiny RDM 以下是如何在Linux或macOS上创建和使用虚拟环境的步骤： 打开终端。 使用python3 -m venv path/to/venv命令创建一个新的虚拟环境，其中path/to/venv是你想要创建虚拟环境的目录。例如，你可以在家目录下创建一个名为myenv的虚拟环境，使用命令python3 -m venv ~/myenv。 激活虚拟环境。在Linux或macOS上，你可以使用以下命令激活虚拟环境： 复制 source ~/myenv/bin/activate 激活后，你的命令行提示符会改变，通常前面会加上虚拟环境的名字，比如(myenv)。 在虚拟环境中，你可以使用pip安装、升级或删除包，而不会影响到系统级别的Python环境。例如，你可以使用以下命令安装一个包： 复制 pip install package-name 当你完成工作后，你可以通过运行deactivate命令来停用虚拟环境。 请注意，如果你的系统上没有安装python3，或者你的Python版本不同，你可能需要根据你的实际情况调整上述命令。如果你使用的是Windows系统，步骤会有所不同，通常你会使用path\\to\\venv\\Scripts\\activate来激活虚拟环境 Mac终端：oh my zshhttps://zhuanlan.zhihu.com/p/550022490https://blog.csdn.net/weixin_42326144/article/details/121957795 TomCat@9 # tomcat9 /usr/local/Cellar/tomcat@9/9.0.102/libexec IDEA在 IntelliJ IDEA 中，要确保项目中的中文字符以 UTF-8 编码保存，可以按照以下步骤操作：1. **打开项目设置**：在 IntelliJ IDEA 中，点击菜单栏中的 File - Settings（或者直接使用快捷键 `Ctrl + Alt + S`）来打开项目设置。 2. **设置文件编码**：在设置窗口左侧的搜索框中输入 File Encoding，然后选择 File Encodings 选项。 3. **更改默认编码**：在右侧的界面中，找到 Global Encoding 下的 IDE Encoding，将其设置为 UTF-8。同样，也可以设置 Project Encoding 和 Default encoding for properties files 为 UTF-8。 4. **应用更改并重新加载项目**：点击 OK 按钮以应用更改，并可能需要重新加载项目以确保更改生效。 5. **保存文件为 UTF-8 编码**：对于现有的文件，可以通过以下方式将其保存为 UTF-8 编码： - 打开文件。 - 点击菜单栏中的 File - Save with Encoding...。 - 在弹出的对话框中，选择 UTF-8 编码，然后点击 OK 保存文件。通过以上步骤，您可以确保在 IntelliJ IDEA 中创建和编辑的所有文件都以 UTF-8 编码保存，包括中文字符。","categories":["杂谈"]},{"title":"security","path":"/2026/01/21/归档/security/","content":"1.引入依赖： dependency groupIdorg.springframework.boot/groupId artifactIdspring-boot-starter-security/artifactId /dependency dependency groupIdorg.springframework.boot/groupId artifactIdspring-boot-starter-web/artifactId /dependency 一些必要的配置： 新建一个配置类 WebSecurityConfig继承WebSecurityConfigurerAdapter重写configure方法。（重要） 是SpringSecurity的核心 @Configuration public class WebSecurityConfig extends WebSecurityConfigurerAdapter @Override protected void configure(HttpSecurity http) throws Exception // 开启登录 http.formLogin(); 新建一个controller用来测试登录 /** * @author zhanghuapeng * @date 2024/1/28 */@RestController public class UserController /** * 获取当前登录用户信息 */ @GetMapping(/user-info) public Authentication getUserInfo(Authentication authentication) return authentication; 启动项目：终端会有这么一段日志 Using generated security password: f429b724-db54-4a56-ae82-7ebb63f22d69 表示：没有设置用户信息，给出了一个默认用户及密码，默认用户user 登录之后，默认会跳转到Index页面，但是目前没有这个页面，所以会报错。暂不处理。 访问：http://localhost:8080/user-info返回结果： credentials:null,details:null,authenticated:false,authorities:null,principal:null,name:not login! 可以通过http://localhost:8080/logount退出登录 之后在访问user-info接口，发现不在包含用户信息 2.实际使用中 没有登录的用户是不能访问接口的 修改WebSecurityConfig @Configuration public class WebSecurityConfig extends WebSecurityConfigurerAdapter @Override protected void configure(HttpSecurity http) throws Exception // 开启登录 http.formLogin(); // 设置访问权限 任何请求均需要认证（登录成功）才能访问 http.authorizeRequests().anyRequest().authenticated(); 重启项目此时，访问：http://localhost:8080/user-info发现会直接跳转到登录页面 增加一些细节依赖dependencies !-- Web -- dependency groupIdorg.springframework.boot/groupId artifactIdspring-boot-starter-web/artifactId exclusions exclusion groupIdorg.springframework.boot/groupId artifactIdspring-boot-starter-tomcat/artifactId /exclusion /exclusions /dependency !-- Undertow -- dependency groupIdorg.springframework.boot/groupId artifactIdspring-boot-starter-undertow/artifactId /dependency !-- Security -- dependency groupIdorg.springframework.boot/groupId artifactIdspring-boot-starter-security/artifactId /dependency !-- Test -- dependency groupIdorg.springframework.boot/groupId artifactIdspring-boot-starter-test/artifactId scopetest/scope /dependency !--lombok-- dependency groupIdorg.projectlombok/groupId artifactIdlombok/artifactId scopeprovided/scope /dependency !--mybatis-- dependency groupIdmysql/groupId artifactIdmysql-connector-java/artifactId scoperuntime/scope /dependency dependency groupIdorg.mybatis.spring.boot/groupId artifactIdmybatis-spring-boot-starter/artifactId version2.2.2/version /dependency !-- 添加jwt的依赖 -- dependency groupIdcom.auth0/groupId artifactIdjava-jwt/artifactId version3.11.0/version /dependency !--Redis-- dependency groupIdorg.springframework.boot/groupId artifactIdspring-boot-starter-data-redis/artifactId /dependency/dependencies 配置server: port: 8080 spring: output: ansi: enabled: always # 强制启用 ansi 输出 datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://127.0.0.1:3306/security_study?useUnicode=truecharacterEncoding=UTF-8serverTimezone=Asia/Shanghai username: root password: 12345678 redis: host: 127.0.0.1 port: 6379 database: 1 jwt: secretKey: a3e4cd2d191a017bf49dbdf49a4c62b1fb292c5b112d6a51bdc4e2ea5052e816 expiration: 3600 logging: pattern: # 控制台日志格式 console: %clr(%dyyyy-MM-dd HH:mm:ss.SSS)faint %clr(%5p) %clr($PID:- )magenta %clr(%-40.40logger39)cyan : %msg%n mybatis: type-aliases-package: com.li.entity configuration: map-underscore-to-camel-case: true log-impl: org.apache.ibatis.logging.stdout.StdOutImpl mapper-locations: classpath:mapper/*.xml 在com.li新建utils包，新建JwtUtils @Component @Slf4j public class JwtUtils //算法密钥 @Value($jwt.secretKey) private String jwtSecretKey; // 过期时间 @Value($jwt.expiration) private long expiration; /** * 创建jwt * @param userInfo 用户信息 * @param authList 用户权限列表 * @return 返回jwt（JSON WEB TOKEN） */ public String createToken(String userInfo, ListString authList) //创建时间 Date currentTime = new Date(); //过期时间，5分钟后过期 Date expireTime = new Date(currentTime.getTime() + expiration); //jwt 的header信息 MapString, Object headerClaims = new HashMap(); headerClaims.put(type, JWT); headerClaims.put(alg, HS256); //创建jwt return JWT.create() .withHeader(headerClaims) // 头部 .withIssuedAt(currentTime) //已注册声明：签发日期，发行日期 .withExpiresAt(expireTime) //已注册声明 过期时间 .withIssuer(thomas) //已注册声明，签发人 .withClaim(userInfo, userInfo) //私有声明，可以自己定义 .withClaim(authList, authList) //私有声明，可以自定义 .sign(Algorithm.HMAC256(jwtSecretKey)); // 签名，使用HS256算法签名，并使用密钥 // HS256是一种对称算法，这意味着只有一个密钥，在双方之间共享。 使用相同的密钥生成签名并对其进行验证。 应特别注意钥匙是否保密。 /** * 验证jwt的签名，简称验签 * * @param token 需要验签的jwt * @return 验签结果 */ public boolean verifyToken(String token) //获取验签类对象 JWTVerifier jwtVerifier = JWT.require(Algorithm.HMAC256(jwtSecretKey)).build(); try //验签，如果不报错，则说明jwt是合法的，而且也没有过期 DecodedJWT decodedJWT = jwtVerifier.verify(token); return true; catch (JWTVerificationException e) //如果报错说明jwt 为非法的，或者已过期（已过期也属于非法的） log.error(验签失败：, token); return false; /** * 获取用户id * * @param token jwt * @return 用户id */ public String getUserInfo(String token) //创建jwt验签对象 JWTVerifier jwtVerifier = JWT.require(Algorithm.HMAC256(jwtSecretKey)).build(); try //验签 DecodedJWT decodedJWT = jwtVerifier.verify(token); //获取payload中userInfo的值，并返回 return decodedJWT.getClaim(userInfo).asString(); catch (JWTVerificationException e) log.error(getUserInfo error, e); return null; /** * 获取用户权限 * * @param token * @return */ public ListString getUserAuth(String token) //创建jwt验签对象 JWTVerifier jwtVerifier = JWT.require(Algorithm.HMAC256(jwtSecretKey)).build(); try //验签 DecodedJWT decodedJWT = jwtVerifier.verify(token); //获取payload中的自定义数据authList（权限列表），并返回 return decodedJWT.getClaim(authList).asList(String.class); catch (JWTVerificationException e) log.error(getUserAuth error, e); return null; 在com.li新建filter包，新建SaySomethingJWTFilter /** * @author zhanghuapeng * @date 2024/2/22 * @desc 一次性请求过滤器 */ @Component public class SaySomethingJWTFilter extends OncePerRequestFilter @Resource private ObjectMapper objectMapper; @Resource private StringRedisTemplate stringRedisTemplate; @Resource private JwtUtils jwtUtils; @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException //获取请求uri String requestURI = request.getRequestURI(); // 如果是登录页面，放行 if (requestURI.equals(/login)) filterChain.doFilter(request, response); return; //获取请求头中的Authorization String authorization = request.getHeader(Authorization); //如果Authorization为空，那么不允许用户访问，直接返回 if (!StringUtils.hasText(authorization)) printFront(response, 没有登录！); return; //Authorization 去掉头部的Bearer 信息，获取token值 String jwtToken = authorization.replace(Bearer , ); //验签 boolean verifyTokenResult = jwtUtils.verifyToken(jwtToken); //验签不成功 if (!verifyTokenResult) printFront(response, jwtToken 已过期); return; //从payload中获取userInfo String userInfo = jwtUtils.getUserInfo(jwtToken); //从payload中获取授权列表 ListString userAuth = jwtUtils.getUserAuth(jwtToken); //创建登录用户 SysUser sysUser = objectMapper.readValue(userInfo, SysUser.class); SecurityUser securityUser = new SecurityUser(sysUser); //设置权限 ListSimpleGrantedAuthority authList = userAuth.stream().map(SimpleGrantedAuthority::new).collect(Collectors.toList()); securityUser.setAuthorities(authList); UsernamePasswordAuthenticationToken usernamePasswordAuthenticationToke = new UsernamePasswordAuthenticationToken(securityUser , null, authList); //通过安全上下文设置认证信息 SecurityContextHolder.getContext().setAuthentication(usernamePasswordAuthenticationToke); //继续访问相应的rul等 filterChain.doFilter(request, response); private void printFront(HttpServletResponse response, String message) throws IOException response.setCharacterEncoding(UTF-8); response.setContentType(application/json;charset=utf-8); PrintWriter writer = response.getWriter(); HttpResult httpResult = new HttpResult(); httpResult.setCode(-1); httpResult.setMsg(message); writer.print(objectMapper.writeValueAsString(httpResult)); writer.flush(); 调整SecurityConfig,将过滤器添加到配置中 @Resource private SaySTokenFilter saySTokenFilter;@Override protected void configure(HttpSecurity http) throws Exception // 增加配置 http.addFilterBefore(saySomethingJWTFilter, UsernamePasswordAuthenticationFilter.class); // ...原来的配置 调试# 不携带token访问http://localhost:8080/user-info返回：code:-1,msg:没有登录！,data:null# 携带错误token访问http://localhost:8080/user-info返回：code:-1,msg:jwtToken 已过期,data:null 在com.li.config,新建SaySAuthenticationSuccessHandler 设置权限在loadUserByUsername中获取权限，并设置到SecurityUser中 // com.li.service.impl.UserServiceImplSecurityUser securityUser = new SecurityUser(sysUser); // 获取权限信息 ListString authList = sysMenuDao.queryPermissionByUserId(sysUser.getUserId()); if (!CollectionUtils.isEmpty(authList)) ListSimpleGrantedAuthority authorities = authList.stream().map(SimpleGrantedAuthority::new).collect(toList()); // 设置权限 securityUser.setAuthorities(authorities); return securityUser; 在SaySAuthenticationSuccessHandler.onAuthenticationSuccess中，生成Token时，可以将权限信息一起放入Token中。 ListString authList = new ArrayList(); // 获取权限 ListSimpleGrantedAuthority authorities = (ListSimpleGrantedAuthority) securityUser.getAuthorities(); if (!CollectionUtils.isEmpty(authorities)) // 转成String 用于生成Token authList = authorities.stream().map(SimpleGrantedAuthority::getAuthority).collect(Collectors.toList()); // 创建Token 增加authList参数String token = saySJwtUtils.createToken(userInfo, authList); 注销处理Jwt本质上是一个字符串，无法手动将其过期，也就是说，即使手动退出登录，对于Token来说，还是一个有效的Token，可以通过接入Redis来解决这一问题 登录成功时，将Token写入Redis // SaySAuthenticationSuccessHandler// 设置过期时间 @Value($jwt.expiration) private long expiration;// 引入StringRedisTemplate@Resource private StringRedisTemplate stringRedisTemplate;// 在创建Token之后，将Token存到Redis中onAuthenticationSuccess()// 创建Token String token = saySJwtUtils.createToken(userInfo, authList);// 写入Redis stringRedisTemplate.opsForValue().set(login_token: + token, objectMapper.writeValueAsString(authentication), expiration, TimeUnit.MILLISECONDS); 校验Token时，先验签，再去Redis中判断Token是否还存在 如果验签成功，但是Redis中不存在，说明Token被手动过期了 doFilterInternal()...// 从Redis获取token并校验 String tokenInRedis = stringRedisTemplate.opsForValue().get(login_token: + jwtToken); if (!StringUtils.hasText(tokenInRedis)) printFront(response, 用户已退出，请重新登录); return; ... 在com.li.config，新建SaysLogoutSuccessHandler /** * 退出成功处理器，用户退出成功后，执行此处理器 */ @Component public class SaysLogoutSuccessHandler implements LogoutSuccessHandler //使用此工具类的对象进行序列化操作 @Resource private ObjectMapper objectMapper; @Resource private StringRedisTemplate stringRedisTemplate; @Override public void onLogoutSuccess(HttpServletRequest request, HttpServletResponse response, Authentication authentication) throws IOException, ServletException //从请求头中获取Authorization信息 String authorization = request.getHeader(Authorization); //如果授权信息为空，返回前端 if (null == authorization) response.setCharacterEncoding(UTF-8); response.setContentType(application/json;charset=utf-8); HttpResult httpResult = HttpResult.builder().code(-1).msg(token不能为空).build(); PrintWriter writer = response.getWriter(); writer.write(objectMapper.writeValueAsString(httpResult)); writer.flush(); return; //如果Authorization信息不为空，去掉头部的Bearer字符串 String token = authorization.replace(Bearer , ); //redis中删除token，这是关键点 stringRedisTemplate.delete(login_token: + token); response.setCharacterEncoding(UTF-8); response.setContentType(application/json;charset=utf-8); HttpResult httpResult = HttpResult.builder().code(200).msg(退出成功).build(); PrintWriter writer = response.getWriter(); writer.write(objectMapper.writeValueAsString(httpResult)); writer.flush(); 调整SecurityConfig @Resource private SaysLogoutSuccessHandler saysLogoutSuccessHandler;configure()http.logout().logoutSuccessHandler(saysLogoutSuccessHandler);// 禁用跨域请求保护 要不然logout不能访问(目前体现是弹出了确认退出登录的确认框 http.csrf().disable(); org.springframework.security.authentication.dao.AbstractUserDetailsAuthenticationProvider#authenticateorg.springframework.security.authentication.dao.DaoAuthenticationProvider#retrieveUser org.springframework.security.authentication.dao.DaoAuthenticationProvider#additionalAuthenticationChecks"},{"title":"GitHub Page","path":"/2026/01/21/归档/GitHub Page/","content":"## 拉取子模块git submodule init // 初始化子模块git submodule update // 更新子模块与主仓库中的子模块代码同步","tags":["hexo"]},{"title":"List stream","path":"/2026/01/21/归档/Java 8 Stream/","content":"通过workOrederNum字段排序 ListProduceOrderDTO collect = list.stream().sorted(Comparator.comparing(ProduceOrderDTO::getWorkOrderNum)).collect(Collectors.toList()); 查出InstructionPoDTO中InstructionDocNum作为list // 筛选出不重复的 instructionDocNumListString instructionDocNums = read.stream().map(InstructionPoDTO::getInstructionDocNum).distinct().collect(Collectors.toList()); 筛选所有instructionDocNum = 123的对象 ListInstructionPoDTO instructionPoDTOS = read.stream().filter(instructionPoDTO - instructionPoDTO.getInstructionDocNum().equals(123)).collect(Collectors.toList()); 查询出第一个 String instructionDocId = instructionDocs.stream().findFirst().get(); 设置typeCode为key，list的对象为value MapString, MtGenType typesMap = types.stream().collect(Collectors.toMap(t - t.getTypeCode(), t - t)); 通过字段去重 instructionSapStockDTOS.stream().collect(Collectors.collectingAndThen(Collectors.toCollection(()- new TreeSet(Comparator.comparing(o - o.getMaterial()+;+o.getPlant()+;+o.getStorage()+;+o.getBatch()+;+o.getSpecialStock()))), ArrayList::new)); GROUP BY MapString, ListWmsIqcRecord map = records.stream().collect(Collectors.groupingBy(iqcRecord - if (StringUtils.equals(TO_DO, iqcRecord.getStatus())) switch (iqcRecord.getDealMethod()) case RELEASE: return TO_RELEASE; case FREEZE: return TO_FREEZE; case RETURN: return TO_RETURN; default: return TO_DO; else if (StringUtils.equals(DONE, iqcRecord.getStatus())) switch (iqcRecord.getDealMethod()) case RELEASE: return RELEASE_DONE; case FREEZE: return FREEZE_DONE; case RETURN: return RETURN_DONE; default: return DONE; else return DEAL; )); // ListLocalDate collect = localDates.stream().sorted((var1, var2) - // if (var1.isBefore(var2)) // return -1;// // return 1;// ).collect(Collectors.toList());// System.out.println(localDates.stream().sorted().collect(Collectors.toList()));","tags":["Java"]},{"title":"hy2.0","path":"/2026/01/21/归档/HY2.0/","content":"id: file-fe-WvEu6lBm7ZXNURS1wwgZwZ5n,object: file,bytes: 53409,created_at: 1739612338,filename: 1，招标文件审查-建造师执业范围2024-8-3.xlsx,purpose: file-extract,status: processed id: file-fe-VUFvRDmAlHHsSmiea1PTSo7F,object: file,bytes: 18695,created_at: 1739614282,filename: 1，招标文件审查-施工总承包序列资质标准最终2024-8-3.xlsx,purpose: file-extract,status: processed id: file-fe-3iPw2e1wP03HQiEDWooGWNQW,object: file,bytes: 4305676,created_at: 1739612549,filename: 徽州区富溪乡水毁桥梁及护岸修复工程.pdf,purpose: file-extract,status: processed word 分段落替换 https://deepoove.com/poi-tl/Flask Python 服务器部署1. 准备服务器首先，你需要一个可以运行 Python 的服务器。你可以使用以下服务： 云服务提供商：如 AWS、阿里云、DigitalOcean 等。 VPS 提供商：如 Linode、Vultr 等。 确保服务器上安装了 Python 和 pip。 2. 连接到服务器使用 SSH 连接到你的服务器： ssh username@your_server_ip 3. 安装依赖在服务器上，确保你已经安装了 Python 和 pip。你可以使用以下命令检查： python3 --version pip3 --version 如果没有安装，可以使用以下命令安装： sudo apt update sudo apt install python3 python3-pip 4. 上传代码将你的 Flask 应用代码上传到服务器。可以使用 SCP、FTP 或 Git 来上传文件。下面是使用 SCP 的示例： scp -r /path/to/your/project username@your_server_ip:/path/to/target/directory 5. 创建虚拟环境在你的项目目录中创建一个虚拟环境： cd /path/to/target/directory python3 -m venv venv source venv/bin/activate 6. 安装项目依赖在虚拟环境中安装你的项目依赖： pip install -r requirements.txt 7. 运行 Flask 应用在开发环境中，你可以使用以下命令运行 Flask 应用： python app.py 但是在生产环境中，最好使用 WSGI 服务器（如 Gunicorn）来运行 Flask 应用： pip install gunicorn gunicorn -w 4 app:app --bind 0.0.0.0:5000 这里 -w 4 表示使用 4 个工作进程，你可以根据需要调整。 8. 配置反向代理（可选）为了在 80 或 443 端口上提供服务，建议使用 Nginx 作为反向代理： 安装 Nginxsudo apt install nginx 配置 Nginx创建一个新的 Nginx 配置文件，例如 /etc/nginx/sites-available/my_flask_app： nginx 复制代码 server { listen 80; server_name your_server_ip; # 或者你的域名 location / { proxy_pass http://127.0.0.1:5000; # Flask 应用的地址 proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; } } 创建符号链接到 sites-enabled： sudo ln -s /etc/nginx/sites-available/my_flask_app /etc/nginx/sites-enabled 测试 Nginx 配置并重启服务： sudo nginx -t sudo systemctl restart nginx 9. 配置防火墙（可选）确保服务器的防火墙允许 HTTP 和 HTTPS 流量： sudo ufw allow Nginx Full 10. 访问你的应用现在，你应该能够通过浏览器访问你的 Flask 应用，使用服务器的 IP 地址或域名。 额外建议 使用 HTTPS：在生产环境中，强烈建议使用 HTTPS。可以使用 Let’s Encrypt 来免费申请 SSL 证书。 监控和日志：考虑使用工具来监控应用的性能和日志，以便及时发现问题。 python好的，这里是一个详细的Python方案，包括登录页面、选择文件夹、处理PDF文件并将数据存储到SQLite数据库，以及在线更新功能。 1. 环境配置和库安装pip install PyInstaller PyUpdater PyPDF2 pdfminer.six pymupdf tkinter requests 2. 登录页面和主程序逻辑2.1. 创建登录界面创建一个文件 login.py 用于实现登录界面： import tkinter as tkfrom tkinter import messageboximport requestsclass LoginApp: def __init__(self, root): self.root = root self.root.title(登录) self.root.geometry(300x150) self.username_label = tk.Label(root, text=用户名) self.username_label.pack() self.username_entry = tk.Entry(root) self.username_entry.pack() self.password_label = tk.Label(root, text=密码) self.password_label.pack() self.password_entry = tk.Entry(root, show=*) self.password_entry.pack() self.login_button = tk.Button(root, text=登录, command=self.login) self.login_button.pack() def login(self): username = self.username_entry.get() password = self.password_entry.get() # 假设存在一个登录接口 login_url = http://example.com/api/login response = requests.post(login_url, json=username: username, password: password) if response.status_code == 200 and response.json().get(status) == success: messagebox.showinfo(成功, 登录成功) self.root.destroy() import main main.run_app() else: messagebox.showerror(错误, 用户名或密码错误)def run_login_app(): root = tk.Tk() app = LoginApp(root) root.mainloop() 2.2. 主程序逻辑创建 main.py 实现主程序逻辑： import osimport fitz # PyMuPDFimport sqlite3import tkinter as tkfrom tkinter import filedialog, messageboxdef select_folder(): folder_path = filedialog.askdirectory(title=选择包含PDF文件的文件夹) return folder_pathdef extract_text_from_pdf(pdf_path): doc = fitz.open(pdf_path) text = for page in doc: text += page.get_text() return textdef store_data_to_db(data): conn = sqlite3.connect(extracted_data.db) cursor = conn.cursor() cursor.execute(CREATE TABLE IF NOT EXISTS pdf_data (id INTEGER PRIMARY KEY, file_name TEXT, content TEXT)) cursor.execute(INSERT INTO pdf_data (file_name, content) VALUES (?, ?), data) conn.commit() conn.close()def process_pdfs(folder_path): for file_name in os.listdir(folder_path): if file_name.endswith(.pdf): pdf_path = os.path.join(folder_path, file_name) text = extract_text_from_pdf(pdf_path) store_data_to_db((file_name, text)) messagebox.showinfo(处理完成, f文件 file_name 处理完成)def run_app(): root = tk.Tk() root.withdraw() folder_path = select_folder() if folder_path: process_pdfs(folder_path) else: messagebox.showinfo(提示, 没有选择文件夹)if __name__ == __main__: run_login_app() 2.3. 在线更新功能创建 client_config.py 配置PyUpdater： import osfrom pyupdater.client import ClientAPP_NAME = PDFExtractorAppAPP_VERSION = 0.1.0UPDATE_URLS = [http://your-update-server.com/]class ClientConfig: PUBLIC_KEY = your-public-key APP_NAME = APP_NAME COMPANY_NAME = YourCompany UPDATE_URLS = UPDATE_URLS MAX_DOWNLOAD_RETRIES = 3 USE_PATCHES = Truedef check_for_updates(): client = Client(ClientConfig(), refresh=True) app_update = client.update_check(ClientConfig.APP_NAME, ClientConfig.APP_VERSION) if app_update is not None: app_update.download() if app_update.is_downloaded(): app_update.extract_restart() 在 main.py 的 run_app 函数中加入更新检查： def run_app(): from client_config import check_for_updates check_for_updates() root = tk.Tk() root.withdraw() folder_path = select_folder() if folder_path: process_pdfs(folder_path) else: messagebox.showinfo(提示, 没有选择文件夹) 2.4. 打包应用程序创建一个 spec 文件来配置打包设置（your_script.spec）： # your_script.spec# -*- mode: python ; coding: utf-8 -*-block_cipher = Nonea = Analysis([main.py], pathex=[], binaries=[], datas=[], hiddenimports=[], hookspath=[], runtime_hooks=[], excludes=[], win_no_prefer_redirects=False, win_private_assemblies=False, cipher=block_cipher, noarchive=False)pyz = PYZ(a.pure, a.zipped_data, cipher=block_cipher)exe = EXE(pyz, a.scripts, [], exclude_binaries=True, name=PDFExtractorApp, debug=False, bootloader_ignore_signals=False, strip=False, upx=True, upx_exclude=[], runtime_tmpdir=None, console=False)coll = COLLECT(exe, a.binaries, a.zipfiles, a.datas, strip=False, upx=True, upx_exclude=[], name=PDFExtractorApp) 然后使用 pyinstaller 打包： pyinstaller your_script.spec 3. 配置和初始化PyUpdaterpyupdater initpyupdater pkg --processpyupdater pkg --signpyupdater pkg --uploadpyupdater keys --createpyupdater settings 4. 部署和测试将生成的可执行文件和更新配置上传到你的服务器。然后运行打包好的应用程序，确保登录功能、PDF处理功能和在线更新功能都正常工作。 这样，你就有了一个带有登录功能的Windows应用程序，可以选择文件夹中的PDF文件进行处理，并支持在线更新。 要读取多个Excel文件并两两判断它们之间是否存在高度重复的数据，可以按以下步骤进行： 读取所有Excel文件。 提取并整理数据。 比较每对Excel文件的数据。 计算重复率。 输出比较结果。 可以使用 pandas 库来处理Excel文件，利用 pandas 的 DataFrame 结构进行数据比较和重复率计算。 1. 安装必要的库首先，确保你已经安装了 pandas 和 openpyxl 库： bash 复制代码 pip install pandas openpyxl 2. 读取所有Excel文件使用 pandas 读取Excel文件，并提取数据。 python 复制代码 import os import pandas as pd def read_excel_files(folder_path): excel_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(.xlsx)] dataframes = {f: pd.read_excel(f) for f in excel_files} return dataframes folder_path = your_folder_with_excel_files dataframes = read_excel_files(folder_path) 3. 比较每对Excel文件的数据定义一个函数来比较两个DataFrame，计算重复率。 python 复制代码 def calculate_similarity(df1, df2): # 确保两者都有相同的列 common_columns = df1.columns.intersection(df2.columns) if len(common_columns) == 0: return 0.0 # 选择共同的列进行比较 df1_common = df1[common_columns] df2_common = df2[common_columns] # 合并两个数据集，保留重复项 combined = pd.concat([df1_common, df2_common]) duplicates = combined.duplicated(keep=False) # 计算重复率 similarity = duplicates.sum() / len(combined) return similarity def compare_excel_files(dataframes): results = [] files = list(dataframes.keys()) for i in range(len(files)): for j in range(i + 1, len(files)): df1 = dataframes[files[i]] df2 = dataframes[files[j]] similarity = calculate_similarity(df1, df2) results.append((files[i], files[j], similarity)) return results similarity_results = compare_excel_files(dataframes) 4. 输出比较结果将比较结果输出，显示每对Excel文件的相似度。 python 复制代码 for file1, file2, similarity in similarity_results: print(f文件 {file1} 和文件 {file2} 的相似度为: {similarity:.2%}) 完整代码python 复制代码 import os import pandas as pd def read_excel_files(folder_path): excel_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(.xlsx)] dataframes = {f: pd.read_excel(f) for f in excel_files} return dataframes def calculate_similarity(df1, df2): common_columns = df1.columns.intersection(df2.columns) if len(common_columns) == 0: return 0.0 df1_common = df1[common_columns] df2_common = df2[common_columns] combined = pd.concat([df1_common, df2_common]) duplicates = combined.duplicated(keep=False) similarity = duplicates.sum() / len(combined) return similarity def compare_excel_files(dataframes): results = [] files = list(dataframes.keys()) for i in range(len(files)): for j in range(i + 1, len(files)): df1 = dataframes[files[i]] df2 = dataframes[files[j]] similarity = calculate_similarity(df1, df2) results.append((files[i], files[j], similarity)) return results folder_path = your_folder_with_excel_files dataframes = read_excel_files(folder_path) similarity_results = compare_excel_files(dataframes) for file1, file2, similarity in similarity_results: print(f文件 {file1} 和文件 {file2} 的相似度为: {similarity:.2%}) 注意事项 列对齐：确保所有比较的数据具有相同的列。 数据清理：在实际使用中，可能需要对数据进行清理和预处理，以确保比较的准确性。 优化：对于大型数据集，计算重复率可能会很耗时。可以考虑优化算法或使用更高效的数据结构。 通过这些步骤，你可以实现读取多个Excel文件并两两判断是否有高度重复的数据，并计算和输出相似度。 审查复杂规则1. 方案每次执行规则，查数据或者把全部数据缓存每次进行匹配，不太友好。 项目启动时，查询范围和资质表，然后处理成对象存到缓存： 一级建造师-工业、民用与公共建筑工程: builderName: 一级建造师, projectName: 工业、民用与公共建筑工程, workType: 一般房屋建筑工程, uom: 金额,// 后面看是不是换成编码 firstLevelMin: 3000, firstLevelMax: , secondLevelMax: 3000, secondLevelMin: 300, thirdLevelMax: 300, thirdLevelMin: 0 后面执行规则的时候，只需要按照特性字段从缓存中取，就可以了。 这样只需要处理一遍范围、资质的数据。 2. 具体实现使用本地缓存Caffeine、根据数据库创建实体类、Mapper、 创建一个 Caffeine 缓存配置类，并在 Spring Boot 启动时加载规则。 @Configuration@EnableCachingpublic class CaffeineCacheConfig @Bean public CacheManager cacheManager() return new CaffeineCacheManager(); 在 Spring Boot 启动时加载规则并缓存: @Componentpublic class RuleLoader @Autowired private CommonMapper commonMapper; @Autowired private CacheManager cacheManager; @PostConstruct public void loadRulesToCache() // 从数据库加载资质数据 ListArchitectScope qualifications = commonMapper.findAll(); MapString, ArchitectScope qualificationCache = new HashMap(); // 根据特性值分组 // 提取特性值、合同金额 // 处理成map，map的key就是建造师名称+类型||资质那里比较特殊，需要存双份，一份key值是资质名称，一份是建造师专业 // 将加载的规则数据放入 Caffeine 缓存 cacheManager.getCache(qualificationCache).put(qualification, qualificationCache); System.out.println(Rules loaded into Caffeine cache.); 使用缓存： public ArchitectScope getQualificationFromCache(String qualificationName) MapString, ArchitectScope qualificationCache = (MapString, ArchitectScope) cacheManager.getCache(qualificationCache).get(qualification).get(); return qualificationCache.get(qualificationName); 功能设计文档页面及流程第一页：采购方式及适用范围展示 功能描述： 提供一个下拉框（请选择采购方式），用户选择后展示相关文本。 用户选择下拉框后，触发接口查询数据，返回的数据以只读形式展示。 页面底部提供“下一页”按钮，参考工程造价页面，点击后进入第二页。 变量定义： 下拉框选项：dropdown_options 查询接口返回数据：query_data 第二页：文件上传与数据提取 功能描述： 页面顶部提供一个上传按钮，支持上传文件夹或多选文件。 触发后端接口，上传文件并提取招标公告和项目信息，提取后的信息存入数据库表。 页面展示提取的项目信息，用户可修改，修改后的数据以文本格式存储。 页面底部提供“执行”按钮，点击后进入第三页。 变量定义： 上传文件的URL：uploaded_file_urls 提取的项目信息：project_info 提取的招标公告内容：tender_notice 修改后的项目信息：modified_project_info 第三页：异步执行 功能描述： 展示固定文本：”异步执行中，请稍后在历史记录中查看。” 数据表结构项目信息表（project_info）CREATE TABLE project_info ( id INT PRIMARY KEY AUTO_INCREMENT COMMENT 主键, project_name VARCHAR(255) NOT NULL COMMENT 项目名称, agency VARCHAR(255) COMMENT 代理机构, bidder VARCHAR(255) COMMENT 招标人, section_code VARCHAR(50) COMMENT 标段编码, location VARCHAR(255) COMMENT 建设地点, estimated_cost DECIMAL(18, 2) COMMENT 合同估算价, duration VARCHAR(50) COMMENT 计划工期, project_category VARCHAR(100) COMMENT 项目类别, qualification_field VARCHAR(100) COMMENT 资质专业, qualification_level VARCHAR(100) COMMENT 资质级别, manager_field VARCHAR(100) COMMENT 项目经理专业, manager_level VARCHAR(100) COMMENT 项目经理级别, performance_req BOOLEAN COMMENT 业绩要求（有或无）, manager_perf_req BOOLEAN COMMENT 项目经理业绩要求（有或无）, financial_req BOOLEAN COMMENT 财务要求（有或无）, doc_acquire_time DATETIME COMMENT 招标文件获取时间, bid_opening_time DATETIME COMMENT 开标时间, evaluation_method VARCHAR(100) COMMENT 评标办法（综合评估法或最低价法）, modified_info TEXT COMMENT 页面修改后的项目信息, tender_doc_urls TEXT COMMENT 招标文件URL（可能是多个）) COMMENT=项目信息表; 上传功能详细流程 用户操作： 用户选择文件或文件夹。 前端调用接口上传文件，返回文件URL列表uploaded_file_urls。 后端处理： 提取文件中的项目信息和招标公告内容。 提取的项目信息字段包括： project_name agency bidder section_code location estimated_cost duration project_category qualification_field qualification_level manager_field manager_level performance_req manager_perf_req financial_req doc_acquire_time bid_opening_time evaluation_method 如果提取到的项目名称存在于缓存中，则直接返回缓存数据；否则： 从文件中提取招标公告及招标文件的段落内容。 将提取结果存入缓存（超时时间30分钟）。 前端展示： 接收返回的project_info并展示。 用户可修改项目信息，修改结果存入modified_project_info。 执行功能详细流程 数据准备： 接收前端传递的modified_project_info，存入数据库。 从缓存中获取： 建筑师职业范围和资质。 审查规则数据（若缓存不存在则查询数据库并存入缓存）。 招标公告和招标文件段落内容。 如果缓存缺失必要数据，向用户提示重新上传。 规则处理： 简单规则：统一循环处理，生成结果对象，包括： 规则编码：rule_code 取证单位名称：evidence_unit 存在问题：issues 评审建议：review_suggestions 页码：page_numbers 段落内容：paragraphs 复杂规则：单独处理，生成结果对象。 报告生成： 获取最新模板：调用queryLatest方法。 根据规则处理结果，循环生成审计单，填充审计报告。 将生成的审计单和报告打包，生成下载链接，并插入记录表。 接口参考 文件上传：net.lab1024.smartadmin.module.business.bidDocAudit.service.AudiReportTplHistoryService#upload 获取最新模板：net.lab1024.smartadmin.module.business.bidDocAudit.service.AudiReportTplHistoryService#queryLatest APACHE-OPENNLP安装Mac安装brew install apache-opennlp 安装后，执行 opennlp看是否有返回help信息 标准 训练标注数据是指将文本中的特定部分（实体）标记为自定义标签。标注格式通常是 每行一个词，并且每个词都有一个与之相关的标签。 1.1 标注规则 B-：表示实体的开始（Begin）。 I-：表示实体的内部部分（Inside）。 O：表示该词不属于任何命名实体（Outside）。 示例： 假设你有以下招标文件内容： XX建筑工程，合同金额为200万元，要求具有二级建筑资质。 标注后的内容可能如下： XX建筑工程，合同金额为200万元，要求具有二级建筑资质。 在这个例子中： XX B-PROJECT_NAME建筑工程 I-PROJECT_NAME， O合同 O金额 O为 O200万元 B-AMOUNT， O要求 O具有 O二级 B-QUALIFICATION建筑资质 I-QUALIFICATION。 O 自动标注人工标注效率太低，标注数据需要大量案例，人工标注并不现实，推荐使用工具。 Label StudioLabel Studio 是一个开源的标注工具，支持文本标注、图片标注、音频标注等多种类型。它具有灵活的配置选项，可以根据需求配置标注任务，并且支持与机器学习模型结合来加速标注过程。 特点： 开源免费，适合小团队使用。 支持 命名实体识别（NER） 标注。 支持多种数据格式的导入和导出，包括 JSON 和 CSV。 能够与 模型 结合，进行 自动标注 和 人工修正。 对中文支持较好。 使用场景： 适合进行大规模的标注任务，尤其是需要标注结构化文本（如招标公告）的任务。 官网：Label Studio 优点： 完全免费且开源。 支持多种标注任务。 可配置和灵活的工作流。 缺点： 比 Prodi.gy 的界面稍显简单。 可能需要一些技术配置和部署。 使用MacBookPro :: work_space/HY_work_space/nlp % opennlp TokenNameFinderTrainer -lang zh -model zh-model-bid-project-info.bin -data ner.txt -encoding UTF-8 ner.txt 是你刚才标注好的数据文件。 zh-model-bid-project-info.bin 是你训练好的模型文件的输出路径。 zh 是语言设置，虽然 OpenNLP 主要提供英语模型，但它也支持其他语言（包括中文）。 import opennlp.tools.namefind.NameFinderME;import opennlp.tools.tokenize.SimpleTokenizer;import opennlp.tools.util.Span;import opennlp.tools.util.model.FileInputStream;import java.io.IOException;public class OpenNLPExample public static void main(String[] args) throws IOException // 加载训练好的NER模型 FileInputStream modelIn = new FileInputStream(en-ner-custom.bin); // 使用你训练的模型 NameFinderME nameFinder = new NameFinderME(new TokenNameFinderModel(modelIn)); // 输入招标文件的内容 String text = XX建筑工程，合同金额200万元，要求具有二级建筑资质。; String[] tokens = SimpleTokenizer.INSTANCE.tokenize(text); // 查找文本中的实体 Span[] nameSpans = nameFinder.find(tokens); for (Span span : nameSpans) System.out.println(实体: + tokens[span.getStart()] + 到 + tokens[span.getEnd() - 1]); LTP1. 检查 LTP 模型文件是否正确LTP 在加载模型时可能会遇到问题，特别是如果模型文件路径不正确或者模型文件损坏。LTP 默认会加载一些预训练的中文模型，如果没有正确加载，程序会卡住。 首先，确保你的 LTP 模型文件已正确安装和加载。通常，LTP 会自动下载并缓存这些模型，但如果出错，可能会导致程序挂起。 尝试手动下载 LTP 模型文件： 下载 LTP 模型： 你可以访问 LTP 官方 GitHub 或其他提供的下载链接，获取 LTP 模型。 下载模型后，将它们解压到本地文件夹。 设置模型路径： 你可以手动设置模型路径，确保 LTP 使用的是正确的模型文件。 python 复制代码 from ltp import LTP # 设置模型路径 ltp = LTP() # 可以尝试通过以下方式手动加载模型 ltp.load(path_to_your_model) # 替换为实际模型路径 2. 检查 LTP 的安装方式LTP 有多个安装方式（如 pyltp 或 ltp），这可能会影响模型加载。你可以尝试使用 pyltp，这是 LTP 的原生 Python 接口，通常支持更好的稳定性。 尝试以下步骤： bash 复制代码 pip install pyltp 然后使用 pyltp 进行模型加载和处理。 python 复制代码 from pyltp import Segmentor, NamedEntityRecognizer # 初始化分词器和命名实体识别器 segmentor = Segmentor() recognizer = NamedEntityRecognizer() # 加载模型路径 segmentor.load(path_to_your_model/cws.model) # 分词模型 recognizer.load(path_to_your_model/ner.model) # 命名实体识别模型 # 测试文本 text = 阜阳市城南新区华信路道路及附属工程施工招标公告（电子招标） # 分词 words = segmentor.segment(text) print(Words:, \\t.join(words)) # 命名实体识别 named_entities = recognizer.recognize(words, [0]*len(words)) # 这里的[0]*len(words)只是一个例子，实际可以传递真实的句法分析结果 print(Named Entities:, \\t.join(named_entities)) 3. 调试模型加载过程为了更深入地理解问题，可以在加载模型时添加更多的调试信息，看看是否能够找出问题所在。 python 复制代码 from ltp import LTP print(Initializing LTP...) try: ltp = LTP() print(LTP initialized.) except Exception as e: print(fError initializing LTP: {e}) 4. 检查是否有资源耗尽在一些低配置的机器或内存较小的环境中，LTP 初始化时可能会耗尽资源，导致卡住。可以查看你的系统资源（如 CPU 和内存）使用情况，检查是否有异常。 5. 模型文件路径权限问题确保 LTP 模型文件有正确的读取权限。有时，路径问题或者权限问题会导致 LTP 卡住。 6. 检查 Python 环境和依赖LTP 依赖于一些底层的 C++ 库，确保你的 Python 环境没有出现冲突。 你可以使用以下命令检查 Python 环境是否有问题： bash 复制代码 pip list 查看是否有任何与 ltp 相关的冲突或版本问题。 7. 更新或降级版本如果你使用的是较新的版本，尝试降级到一个稳定的版本，或尝试使用其他版本的 LTP 进行兼容性测试。 8. 使用其他轻量化中文NLP库如果 LTP 继续出现问题，考虑使用其他轻量的 NLP 库，如： jieba：一个轻量级的中文分词库，适合分词和简单的文本处理。 SpaCy + 预训练模型：SpaCy 也支持中文，并且可以通过加载模型进行命名实体识别。 总结： 确保 LTP 模型文件已正确下载并加载。 检查 LTP 安装是否正确，尝试使用 pyltp。 加入更多调试信息，查看错误。 确保系统资源足够，检查是否有资源耗尽的情况。 尝试其他轻量化 NLP 库，如 jieba，如果 LTP 无法解决问题。 TONGYI-LONG新角度 返回全部规则的json key为规则编码，value为是否curl --location https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions \\--header Authorization: Bearer sk-4b479404a0f3478db9f64005cf08367f \\--header Content-Type: application/json \\--header Cookie: acw_tc=2526ba21-09fc-95d2-805b-b4218729fdf1cf2b8df336c14ec4375c39b114b97498 \\--data model: qwen-long, response_format: type: json_object , messages: [ role: system, content: 你是一个有熟练经验的审计工程师 , role: system, content: fileid://file-fe-VAAynUVqimzTAIH1yQbXXAq5 , role: user, content: 这个招标文件正文中,投标有效期是否为0或空，请返回json形式 ] 设计：上传文件时，将文件直接上传至阿里qwen-long，返回文件id通过接口获取项目信息（）"},{"path":"/2026/01/21/归档/Leetcode/","content":"2171 拿出最少得魔法豆 二分法： class Solution public int search(int[] nums, int target) if (nums.length == 0) return -1; if (nums.length == 1) return nums[0] == target ? 0 : -1; int index = -1; int lfet = 0; int right = nums.length - 1; return search(lfet, right, nums, target); public int search(int left, int right, int[] nums, int target) if (left right) return -1; int center = (left + right) / 2; if (nums[center] == target) return center; else if (nums[center] target) return search(left, center - 1, nums, target); else return search(center + 1, right, nums, target);"},{"title":"Jmeter","path":"/2026/01/21/归档/Jmeter简单使用/","content":"","tags":["软件"]},{"path":"/2026/01/21/归档/MJ/","content":"面试官：谈谈你对乐观锁、悲观锁、分布式锁、读写锁的理解。候选人： 好的，这些锁机制是解决并发问题的核心手段，各自适用于不同的场景。我来分别阐述它们的原理、应用及实践经验。 一、乐观锁（Optimistic Lock）核心思想：假设并发冲突的概率低，只在提交时检测数据是否被修改。实现方式： 版本号机制：数据表中增加版本号字段，更新时校验版本号。 UPDATE table SET value = new_value, version = version + 1 WHERE id = #id AND version = #old_version CAS（Compare And Swap）：通过CPU原子指令实现无锁并发。 AtomicInteger count = new AtomicInteger(0);count.compareAndSet(0, 1); // 当前值为0时更新为1 适用场景： 读多写少，冲突概率低（如点赞计数、库存扣减）。 需要高并发吞吐（避免锁竞争开销）。 优点：无锁设计，性能高。缺点： ABA问题：数据被修改后恢复原值，导致CAS误判（可通过时间戳或递增版本号解决）。 自旋开销：高冲突场景下频繁重试。 案例：电商系统中，秒杀活动库存扣减使用Redis的WATCH+MULTI实现乐观锁，确保超卖问题。 二、悲观锁（Pessimistic Lock）核心思想：假设并发冲突概率高，操作前先加锁独占资源。实现方式： 数据库行锁：SELECT ... FOR UPDATE。 Java锁机制：synchronized、ReentrantLock。 适用场景： 写多读少，冲突概率高（如账户转账、订单支付）。 需要强一致性保证。 优点：保证数据强一致性。缺点：锁竞争导致吞吐下降，可能引发死锁。 案例：银行转账时，使用数据库事务+行级锁，确保转账操作的原子性。 三、分布式锁（Distributed Lock）核心思想：在分布式系统中协调多节点对共享资源的互斥访问。实现方式： Redis（AP模型）： // Redisson实现RLock lock = redisson.getLock(order_lock);lock.lock(30, TimeUnit.SECONDS); // 支持自动续期try // 业务逻辑 finally lock.unlock(); 缺点：主从切换可能导致锁失效（需RedLock算法，但仍有争议）。 ZooKeeper（CP模型）： 基于临时顺序节点，通过Watcher机制实现锁竞争。 优点：强一致，无脑裂问题。 缺点：性能低于Redis，需维护长连接。 适用场景： 分布式系统资源互斥（如定时任务调度、分布式事务协调）。 关键问题： 锁续期：需实现心跳机制防止业务未完成锁超时（如Redisson的WatchDog）。 容错性：确保锁在节点宕机时自动释放。 案例：分布式系统中，使用ZooKeeper实现全局唯一ID生成服务的互斥锁。 四、读写锁（ReadWrite Lock）核心思想：读共享，写独占，提升读多写少场景的并发度。实现方式： ReentrantReadWriteLock rwLock = new ReentrantReadWriteLock();Lock readLock = rwLock.readLock(); // 读锁（共享）Lock writeLock = rwLock.writeLock(); // 写锁（独占）// 读操作readLock.lock();try // 读取数据 finally readLock.unlock();// 写操作writeLock.lock();try // 修改数据 finally writeLock.unlock(); 适用场景： 读操作远多于写操作（如配置中心、缓存数据）。 需要保证写操作的原子性，同时允许多读并发。 优点：显著提升读性能。缺点： 写饥饿：持续读操作可能导致写线程长期等待（可设置公平锁缓解）。 锁降级：写锁可降级为读锁，但读锁无法升级为写锁。 案例：缓存系统中，使用StampedLock的乐观读（tryOptimisticRead）进一步减少锁竞争。 五、锁机制对比与选型 锁类型 适用场景 性能 一致性 复杂度 乐观锁 低冲突、高并发读 高 最终 低 悲观锁 高冲突、强一致性 中 强 中 分布式锁 跨进程资源协调 低 依赖实现 高 读写锁 读多写少 高 强 中 六、实践经验总结 减少锁粒度： 使用ConcurrentHashMap的分段锁替代全局锁。 数据库对非必要字段不加锁。 避免死锁： 按固定顺序获取锁。 使用tryLock设置超时。 监控与调优： 通过JMX监控锁竞争（如ReentrantLock的getQueueLength）。 压测验证锁性能（如使用JMeter模拟高并发）。 分布式锁容灾： 为Redis锁设置合理的超时时间，并实现续期逻辑。 ZooKeeper锁需处理Session过期（如Curator的InterProcessMutex）。 案例：某交易平台在促销活动中，针对商品详情页的读多写少场景，采用ReentrantReadWriteLock，将QPS从1.2万提升至4.8万，同时保证价格库存的强一致性。 总结： 乐观锁和悲观锁是解决并发问题的两种哲学，前者信任环境，后者防范风险。 分布式锁是分布式系统的刚需，需在CAP中权衡选择Redis或ZooKeeper。 读写锁通过分离读写操作最大化并发效率。 实际开发中需结合业务特点（冲突频率、一致性要求、吞吐需求）选择最合适的锁机制。 面试官：谈谈你对线程守护的理解。候选人： 好的，守护线程（DaThread）是Java中一种特殊类型的线程，它的核心作用是为其他线程（用户线程）提供后台服务支持。当所有用户线程结束时，守护线程会自动终止，无论其任务是否完成。以下是我对守护线程的理解和实际应用中的注意事项： 一、守护线程的核心特性 自动终止机制当JVM中仅剩守护线程运行时，JVM会直接退出，不会等待守护线程完成任务。示例： Thread daemonThread = new Thread(() - while (true) System.out.println(守护线程运行中...); try Thread.sleep(1000); catch (InterruptedException e) e.printStackTrace(); );daemonThread.setDaemon(true); // 必须在线程启动前设置daemonThread.start();// 主线程结束 → 所有用户线程终止 → 守护线程自动退出 非阻塞性守护线程的存在不会阻止JVM退出，适合执行非关键性任务（如日志轮转、监控等）。 继承性由守护线程创建的线程默认也是守护线程。 二、典型应用场景 场景 说明 垃圾回收（GC） JVM的垃圾回收线程是守护线程，负责自动内存管理 心跳检测 网络服务中定期发送心跳包检测连接状态 缓存清理 周期性清理过期缓存条目 日志异步写入 将日志写入操作委托给守护线程，避免阻塞主线程（需确保写入完整性） 三、使用注意事项 设置时机必须在调用start()方法前设置setDaemon(true)，否则抛出IllegalThreadStateException。 资源管理风险守护线程中不要执行关键任务（如数据库事务提交、文件持久化），否则可能因JVM退出导致数据丢失。反例： daemonThread = new Thread(() - try writeToFile(); // 可能未完成写入即被终止 finally // finally块可能无法执行 ); 线程池中的守护线程通过ThreadFactory自定义线程池中的线程为守护线程： ExecutorService executor = Executors.newCachedThreadPool(r - Thread t = new Thread(r); t.setDaemon(true); return t;); 避免依赖守护线程执行清理需要显式释放资源（如关闭网络连接）时，应使用用户线程结合shutdownHook。 四、守护线程 vs 用户线程 特性 守护线程 用户线程 JVM退出影响 立即终止 必须等待执行完毕 默认类型 否（需显式设置） 是（主线程默认是用户线程） 适用场景 辅助性任务 核心业务逻辑 资源依赖 避免持有需释放的资源 需确保资源正确释放 五、实战避坑指南 避免在守护线程中执行IO操作若必须执行，需增加同步屏障确保任务完成： CountDownLatch latch = new CountDownLatch(1);daemonThread = new Thread(() - writeToFile(); latch.countDown(););daemonThread.setDaemon(true);daemonThread.start();latch.await(); // 主线程等待守护线程完成 监控守护线程状态通过JMX或自定义监控逻辑检测守护线程是否存活： if (!daemonThread.isAlive()) log.error(守护线程异常终止); 与ShutdownHook结合在JVM关闭时执行必要的清理操作： Runtime.getRuntime().addShutdownHook(new Thread(() - // 释放资源)); 总结：守护线程是Java多线程编程中重要的后台支持机制，但需谨慎使用。它适用于非关键性任务，如监控、日志等，但需避免依赖其执行资源敏感型操作。正确理解其生命周期和限制，能够有效提升程序的健壮性。例如，在分布式系统中，我们曾用守护线程实现服务注册中心的健康检查，确保在主服务线程异常退出时，守护线程能快速终止，避免僵尸进程。 线程池与线程安全容器详解一、线程池的核心概念与实现线程池是一种线程资源复用机制，通过预先创建并管理线程，降低频繁创建和销毁线程的开销，提升系统性能和稳定性。 1. 线程池关键参数 核心线程数（corePoolSize）：线程池长期维持的线程数量，即使空闲也不会回收。 最大线程数（maximumPoolSize）：线程池允许创建的最大线程数。 任务队列（workQueue）：用于缓存待执行任务的阻塞队列。 拒绝策略（RejectedExecutionHandler）：当任务数超过最大处理能力时的处理策略。 2. 线程池工作流程graph TDA[提交任务] -- B核心线程是否已满?B --|未满| C[创建新线程执行任务]B --|已满| D队列是否已满?D --|未满| E[任务入队等待]D --|已满| F是否达到最大线程数?F --|未达到| G[创建新线程执行任务]F --|已达到| H[触发拒绝策略] 3. 常见线程池类型 类型 特点 适用场景 FixedThreadPool 固定线程数，使用无界队列（LinkedBlockingQueue） 长期稳定的并发任务 CachedThreadPool 线程数无上限，空闲线程60秒回收，使用同步队列（SynchronousQueue） 短时异步任务，高并发但需防资源耗尽 ScheduledThreadPool 支持定时或周期性任务，使用DelayedWorkQueue 定时任务、心跳检测 SingleThreadExecutor 单线程执行，保证任务顺序性 需顺序执行的任务（如日志处理） 4. 拒绝策略 AbortPolicy（默认）：抛出RejectedExecutionException。 CallerRunsPolicy：由提交任务的线程直接执行任务。 DiscardPolicy：静默丢弃任务。 DiscardOldestPolicy：丢弃队列中最旧的任务，重试提交。 示例代码： ThreadPoolExecutor executor = new ThreadPoolExecutor( 4, // corePoolSize 8, // maximumPoolSize 60, TimeUnit.SECONDS, // keepAliveTime new ArrayBlockingQueue(100), // 有界队列 new ThreadPoolExecutor.CallerRunsPolicy() // 拒绝策略); 二、线程安全容器线程安全容器通过内部同步机制保证多线程环境下的数据一致性，常见实现类位于java.util.concurrent包。 1. 常见线程安全容器 容器 实现原理 适用场景 ConcurrentHashMap 分段锁（JDK7）或 CAS + synchronized（JDK8） 高并发读写，如缓存、计数器 CopyOnWriteArrayList 写时复制（复制整个数组） 读多写少场景（如监听器列表） BlockingQueue 锁 + Condition实现阻塞操作 生产者-消费者模型（如任务队列） ConcurrentLinkedQueue CAS实现的无锁队列 高吞吐量无阻塞队列 2. 核心实现对比 ConcurrentHashMapJDK8后采用Node + CAS + synchronized，锁粒度细化到链表头节点，并发度更高。 ConcurrentHashMapString, Integer map = new ConcurrentHashMap();map.computeIfAbsent(key, k - 1); // 原子操作 CopyOnWriteArrayList写操作通过复制数组实现线程安全，读操作无锁。适合遍历频繁但修改少的场景。 CopyOnWriteArrayListString list = new CopyOnWriteArrayList();list.add(item); // 加锁复制数组 BlockingQueue如ArrayBlockingQueue（有界）和LinkedBlockingQueue（可选有界无界），支持阻塞插入取出。 BlockingQueueRunnable queue = new ArrayBlockingQueue(100);queue.put(task); // 阻塞直到队列有空位Runnable task = queue.take(); // 阻塞直到队列有元素 3. 使用场景与选型 高并发计数器：使用ConcurrentHashMap的compute方法。 缓存系统：ConcurrentHashMap + 软引用弱引用。 任务调度：ThreadPoolExecutor + BlockingQueue。 事件监听器：CopyOnWriteArrayList避免遍历时修改导致的异常。 三、实战经验与避坑指南1. 线程池常见问题 资源耗尽：无界队列（如LinkedBlockingQueue）可能导致OOM。 解决方案：使用有界队列并合理设置拒绝策略。 死锁：任务相互等待导致线程饥饿。 示例：线程池大小为2，两个任务各自提交子任务并等待结果。 解决：避免在任务中提交阻塞性子任务，或使用ForkJoinPool。 2. 线程安全容器注意事项 ConcurrentHashMap的弱一致性：迭代器不保证反映最新修改。ConcurrentHashMapString, String map = new ConcurrentHashMap();map.put(a, 1);IteratorString it = map.values().iterator();map.put(b, 2); // 迭代器可能不包含b CopyOnWriteArrayList的内存开销：频繁写操作会导致数组频繁复制，适合读多写少场景。 3. 性能优化 线程池监控：通过ThreadPoolExecutor的getActiveCount()、getQueue().size()等指标实时监控。 容器选择：读多写少用ConcurrentHashMap，写多用Collections.synchronizedMap()（需外部同步）。 避免锁竞争：使用LongAdder替代AtomicLong（高并发计数器场景）。 四、总结 线程池是管理线程生命周期的核心工具，需根据任务类型（CPU密集型、IO密集型）合理配置参数。 线程安全容器通过精细的锁机制或无锁编程实现高效并发，需根据读写比例和性能需求选择。 实际应用中，线程池需配合有界队列和拒绝策略防止资源耗尽，线程安全容器需注意迭代器弱一致性和内存开销。 通过合理使用线程池和线程安全容器，可显著提升高并发系统的吞吐量和稳定性。例如，某电商系统通过ThreadPoolExecutor管理订单处理线程，结合ConcurrentHashMap缓存商品信息，成功支撑了双十一期间每秒数万次的并发请求。 面试官：谈谈你对线程安全的理解，以及信号量、Lock、synchronized的使用概念？候选人： 好的，我来分享一下我对线程安全和这些同步机制的理解。 1. 线程安全的核心问题线程安全的核心是确保多个线程并发访问共享资源时，程序的执行结果始终符合预期。这需要解决三个关键问题： 原子性：操作不可分割（如 i++ 需要保证“读取-修改-写入”的原子性）。 可见性：一个线程对共享变量的修改对其他线程立即可见。 有序性：禁止指令重排序导致逻辑错误。 2. synchronized：内置锁特点： 语法简单：直接修饰方法或代码块，自动加锁解锁。 基于Monitor机制：每个对象关联一个监视器锁，通过字节码指令 monitorenter 和 monitorexit 实现。 非公平锁：等待线程无法按申请顺序获取锁。 可重入性：同一线程可重复获取同一把锁（避免死锁）。 使用场景： 简单的临界区保护（如单例模式的懒加载）。 对性能要求不高且同步逻辑不复杂的场景。 示例： public class Counter private int count; public synchronized void increment() count++; // 保证原子性 缺点： 无法中断等待锁的线程。 无法设置超时。 粒度较粗（只能锁整个方法或对象）。 3. Lock接口：灵活控制核心实现（如ReentrantLock）： 显式锁：需要手动调用 lock() 和 unlock()（通常在 finally 中释放）。 可中断：通过 lockInterruptibly() 响应中断。 超时机制：tryLock(long timeout, TimeUnit unit) 避免死等。 公平性：支持公平锁（按申请顺序获取）和非公平锁。 条件变量：通过 Condition 实现线程间精确唤醒（如生产者-消费者模型）。 使用场景： 需要灵活控制锁的获取与释放。 需要实现复杂同步逻辑（如超时、可中断）。 需要公平性保证的高并发场景。 示例： Lock lock = new ReentrantLock();public void transfer(Account from, Account to, int amount) lock.lock(); try // 转账逻辑 finally lock.unlock(); 优势： 更细粒度的控制。 支持多条件变量，提升并发效率。 4. 信号量（Semaphore）：资源管控核心思想： 通过“许可证”机制控制并发线程数。 初始化时指定许可证数量，线程获取许可证后执行，执行完毕释放。 使用场景： 限流（如接口每秒最多处理100个请求）。 资源池管理（如数据库连接池）。 控制同时访问特定资源的线程数。 示例： Semaphore semaphore = new Semaphore(10); // 允许10个线程并发public void accessResource() semaphore.acquire(); // 获取许可 try // 使用资源 finally semaphore.release(); // 释放许可 特性： 支持公平非公平模式。 可动态调整许可证数量（如 semaphore.release(5)）。 5. 对比与选型 机制 适用场景 优势 局限性 synchronized 简单同步、单JVM内互斥 自动管理、无需手动释放 功能单一、无法中断或超时 Lock 复杂锁逻辑、需要细粒度控制 灵活、支持条件变量和超时 需手动管理、易遗漏释放 Semaphore 资源并发数限制、流量控制 灵活控制并发度 不保证资源操作的原子性 6. 实战经验与避坑指南 锁粒度控制： 粗粒度锁（如锁整个方法）可能导致性能瓶颈。 细粒度锁（如分段锁）提升并发能力，但复杂度高。 死锁预防： 避免嵌套锁（如线程A持有锁1请求锁2，线程B持有锁2请求锁1）。 使用 tryLock 设置超时，打破死锁等待。 性能优化： 读多写少场景使用 ReadWriteLock（如缓存）。 无竞争时，synchronized 经过JVM优化（偏向锁、轻量级锁）性能优于 Lock。 总结： synchronized 适合简单场景，开发成本低； Lock 提供更灵活的并发控制，适合复杂逻辑； Semaphore 用于资源管控而非互斥。实际选型需结合具体场景，在高并发系统中，通常会组合使用多种机制（如 synchronized + ConcurrentHashMap + Semaphore）实现最优效果。"},{"title":"Navicat数据库导出链接密码解析","path":"/2026/01/21/归档/Mac 数据库忘记密码/","content":"参考：https://blog.csdn.net/harris_lele/article/details/123588127 导出来，然后用php解析密码即可； 在线运行php： https://www.toolfk.com/tools/online-runphp.html 运行代码： ?phpclass NavicatPassword protected $version = 0; protected $aesKey = libcckeylibcckey; protected $aesIv = libcciv libcciv ; protected $blowString = 3DC5CA39; protected $blowKey = null; protected $blowIv = null; public function __construct($version = 12) $this-version = $version; $this-blowKey = sha1(3DC5CA39, true); $this-blowIv = hex2bin(d9c7c3c8870d64bd); public function encrypt($string) $result = FALSE; switch ($this-version) case 11: $result = $this-encryptEleven($string); break; case 12: $result = $this-encryptTwelve($string); break; default: break; return $result; protected function encryptEleven($string) $round = intval(floor(strlen($string) / 8)); $leftLength = strlen($string) % 8; $result = ; $currentVector = $this-blowIv; for ($i = 0; $i $round; $i++) $temp = $this-encryptBlock($this-xorBytes(substr($string, 8 * $i, 8), $currentVector)); $currentVector = $this-xorBytes($currentVector, $temp); $result .= $temp; if ($leftLength) $currentVector = $this-encryptBlock($currentVector); $result .= $this-xorBytes(substr($string, 8 * $i, $leftLength), $currentVector); return strtoupper(bin2hex($result)); protected function encryptBlock($block) return openssl_encrypt($block, BF-ECB, $this-blowKey, OPENSSL_RAW_DATA|OPENSSL_NO_PADDING); protected function decryptBlock($block) return openssl_decrypt($block, BF-ECB, $this-blowKey, OPENSSL_RAW_DATA|OPENSSL_NO_PADDING); protected function xorBytes($str1, $str2) $result = ; for ($i = 0; $i strlen($str1); $i++) $result .= chr(ord($str1[$i]) ^ ord($str2[$i])); return $result; protected function encryptTwelve($string) $result = openssl_encrypt($string, AES-128-CBC, $this-aesKey, OPENSSL_RAW_DATA, $this-aesIv); return strtoupper(bin2hex($result)); public function decrypt($string) $result = FALSE; switch ($this-version) case 11: $result = $this-decryptEleven($string); break; case 12: $result = $this-decryptTwelve($string); break; default: break; return $result; protected function decryptEleven($upperString) $string = hex2bin(strtolower($upperString)); $round = intval(floor(strlen($string) / 8)); $leftLength = strlen($string) % 8; $result = ; $currentVector = $this-blowIv; for ($i = 0; $i $round; $i++) $encryptedBlock = substr($string, 8 * $i, 8); $temp = $this-xorBytes($this-decryptBlock($encryptedBlock), $currentVector); $currentVector = $this-xorBytes($currentVector, $encryptedBlock); $result .= $temp; if ($leftLength) $currentVector = $this-encryptBlock($currentVector); $result .= $this-xorBytes(substr($string, 8 * $i, $leftLength), $currentVector); return $result; protected function decryptTwelve($upperString) $string = hex2bin(strtolower($upperString)); return openssl_decrypt($string, AES-128-CBC, $this-aesKey, OPENSSL_RAW_DATA, $this-aesIv); ; //需要指定版本两种，11或12//$navicatPassword = new NavicatPassword(11);$navicatPassword = new NavicatPassword(12); //解密//$decode = $navicatPassword-decrypt(15057D7BA390);$decode = $navicatPassword-decrypt(75008D0AE102C19EE3767E201AC9E4D2);echo $decode. ;?","tags":["数据库"],"categories":["实用"]},{"title":"Mac使用记录","path":"/2026/01/21/归档/Mac使用记录/","content":"软件ttygif 终端录制工具 安装教程brew install ttygif 使用命令行提示符 command:(\"[root@localhost] $\":1,9-10||\"[admin@remotehost] #\":4-6)ttyrec myrecording sshx 终端共享 使用zhanghuapengdeMacBook-Pro :: Downloads/work_space/AA % sshx sshx v0.2.1 ➜ Link: https://sshx.io/s/ZtVval8VO2#e9o4sruIiflVdh ➜ Shell: /bin/zsh Flutter环境安装：官方说明 环境python环境 虚拟环境：~ DP:DrissionPage LUAlua+redis限流 Cargoinstall cargo 破解软件打不开# 这个好像没生效Mac :: ~ % sudo spctl --global-disablePassword:# 将软件拖进来Mac :: ~ % sudo xattr -r -c /Applications/Navicat\\ Premium.app Jrebel 激活docker pull qierkang/golang-reverseproxydocker run -d -p 8888:8888 qierkang/golang-reverseproxy#licenehttp://127.0.0.1:8888/7a14c9f7-8a27-46d6-bb50-2b30c19e766c 一行命令下载全网视频$ pip3 install you-get 如何下载 1. 可通过如下命令查看该视频的详细信息。 you-get -i 视频url 2. 下载方式更简单，只需一行命令即可下载了： you-get 视频url Jan - 将人工智能带入您的桌面```## Sonoma系统退回到Catalina![](https://s3.bmp.ovh/imgs/2024/03/18/26d4edbd95ba29b0.png)20款MacBook Pro，使用Sonoma系统感觉有点卡顿，晚上说是新系统对旧Mac兼容不是很好，决定退回Catalina版本，最后一个Inter电脑发布的系统准备：U盘（32G）（没有也行时间机器：（没有也行 主打一个凑合电脑硬盘：这个得有Catalina系统安装器（去App Store下载好0. 先分区 - 有U盘的情况，直接新建一个系统分区就好（`APFS`格式） - 无U盘的情况，先建一个系统分区，再用至少20G空间做一个引导系统分区，格式选（Mac OS日志） - 分区的时候，该抹掉就抹掉，只要别把当前系统抹掉就行1. 制作引导系统 （这步记不太清楚了有U盘的情况下，重启电脑，按`option`键，显示小地球图标（没有图），大概就是下面的这种，![](https://s3.bmp.ovh/imgs/2024/03/18/5ad8cd52fe6b475c.png)2. 分区3. 安装到分区上4. 用Catalina系统制作时间机器，保证时间机器分区是Mac OS 扩展（日志式）5. 将Sonoma系统数据备份到时间机器6. 到Catalina系统，用迁移助理将数据迁移过来7. 后续看情况删除Sonoma系统分区## Docker### QL#### dailycheckin```python获取i茅台账号cookieimport hashlibimport jsonimport timeimport requests获取地点信息,这里用的高德 api,需要自己去高德开发者平台申请自己的 keyAMAP_KEY = d13d06ac58fd360776f58583254c0079SALT = 2af72f100c356273d46284f6fd1dfc08CURRENT_TIME = str(int(time.time() * 1000))headers = mt_version = json.loads(requests.get(https://itunes.apple.com/cn/lookup?id=1600482450).text)[results][0][version]header_context = MT-Lat: 28.499562MT-K: 1675213490331MT-Lng: 102.182324Host: app.moutai519.com.cnMT-User-Tag: 0Accept: */*MT-Network-Type: WIFIMT-Token: 1MT-Team-ID: 1MT-Info: 028e7f96f6369cafe1d105579c5b9377MT-Device-ID: 2F2075D0-B66C-4287-A903-DBFF6358342AMT-Bundle-ID: com.moutai.mallAccept-Language: en-CN;q=1, zh-Hans-CN;q=0.9MT-Request-ID: 167560018873318465MT-APP-Version: 1.3.7User-Agent: iOS;16.3;Apple;?unrecognized?MT-R: clips_OlU6TmFRag5rCXwbNAQ/Tz1SKlN8THcecBp/HGhHdw==Content-Length: 93Accept-Encoding: gzip, deflate, brConnection: keep-aliveContent-Type: application/jsonuserId: 2# 初始化请求头def init_headers(user_id: str = 1, token: str = 2, lat: str = 29.83826, lng: str = 119.74375):for k in header_context.strip().split( ):temp_l = k.split(: )dict.update(headers, temp_l[0]: temp_l[1])dict.update(headers, userId: user_id)dict.update(headers, MT-Token: token)dict.update(headers, MT-Lat: lat)dict.update(headers, MT-Lng: lng)dict.update(headers, MT-APP-Version: mt_version)# 用高德api获取地图信息def select_geo(i: str):# 校验高德api是否配置if AMAP_KEY is None:print(!!!!请配置 AMAP_KEY (高德地图的MapKey))raise ValueErrorresp = requests.get(fhttps://restapi.amap.com/v3/geocode/geo?key=AMAP_KEYoutput=jsonaddress=i)geocodes: list = resp.json()[geocodes]return geocodesdef signature(data: dict):keys = sorted(data.keys())temp_v = for item in keys:temp_v += data[item]text = SALT + temp_v + CURRENT_TIMEhl = hashlib.md5()hl.update(text.encode(encoding=utf8))md5 = hl.hexdigest()return md5# 获取登录手机验证码def get_vcode(mobile: str):params = mobile: mobilemd5 = signature(params)dict.update(params, md5: md5, timestamp: CURRENT_TIME, MT-APP-Version: mt_version)responses = requests.post(https://app.moutai519.com.cn/xhr/front/user/register/vcode,json=params,headers=headers,)if responses.status_code != 200:print(fget v_code : params : params, response code : responses.status_code, response body : responses.text)# 执行登录操作def login(mobile: str, v_code: str):params = mobile: mobile, vCode: v_code, ydToken: , ydLogId: md5 = signature(params)dict.update(params, md5: md5, timestamp: CURRENT_TIME, MT-APP-Version: mt_version)responses = requests.post(https://app.moutai519.com.cn/xhr/front/user/register/login,json=params,headers=headers,)if responses.status_code != 200:print(flogin : params : params, response code : responses.status_code, response body : responses.text)dict.update(headers, MT-Token: responses.json()[data][token])dict.update(headers, userId: responses.json()[data][userId])return responses.json()[data][token], responses.json()[data][userId]def get_location():while 1:location = input(请输入精确小区位置，例如[小区名称]，为你自动预约附近的门店:).strip()selects = select_geo(location)a = 0for item in selects:formatted_address = item[formatted_address]province = item[province]print(fa : [地区:province,位置:formatted_address])a += 1user_select = input(请选择位置序号,重新输入请输入[-]:).strip()if user_select == -:continueselect = selects[int(user_select)]formatted_address = select[formatted_address]province = select[province]print(f已选择 地区:province,[formatted_address]附近的门店)return selectif __name__ == __main__:items = []while 1:init_headers()location_select: dict = get_location()province = location_select[province]city = location_select[city]location: str = location_select[location]mobile = input(输入手机号[18888888888]:).strip()get_vcode(mobile)code = input(f输入 [mobile] 验证码[8888]:).strip()token, userId = login(mobile, code)item = city: str(city),lat: location.split(,)[1],lng: location.split(,)[0],mobile: str(mobile),province: province,token: str(token),userid: str(userId),reserve_rule: 0,item_codes: [10941, 10942],items.append(item)condition = input(是否继续添加账号[y/n]:).strip()with open(account.json, w) as f:f.write(json.dumps(items, ensure_ascii=False, indent=4))if condition.lower() == n:break Scrcpy# 手机息屏启动scrcpy --turn-screen-off 服务器FRPpath: /home/li/frpc","tags":["日常记录"]},{"title":"say something","path":"/2026/01/21/归档/N N/","content":"Java大厂面试题https://blog.csdn.net/atgfg/category_9623106.html A延迟队列？15天 并且可以重置提醒续命 （记录）\t通知 +1天 通知+短信 +2天 发给紧急联系人（）\t可以关闭掉如果恢复，打上标记 或者删掉这条记录 —打上标记 [type:text,value:222,timestamp:2024-10-08 16:22:11.421,synced:true,type:text,value:1111,timestamp:2024-10-08 16:21:50.566,synced:true] B"},{"title":"Nacos","path":"/2026/01/21/归档/Nacos/","content":"配置中心1.添加依赖dependency groupIdcom.alibaba.boot/groupId artifactIdnacos-config-spring-boot-starter/artifactId version0.2.1/version /dependency 2.启动类注解 @NacosPropertySource@SpringBootApplication // dataId 对应配置管理-配置列表-dataId@NacosPropertySource(dataId = nacosDemo, autoRefreshed = true) public class NacosDemoApplication public static void main(String[] args) SpringApplication.run(NacosDemoApplication.class, args); 3.配置nacos地址spring: application: name: nacos-demo 4.使用配置@RestController public class CacheController @NacosValue(value = $useLocalCache:false, autoRefreshed = true) private boolean useLocalCache; private static final String template = useLocalCache is %s!; @GetMapping(/cache) public String cache() // 默认返回false return String.format(template, useLocalCache); // 此时返回结果 ：useLocalCache is false! 增加配置并发布 // 返回结果 ：useLocalCache is true!","categories":["中间件"]},{"title":"MySQL","path":"/2026/01/21/归档/MySQL/","content":"SELECT\tswid.OPERATION,\tswid.DELIVERY_METHOD,\tGROUP_CONCAT( DISTINCT( swid.WORK_ORDER_ID ) ) WORK_ORDER_ID FROM\tSSME_WO_ISSUE_DETAIL swid WHERE\tswid.TENANT_ID = 4 AND swid.WORK_ORDER_ID IN ( 42717.1,42719.1 ) GROUP BY\tswid.OPERATION,\tswid.DELIVERY_METHOD https://www.cnblogs.com/minqiliang/p/16577102.html https://blog.csdn.net/z15711187787/article/details/124986309 https://blog.csdn.net/weixin_45994575/article/details/123071909?spm=1001.2101.3001.6661.1utm_medium=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-123071909-blog-123821186.t0_edu_mixdepth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-123071909-blog-123821186.t0_edu_mixutm_relevant_index=1 部署记录 JDBCTemplete批处理// sql语句String sql = INSERT INTO ssme_iqc_change(TENANT_ID, KID) VALUE (?, ?);;ListString kids = new ArrayList();// BatchPreparedStatementSetter 通过循环取出数据填充到SQL中jdbcTemplate.batchUpdate(sql, new BatchPreparedStatementSetter() @Override public void setValues(PreparedStatement ps, int i) throws SQLException ps.setLong(1, 4L); ps.setString(2, kids.get(i)); @Override public int getBatchSize() return kids.size(); ); MySQL数据删除恢复# 数据库中运行# 判断binlog是否开启show variables like %log_bin%;# 找到数据库data位置show variables like datadir; data目录下数据 找到当天的binlog # 转换为SQL 只转换操作时间内的数据即可root@VM-4-10-ubuntu:/var/lib/mysql# mysqlbinlog --base64-output=decode-rows -v --database=smart-admin-dev --start-datetime=2022-11-28 10:50:00 --stop-datetime=2022-11-28 11:00:00 binlog.000018 000018.sql 000018.sql # 将SQL转换为insert语句root@VM-4-10-ubuntu:/var/lib/mysql# cat 000018.sql | sed -n /###/p | sed s/### //g;s/\\/\\*.*/,/g;s/DELETE FROM/;INSERT INTO/g;s/WHERE/SELECT/g; |sed -r s/(@17.*),/\\1;/g | sed s/@1=//g| sed s/@[1-9]=/,/g | sed s/@[1-9][0-9]=/,/g 000018OK.sql 000018OK.sql 最后将数据导入数据库即可。 Group-- 修改 group_concat 长度限制SET GLOBAL group_concat_max_len=102400;SET SESSION group_concat_max_len=102400; Mapper空指针count sql resultType为对象，导致报错 Waiting for table metadata lockhttps://blog.csdn.net/jianlong727/article/details/111877226","categories":["数据库"]},{"path":"/2026/01/21/归档/Arthas/","content":"[arthas@18883]$ trace com.li.service.impl.SimpleServiceImpl queryPress Q or Ctrl+C to abort.Affect(class count: 1 , method count: 1) cost in 108 ms, listenerId: 1`---ts=2025-02-20 11:41:43.977;thread_name=http-nio-10000-exec-1;id=31;is_daemon=true;priority=5;TCCL=org.springframework.boot.web.embedded.tomcat.TomcatEmbeddedWebappClassLoader@8deb645 `---[1612.333758ms] com.li.service.impl.SimpleServiceImpl:query() +---[31.27% 504.240305ms ] com.li.service.impl.SimpleServiceImpl:sleep500() #16 `---[6.47% 104.355554ms ] com.li.service.impl.SimpleServiceImpl:sleep100() #17"},{"path":"/2026/01/21/归档/Austin/","content":"虚拟机的Docker启动一个MySQL5.7 docker run -d --name mysql57 \\ -e MYSQL_ROOT_PASSWORD=mysql57 \\ -p 3307:3306 \\ # 主机 3307 → 容器 3306 mysql:5.7 强制删除容器：docker rm -f mysql57"},{"title":"Centos","path":"/2026/01/21/归档/Centos/","content":"1.frpc内网穿透2. 青龙3.xdd-plushttps://www.qqmate.cn/652.html1.进入xdd目录找到 device.json 文件2.双击打开，修改： “protocol”:0,改为”protocol”:2, FRPC1. 在`frpc.exe`所在的文件夹中，右键点击空白处，选择“新建” - “快捷方式”。2. 在创建快捷方式向导中，浏览并选择`frpc.exe`文件，然后点击“下一步”。3. 给快捷方式命名，然后点击“完成”。4. 找到刚刚创建的快捷方式，右键点击它，选择“属性”。5. 在“快捷方式”标签页下，找到“目标”字段。默认情况下，它应该只包含`C:\\Path\\To\\frpc.exe`（假设`frpc.exe`在`C:\\Path\\To`目录下）。6. 在“目标”字段的末尾，添加一个空格，然后输入`-c frpc.toml`，确保整个命令看起来像这样：`C:\\Path\\To\\frpc.exe -c frpc.toml`。7. 点击“应用”和“确定”保存更改。8. 将这个修改过的快捷方式拖放到“启动”文件夹中。这样，每次您登录Windows时，`frpc.exe`都会以`frpc.toml`作为配置文件运行。请注意，这种方法不会在后台静默运行`frpc.exe`，它会在用户登录时打开一个命令行窗口。如果您想要`frpc.exe`在后台运行而不显示命令行窗口，您应该考虑使用任务计划程序或将其安装为服务。 1. **使用任务计划程序**: - 打开“任务计划程序”（可以在开始菜单中搜索“任务计划程序”来找到它）。 - 创建一个新的基本任务，设置触发器按照您的需要启动任务（例如，计算机启动时）。 - 在操作步骤中，选择“启动程序”，然后浏览并选择`frpc.exe`，并在“添加参数（可选）”中输入`-c frpc.toml`。2. **使用Windows服务**: - 使用第三方工具如[nssm](https://nssm.cc/)（Non-Sucking Service Manager）将`frpc.exe`安装为一个服务。 - 下载并解压`nssm.exe`。 - 打开命令提示符或PowerShell，导航到`nssm.exe`所在的文件夹。 - 运行命令`nssm install ServiceName`来创建新的服务，然后`nssm set ServiceName AppPath PathTofrpc.exe`设置应用路径，接着`nssm set ServiceName AppParameters -c frpc.toml`设置参数。 - 最后，启动服务使用`nssm start ServiceName`。3. **使用批处理文件**: - 创建一个批处理文件（`.bat`），在其中写入`frpc.exe -c frpc.toml`。 - 将批处理文件放置在`frpc.exe`相同的文件夹中。 - 您可以双击运行此批处理文件，或者将其添加到启动文件夹以在用户登录时自动运行。 端口3001账号：li gz123456 开机启动frpc全部服务 [Unit]Description=Frp Multiple Client ServicesAfter=network.target[Service]Type=simpleExecStart=/root/frpc/frpc/start_all_frpc.shRestart=on-failureRestartSec=5s[Install]WantedBy=multi-user.target start_all_frpc.sh #!/bin/bash/root/frpc/frpc -c /root/frpc/frpc/frpc.toml /root/frpc/frpc -c /root/frpc/frpc/frpc-29252.toml /root/frpc/frpc -c /root/frpc/frpc/frpc-3001.toml wait Nginx安装sudo yum install nginx# 如果报错：没有可用软件包 nginxsudo vi /etc/yum.repos.d/nginx.repo[nginx-stable]name=nginx stable repobaseurl=http://nginx.org/packages/centos/$releasever/$basearch/gpgcheck=1enabled=1gpgkey=https://nginx.org/keys/nginx_signing.keymodule_hotfixes=true 使用curl localhost可以curl ip 不可以修改配置文件/etc/nginx/config.d/default.conf GitHub PageNGINX配置listen 80;server_name 10.213.42.79;#access_log /var/log/nginx/host.access.log main;location / root /usr/share/nginx/fairyeye.github.io; index index.html index.htm; 分之：master位置：/usr/share/nginx/fairyeye.github.io [] 未实现部分 自动拉代码 本地每天部署一遍 更新图片地址 Windows开机启动虚拟机在虚拟机安装目录新建start_vm.bat， ps：如果vmx文件包含中文，保存编码选择GB开头的格式 @echo off.\\vmrun.exe start D:\\Centos\\CentOS 7 64位.vmxexit"},{"path":"/2026/01/21/归档/FileUtils/","content":"title: 工具类date: 2020-04-20 11:00:50categories: “工具类”数组转文件/** * @param bfile * @param filePath * @param fileName * * 根据byte数组，生成文件 */public static void getFile(byte[] bfile, String filePath,String fileName) BufferedOutputStream bos = null; FileOutputStream fos = null; File file = null; try File dir = new File(filePath); if(!dir.exists()dir.isDirectory())//判断文件目录是否存在 dir.mkdirs(); file = new File(filePath+\\\\+fileName); fos = new FileOutputStream(file); bos = new BufferedOutputStream(fos); bos.write(bfile); catch (Exception e) e.printStackTrace(); finally if (bos != null) try bos.close(); catch (IOException e1) e1.printStackTrace(); if (fos != null) try fos.close(); catch (IOException e1) e1.printStackTrace();"},{"title":"Delete/Truncate/Drop","path":"/2026/01/21/归档/Delete & Truncate/","content":"假如把一张表比作一间教室，数据比作学生。 drop 就是把这件教师炸掉了，教室都没了，更不用说数据了。 truncate 就是把学生开除了，离开了，再也没有了。 delete 就是学生出去了，虽然他们可能不会回来了，但是位置还是要留着。 Drop直接删掉表，这个没什么好说的。 包括表结构，表数据，全部删除，占用的空间也会释放。 Truncate截断表，会释放空间。 Delete删除数据","tags":["dairy"]},{"title":"231104","path":"/2026/01/21/归档/231104/","content":"pur-24166返回消息：\tscux.spuc.lotus_nyo_no_enabled_master_enable_bank\tscux.spuc.lotus_nyo_no_erp_supplier埋点：\tSPUC_SUBMIT_PO pur-26089组合业务对象：\tSRM_C_SRM_SODR_PO_HEADER个性化单元：\tSODR.ORDER_TRACKING_LIST.EXPORT pur-25937平台供应商多语言待确定 页面个性化： SODR.WORKSPACE_DETAILALL.SEARCH pur-26467独立脚本+API发布：\tSCUX_LDJT_QUERY_LAST_PURCHASE_PRICE pur-26322独立脚本+API：\tSCUX_WATSONS_UPDATE_ATTACHMENT_WFL适配器：\tSCUX_MTC_PO_HEADER_INFO\tSPUC_ORDER_QUERY_PROCESS_ACTION pur-26427配置表：\tscux_srm_carlsberg_contract_amount_change_record适配器：\tSPUC_ORDER_SYNC_IMP_INSERT_PROCESS\tSPUC_BEFORE_ERP_CLOSE_OR_CANCEL_PO 更新时：判断取消状态和表里的取消状态 pur-26689独立脚本：\tSCUX_VN_SCM_PO_RETURN_OA适配器：\t重新同步：SPUC_RE_SYNC_ERP 值集：\tSPUC.SYNC_EXP_TYPE\tSPUC.SYNC_INTERFACE_TYPE pur-26080适配器:\tSPUC_SUBMIT_PO\tSPUC_ORDER_APPROVED_EVENT pur-26150配置表： scux_srm_sanning_fee_info scux_srm_sanning_fee_calculate_type API: 查询（返回配置表数据，且翻译税率、关联协议：SCUX_SANNING_FEE_INFO_QUERY /marmot-api/v49ECXUYP60iaTD6VDYCeIrqbnlzgazaL5HYWyv9ScGg 查询2 及币种精度、CNY币种ID、CNY、费用计算类型对应关系 SCUX_SANNING_FEE_OTHER_QUERY 保存 有ID是更新，没有ID是新增 SCUX_SANNING_FEE_INFO_SAVE_OR_UPDATE /marmot-api/v49ECXUYP60iaTD6VDYCeIpQpEumLeekdKWnTERvKJjibX4rd3PkiakwNOzdMU5JBn8 删除 根据ID删除，支持批量删除 SCUX_SANNING_FEE_INFO_DEL /marmot/v1/20990/marmot-api/v49ECXUYP60iaTD6VDYCeIiab6r6sOKdPfrdSqia2ePicuU 更新预付标识：SCUX_SANNING_FEE_INFO_UPDATE_PAY_FLAG 查询: 给结算用 SCUX_SANNING_FEE_INFO_QUERY_FOR_SETTLE QB：SCUX_SANNING_FEE_INFO_QUERY_FOR_SETTLE 独立脚本： SCUX_SANNING_FEE_INFO_QUERY SCUX_SANNING_FEE_OTHER_QUERY SCUX_SANNING_FEE_INFO_SAVE_OR_UPDATE SCUX_SANNING_FEE_INFO_DEL 埋点： 保存、提交计算头个性化字段金额：SPUC_ORDER_PRICE_SOURCE_TYPE 整单取消：SPUC_ALL_CANCEL_PO_HEADER 按行取消：SPUC_LINE_CANCEL_PO_LINE 复制： SPUC_ORDER_SAVE_DATA_CONVERSION_AFTER（写入数据 SPUC_ORDER_SAVE_DATA_CONVERSION_NEWPRICE_AFTER SCUX_ORDER_PO_COPY_LINE（记录订单行ID pur-27164\t适配器： SPUC_ORDER_SYNC_IMP_INSERT_PROCESS SPUC_ORDER_SYNC_IMP_UPDATE_PROCESS 配置表： scux_srm_daqo_po_drawing_info API+独立脚本 查询：SCUX_DAQO_PO_DRAWING_INFO_QUERY 导出：SCUX_DAQO_PO_DRAWING_INFO_EXPORT 下载： BUG pur-26901 SPUC_ORDER_BATCH_SUBMIT_HANDLE [Ctrl]{.kbd} + [C]{.kbd .red}","tags":["work","迭代"]},{"title":"主题配置","path":"/2026/01/21/HEXO相关/主题配置/","content":"https://xaoxuu.com/wiki/stellar/sidebar/","tags":["日常记录"]},{"title":"Fake SRM","path":"/2026/01/21/Archive.26/项目/前端+后端初始化/","content":"查询接口实现总结项目概述本项目为 fake-srm 微服务系统添加了完整的查询接口，并实现了前端与后端的联通。 已完成的工作1. fake-product 服务（产品服务）新增接口 接口 方法 路径 功能描述 查询产品详情 GET /product/{id} 根据产品ID查询产品详情 分页查询产品列表 GET /product/list 分页查询产品列表，支持按名称模糊查询 创建产品 POST /product 创建新产品 更新产品 PUT /product/{id} 更新产品信息 删除产品 DELETE /product/{id} 删除产品 接口参数说明分页查询产品列表 (GET /product/list) page (可选, 默认1): 页码，从1开始 size (可选, 默认10): 每页数量 name (可选): 产品名称，支持模糊查询 创建产品 (POST /product) { productName: 产品名称, stock: 100, price: 99.99} 更新产品 (PUT /product/{id}) { productName: 更新产品名称, stock: 50, price: 199.99} 代码修改 ProductController.java - 添加了5个新的REST接口 ProductService.java - 添加了对应的业务方法 ProductRepository.java - 继承了 JpaSpecificationExecutor 以支持动态查询 2. fake-order 服务（订单服务）新增接口 接口 方法 路径 功能描述 查询订单详情 GET /order/{id} 根据订单ID查询订单详情 分页查询订单列表 GET /order/list 分页查询订单列表，支持按状态和订单编号筛选 取消订单 POST /order/{id}/cancel 取消待处理状态的订单 完成订单 POST /order/{id}/complete 完成待处理状态的订单 接口参数说明分页查询订单列表 (GET /order/list) page (可选, 默认1): 页码，从1开始 size (可选, 默认10): 每页数量 status (可选): 订单状态（PENDING, COMPLETED, CANCELLED） orderNum (可选): 订单编号，支持模糊查询 代码修改 OrderController.java - 添加了4个新的REST接口 OrderService.java - 添加了对应的业务方法 OrderRepository.java - 继承了 JpaSpecificationExecutor 以支持动态查询 3. fake-srm-front 前端项目新增文件servicesapi.ts - API服务层 productApi: 产品相关API listProducts(page, size, name): 获取产品列表 getProduct(id): 获取产品详情 createProduct(data): 创建产品 updateProduct(id, data): 更新产品 deleteProduct(id): 删除产品 deductStock(productId, quantity): 扣减库存 orderApi: 订单相关API listOrders(page, size, status, orderNum): 获取订单列表 getOrder(id): 获取订单详情 createOrder(productId, quantity): 创建订单 cancelOrder(id): 取消订单 completeOrder(id): 完成订单 修改的文件types.ts - TypeScript类型定义 添加了 BackendProduct 和 BackendOrder 接口，用于定义后端返回的数据结构 InventoryView.tsx - 库存管理页面 连接产品查询接口，实时获取产品数据 添加搜索功能，支持按产品名称模糊查询 添加分页功能，支持翻页 连接下单接口，创建订单后自动刷新产品列表 OrdersView.tsx - 订单管理页面 连接订单查询接口，实时获取订单数据 添加搜索功能，支持按订单编号模糊查询 添加状态筛选功能（全部、待处理、已完成、已取消） 添加分页功能，支持翻页 SummaryBar.tsx - 下单汇总栏 连接下单接口，支持批量创建订单 添加加载状态和错误处理 下单成功后自动重置选择状态并刷新产品列表 技术实现细节1. 数据转换前端将后端返回的数据格式转换为前端需要的格式： // 后端数据格式 { productId: number; productName: string; stock: number; price: number; // ...} // 前端数据格式 { id: string; name: string; sku: string; price: number; stock: number; status: ProductStatus;} 2. 分页查询使用 Spring Data JPA 的 Page 对象进行分页查询： Pageable pageable = PageRequest.of(page - 1, size, Sort.by(Sort.Direction.DESC, createdTime)); SpecificationProduct specification = ...; return productRepository.findAll(specification, pageable); 3. 动态查询使用 JPA Specification 实现动态查询条件： SpecificationOrder specification = (root, query, criteriaBuilder) - { ListPredicate predicates = new ArrayList(); if (StringUtils.hasText(status)) { predicates.add(criteriaBuilder.equal(root.get(orderStatus), status)); } if (StringUtils.hasText(orderNum)) { predicates.add(criteriaBuilder.like(root.get(orderNum), % + orderNum + %)); } return criteriaBuilder.and(predicates.toArray(new Predicate[0]));}; 4. 搜索防抖前端使用防抖技术优化搜索体验： useEffect(() = { const timer = setTimeout(() = { setPage(1); // 搜索时重置到第一页 }, 500); return () = clearTimeout(timer);}, [searchKeyword]); 使用说明启动后端服务 启动 Eureka Server 启动 fake-product 服务（默认端口：8082） 启动 fake-order 服务（默认端口：8081） 启动前端项目cd /Users/li/WorkSpace/year26/spring-cloud-demo-26/fake-srm/fake-srm-frontpnpm installpnpm dev``` ### API 地址 - **产品服务**: http://localhost:8082 - **订单服务**: http://localhost:8081 - **前端**: http://localhost:5173 (默认) ## 注意事项 1. **CORS 配置**: 如果前端和后端不在同一个域名下，需要配置 CORS 2. **数据库连接**: 确保数据库服务已启动并配置正确 3. **Eureka 注册**: 确保 Eureka Server 已启动，服务能正常注册 ## 后续优化建议 1. 添加更完善的参数校验 2. 添加单元测试和集成测试 3. 优化前端 UI/UX 4. 添加数据权限控制 5. 添加操作日志记录 6. 优化数据库查询性能（添加索引）","tags":["fake-srm"]},{"title":"问题记录","path":"/2026/01/18/Archive.26/项目/问题记录/","content":"CORS 问题故障排查问题1: No ‘Access-Control-Allow-Origin’ header症状Access to fetch at http://localhost:7999/api/product/list?page=1size=10 from origin http://localhost:3000 has been blocked by CORS policy: Response to preflight request doesnt pass access control check: No Access-Control-Allow-Origin header is present on the requested resource. 原因网关服务没有配置CORS，或者网关服务没有启动。 解决方案 确保网关服务已启动 cd /Users/li/WorkSpace/year26/spring-cloud-demo-26/fake-srm/fake-gateway mvn spring-boot:run ``` 检查网关的CORS配置确认 fake-gateway/src/main/java/com/year26/fakegateway/config/GatewayConfig.java 中有CORS配置。 重启所有服务 cd /Users/li/WorkSpace/year26/spring-cloud-demo-26/fake-srm ./stop-all-services.sh ./start-all-services.sh ``` 问题2: Access-Control-Allow-Origin header contains multiple values症状Access to fetch at http://localhost:7999/api/order/list?page=1size=10status=PENDING from origin http://localhost:3000 has been blocked by CORS policy: The Access-Control-Allow-Origin header contains multiple values http://localhost:3000, http://localhost:3000, but only one is allowed. 原因CORS配置被重复应用了： 网关中配置了CORS 微服务中也配置了CORS 导致响应头中包含了重复的 Access-Control-Allow-Origin 解决方案方式1: 一键修复（推荐）cd /Users/li/WorkSpace/year26/spring-cloud-demo-26/fake-srm./fix-cors-issue.sh 方式2: 手动修复# 1. 停止所有服务 ./stop-all-services.sh # 2. 清理重复的CORS配置 ./clean-cors.sh # 3. 重新编译微服务 cd fake-services/fake-product mvn clean compile cd ../fake-order mvn clean compile cd ../.. # 4. 重新启动所有服务 ./start-all-services.sh 问题3: 前端无法访问网关症状浏览器控制台显示网络错误，无法连接到 http://localhost:7999 原因网关服务没有启动，或者端口被占用。 解决方案 检查网关服务状态 curl http://localhost:7999/actuator/health ``` 检查端口占用 lsof -i :7999 ``` 重启网关服务 cd /Users/li/WorkSpace/year26/spring-cloud-demo-26/fake-srm/fake-gateway mvn spring-boot:run ``` 问题4: 微服务没有注册到Eureka症状网关无法路由到微服务，返回503错误。 原因微服务没有启动，或者没有正确注册到Eureka。 解决方案 检查Eureka状态访问 http://localhost:8000/ 查看已注册的服务 检查微服务日志查看微服务启动日志，确认成功注册到Eureka 重启所有服务 cd /Users/li/WorkSpace/year26/spring-cloud-demo-26/fake-srm ./stop-all-services.sh ./start-all-services.sh ``` 问题5: 前端显示”网络请求失败”症状前端页面显示错误提示：”网络请求失败，请检查网络连接” 原因 网关服务没有启动 微服务没有启动 网络连接问题 解决方案 检查所有服务状态 curl http://localhost:7999/actuator/health curl http://localhost:8002/actuator/health curl http://localhost:8001/actuator/health ``` 查看浏览器控制台打开浏览器开发者工具，查看Network标签页的详细错误信息 重启所有服务 cd /Users/li/WorkSpace/year26/spring-cloud-demo-26/fake-srm ./stop-all-services.sh ./start-all-services.sh ``` 问题6: 前端显示后端错误信息症状前端从右侧滑入红色错误提示框，显示后端返回的错误信息，例如： “订单金额超出限制（最大1999元）” “产品不存在” 说明这是正常行为！错误处理已经正确配置，前端会显示后端返回的具体错误信息。 如何验证 查看错误提示框错误信息会从右侧滑入显示 查看浏览器控制台按 F12 打开开发者工具，查看Console标签页 查看后端日志查看微服务的控制台输出，确认错误原因 快速诊断命令# 1. 检查所有服务状态 curl http://localhost:7999/actuator/health curl http://localhost:8002/actuator/health curl http://localhost:8001/actuator/health # 2. 检查Eureka注册状态 curl http://localhost:8000/ # 3. 测试API（通过网关） curl http://localhost:7999/api/product/list?page=1size=10 # 4. 测试API（直接访问微服务） curl http://localhost:8002/product/list?page=1size=10 # 5. 查看网关日志 tail -f /tmp/gateway.log # 6. 查看微服务日志 tail -f /tmp/fake-product.log tail -f /tmp/fake-order.log 服务端口汇总 服务 端口 访问地址 说明 Eureka Server 8000 http://localhost:8000/ 服务注册中心 Gateway 7999 http://localhost:7999/api 网关（统一入口） fake-product 8002 http://localhost:8002/product/… 产品服务 fake-order 8001 http://localhost:8001/order/… 订单服务 前端 3000 http://localhost:3000 管理界面 架构流程浏览器 (http://localhost:3000) ↓React 前端组件 ↓API 服务层 (services/api.ts) ↓Spring Cloud Gateway (http://localhost:7999/api) ↓CORS 配置（统一处理跨域） ↓路由转发 ↓├─→ fake-product (http://localhost:8002/product/...) └─→ fake-order (http://localhost:8001/order/...) ↓MySQL 数据库 关键配置文件网关CORS配置文件: fake-gateway/src/main/java/com/year26/fakegateway/config/GatewayConfig.java 重要: 微服务中不要配置CORS，避免重复。 前端API配置文件: fake-srm-front/services/api.ts const API_BASE_URL = http://localhost:7999/api; // fake-order 服务地址 const PRODUCT_API_URL = http://localhost:7999/api; // fake-product 服务地址 常用脚本# 一键启动所有服务 ./start-all-services.sh # 一键停止所有服务 ./stop-all-services.sh # 一键修复CORS问题 ./fix-cors-issue.sh # 清理重复的CORS配置 ./clean-cors.sh 参考文档 CORS_FIX.md - CORS解决方案 ERROR_HANDLING.md - 错误处理改进 QUICK_START.md - 快速启动指南 README.md - 完整项目文档","tags":["日常记录","项目","fake-srm"],"categories":["java"]},{"title":"Arch Linux安装","path":"/2024/07/03/归档/Arch Linux/","content":"很详细的链接 制作U盘使用 Rufus 下载链接v4.5 使用 archInstall 安装archinstall# 设置一下即可# 必选：设置硬盘、root密码 网络！！ 选第二个# 可选：时区 启用SSH如果你安装完系统后无法通过 SSH 远程登录，可能是由于 SSH 服务未安装、未启动或防火墙配置问题。以下是一些可能的解决方法： 1. 检查并安装 OpenSSH确保 OpenSSH 已安装： 安装 sshd sudo pacman -S openssh 2. 启动并启用 SSH 服务启动 SSH 服务： sudo systemctl start sshd 启用 SSH 服务，使其在系统启动时自动运行： sudo systemctl enable sshd 3. 检查防火墙设置如果你启用了防火墙，需要确保允许 SSH 端口（默认端口 22）的连接。例如，如果你使用 ufw 作为防火墙，可以使用以下命令： sudo ufw allow ssh 如果使用 iptables，可以使用以下命令： sudo iptables -A INPUT -p tcp --dport 22 -j ACCEPT 4. 检查 SSH 配置文件检查 SSH 配置文件 /etc/ssh/sshd_config 是否正确配置。例如，确保以下行没有被注释掉（去掉前面的 #）： Port 22 PermitRootLogin yes # 如果你需要以 root 登录 PasswordAuthentication yes # 如果你使用密码登录 编辑完配置文件后，重新启动 SSH 服务以应用更改： sudo systemctl restart sshd 5. 检查网络连接确保你的计算机在网络中是可访问的，可以通过以下命令查看 IP 地址： ip addr show 确保你使用的是正确的 IP 地址和端口连接。 6. 检查 SSH 客户端输出如果仍然无法连接，使用 SSH 客户端连接时查看详细输出，以获取更多调试信息。例如，在 Linux 或 macOS 上，可以使用以下命令： ssh -v user@hostname 这个命令会显示详细的连接过程，有助于找出问题所在。 7. 确保 SSH 服务在运行使用以下命令检查 SSH 服务状态： sudo systemctl status sshd 确保显示的状态为 active (running)。如果不是，请检查日志文件以获取更多信息： sudo journalctl -u sshd 8. 确保主机名解析正常确保你连接的主机名可以正确解析。如果你使用主机名连接，尝试改用 IP 地址连接，以排除 DNS 解析问题。 9. 确保网络没有阻塞 SSH 端口某些网络环境（如企业网络或公共 WiFi）可能会阻止 SSH 端口的流量。尝试在不同的网络环境中进行连接测试。 10. 检查用户权限确保你使用的用户在目标机器上存在，并且具有适当的权限。你可以使用以下命令查看当前用户列表： cat /etc/passwd 确保用户存在并且可以登录。 启用并启动显示管理器假设你选择了 GDM 作为显示管理器： sudo systemctl enable gdmsudo systemctl start gdm 如果选择了 SDDM： sudo systemctl enable sddmsudo systemctl start sddm 安装缺失的软件包: sudo pacman -S gnome # 安装 GNOMEsudo pacman -S plasma # 安装 KDE Plasmasudo pacman -S gdm # 安装 GDMsudo pacman -S sddm # 安装 SDDM 到这里 系统就算安装完成了 安装Hyprland 报错中需要创建一个非root用户 给sudo权限 需要安装编辑器 vim或者nano","categories":["杂项"]},{"title":"拉勾训练营5期","path":"/2024/03/20/归档/AA/","content":"JDBC需要手动引入Mysql的jar包 public class JDBCDemo public static void main(String[] args) throws ClassNotFoundException, SQLException // 加载驱动 Class.forName(com.mysql.jdbc.Driver); // 建立连接 Connection connection = DriverManager.getConnection(jdbc:mysql://localhost:3306/test, root, 12345678); // 定义SQL语句 String sql = select * from db_account where id = 4; // 获取预处理prepareStatement PreparedStatement preparedStatement = connection.prepareStatement(sql); // 设置参数 // preparedStatement.setInt(1, 4); // 执行查询 得到结果 ResultSet resultSet = preparedStatement.executeQuery(sql); // 处理结果 while (resultSet.next()) System.out.println(id: + resultSet.getInt(id)); System.out.println(email: + resultSet.getString(email)); 为什么要有ORM框架 驱动uri、数据库地址、账号密码，硬编码，不灵活 重复的建立连接 处理结果集麻烦 自定义创建两个工程 IPersistence、IPersistence_Test IPersistence_Test 使用端IPersistence 自定义框架根据配置文件的路径，将配置文件加载成字节输入流，存储在内存中Resources.getResourceAsStream(String path) 获得sqlSession对象 sqlSession通过sqlSessionFatory.open获得sqlSessionFatory通过sqlSessionFatoryBuilder.build(configuration)获得\tbuild需要获取数据库信息 创建SqlSessionFactoryBuilder 通过SqlSessionFatoryBuilder.build()获得SqlSessionFatory 通过DefaultSqlSessionFactory.open()获得SqlSession 创建DefaultSqlSession 实现基础方法 selectAll，selectList 执行JDBC逻辑 创建Executor、Executor实现类，执行CURD 处理返回结果 通过反射或内省+SQLID上的resultType全路径，处理返参 问题1：数据库类型与实体类型不一致 Exception in thread main java.lang.IllegalArgumentException: argument type mismatch at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) 问题2：数据库版本与驱动版本不一致 无法获取数据库连接，报错信息和获取连接方法有关 使用C3P0连接池是报错： java.sql.SQLException: Connections could not be acquired from the underlying database! 使用DriverManager直接连接时： Client does not support authentication protocol requested by server; consider upgrading MySQL client 持久层实现 通过mapper接口，数据库的交互 SqlSession中创建一个getMapper方法，获取mapper的代理类，执行被代理类的方法 Mybatis概念基于ORM的半自动轻量级持久层框架。 缓存底层数据结构： 就是一个HashMap。 先去缓存中查，然后到数据库中，如果缓存中有，就直接返回，不再去数据库查询。 一级缓存-SqlSession级别是否启用： 默认开启 cacheKey: org.apache.ibatis.executor.BaseExecutor#createCacheKey 增删改操作时，会刷新缓存（全部缓存） 二级缓存-NameSpace级别是否启用： 默认关闭，需要手动开启 [I] 二级缓存是在SqlSession事务提交时写入的 [!] 二级缓存在分布式的情况下，可能有问题。 @Test public void secondLevelCacheTest() throws IOException InputStream inputStream = Resources.getResourceAsStream(sqlMapConfig.xml); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); SqlSession sqlSession1 = sqlSessionFactory.openSession(); SqlSession sqlSession2 = sqlSessionFactory.openSession(); IUserMapper mapper1 = sqlSession1.getMapper(IUserMapper.class); IUserMapper mapper2 = sqlSession2.getMapper(IUserMapper.class); User user1 = mapper1.selectByPrimaryKey(1); // 这样是不会查到二级缓存的，需要事务提交或者关闭后才可以 // sqlSession1.commit(); // sqlSession1.close(); User user2 = mapper2.selectByPrimaryKey(1); System.out.println(user1==user2); 结论： 节省了数据库的交互 Q: @Test public void firstLevelCacheTest3() throws IOException InputStream inputStream = Resources.getResourceAsStream(sqlMapConfig.xml); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); SqlSession sqlSession = sqlSessionFactory.openSession(true); SqlSession sqlSession2 = sqlSessionFactory.openSession(true); IUserMapper mapper = sqlSession.getMapper(IUserMapper.class); IUserMapper mapper2 = sqlSession2.getMapper(IUserMapper.class); User user = mapper.selectByPrimaryKey(1); System.out.println(user); mapper2.updateUserByPrimaryKey(new User(1, gaga)); User user1 = mapper.selectByPrimaryKey(1); System.out.println(user1); System.out.println(user == user1: + (user == user1)); sqlSession.close(); sqlSession2.close(); // Userid=1, name=haha// Userid=1, name=haha// user == user1: true 插件 [I] 需要在SqlMapConfig.xml中启用 plugins plugin interceptor=com.li.plugin.MyPlugin/plugin /plugins 分页插件拦截器实现 [*] com.github.pagehelper.PageHelper [*] 入口：com.github.pagehelper.SqlUtil#_processPage [*] 增加COUNTSQL：com.github.pagehelper.MSUtils#processCountMappedStatement(MappedStatement ms, SqlSource sqlSource, Object[] args) countSql返回结果大于0时，执行分页，将总数设置到page对象中 替换参数 com.github.pagehelper.MSUtils#processPageMappedStatement(MappedStatement ms, SqlSource sqlSource, Page page, Object[] args) 创建新的mapperStatement，执行分页SQL 设置分页参数：com.github.pagehelper.MSUtils#setPageParameter 通用Mapper架构原理架构设计接口 通过sqlSession.method(statementId)或者Mapper代理类调用方法，执行主句的增删改查。 调用接口修改配置信息等。 数据处理 请求参数处理(@Param)：ParameterHandler SQL解析(处理占位符、Mapper标签)：SqlSource SQL执行(JDBC)：Executor 返回结果处理(类型转换等)：ResultSetHandler 框架支撑 事务管理 连接池管理 缓存机制 主要构件 SqlSession：session表示与数据库的连接 Executor：执行器 StatementHandler： ParameterHandler： BoundSql： ResultSetHander： TypeHandler：数据库类型与JavaBean类型的转换 MappedStatement： SqlSource： 总体流程 SqlSessionFactoryBuilder获取SqlSessionFactory SqlSessionFactory.openSession获取SqlSession对象 通过getMapper获取Mapper代理对象 执行代理Mapper的方法 Executor Mybatis的执行器 StatementHandler 与JDBC Statement的交互 ParameterHandler 处理方法中携带的参数，拼接到Sql中 执行JDBC流程（加载驱动、建立连接、定义Sql、获取预处理对象、处理参数、执行、处理返回结果） 处理Java类型和数据库类型映射 源码分析getMapper扫描@Mapper注解、从sqlMapConfigXml中读取Mapper包名，或者Mapper接口，将其存到MapperRegistry.knownMappers中 MapClass?, MapperProxyFactory? knownMappers = new HashMap(); value值存储的是一个工厂类，有个ClassT的变量，和newInstance(SqlSession sqlSession)方法，用于给Mapper创建代理对象 [*] Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[]{mapperInterface}, mapperProxy); // JDK动态代理 生成代理对象/** * loader 类加载器 * interfaces 代理对象类型 * h InvocationHandler接口的实现类，需要实现invoke方法 */newProxyInstance(ClassLoader loader, Class?[] interfaces, InvocationHandler h) 二级缓存 [*] org.apache.ibatis.executor.CachingExecutor#flushCacheIfRequired [*] org.apache.ibatis.builder.MapperBuilderAssistant#addMappedStatement(java.lang.String, org.apache.ibatis.mapping.SqlSource, org.apache.ibatis.mapping.StatementType, org.apache.ibatis.mapping.SqlCommandType, java.lang.Integer, java.lang.Integer, java.lang.String, java.lang.Class?, java.lang.String, java.lang.Class?, org.apache.ibatis.mapping.ResultSetType, boolean, boolean, boolean, org.apache.ibatis.executor.keygen.KeyGenerator, java.lang.String, java.lang.String, java.lang.String, org.apache.ibatis.scripting.LanguageDriver, java.lang.String) [?] 二级缓存需要再事务提交后或者关闭后生效 org.apache.ibatis.executor.CachingExecutor#query(org.apache.ibatis.mapping.MappedStatement, java.lang.Object, org.apache.ibatis.session.RowBounds, org.apache.ibatis.session.ResultHandler, org.apache.ibatis.cache.CacheKey, org.apache.ibatis.mapping.BoundSql) 使用CachingExecutor.query() 清空缓存 // 从二级缓存中，获取结果ListE list = (ListE) tcm.getObject(cache, key);getObject = TransactionalCacheManager.transactionalCaches.delegate中获取缓存// 如果没有取到 去一级缓存中取// 缓存查询结果 tcm.putObject(cache, key, list);= 实际是存到了entriesToAddOnCommit中transactionalCaches中有一个：private final MapObject, Object entriesToAddOnCommit;public void putObject(Cache cache, CacheKey key, Object value) // 存入TransactionalCache的缓存中 getTransactionalCache(cache).putObject(key, value); = entriesToAddOnCommit.put(key, object);transactionalCaches中有一个flushPendingEntries方法，该方法会在事务提交、关闭时会调用，这也是二级缓存需要在事务提交或者关闭后才能查到的原因// 将 entriesToAddOnCommit、entriesMissedInCache 刷入 delegate(cache) 中 flushPendingEntries(); [?] 二级缓存为什么使用的是CachingExecutor sqlSessionFactory.openSession()时会new Executororg.apache.ibatis.session.defaults.DefaultSqlSessionFactory#openSessionFromDataSource org.apache.ibatis.session.Configuration#newExecutor(org.apache.ibatis.transaction.Transaction, org.apache.ibatis.session.ExecutorType)","tags":["学习"]},{"title":"Hello Algo","path":"/2023/12/25/归档/Algo/","content":"二分搜索、插入排序、贪心 迭代、递归 # n = 1 时T(n) = 3+2n = 3n+2n = 5nT(n) = c * f(n)T(n) = O(f(n)) KMP求next[]next[]：找出一个以0下标(必须0下标)开始，以j-1下标结束的两个相同子串=next[j-1] = k-1 哈哈 k x j 下标k 0 1 2 3 4 5 6 7 8 9 10 11 12 13数组p a b a b c a b c d a b c d enext数组 -1 0 0 1 2 0 1 2 0 0 1 2 0 0j++下标0 = a当 j = 3:\t下标j-1=2 - a 可以找到 a、aba、a 但是aba不满足条件 = 1当 j = 4:\t下标j-1=3 - b 可以找到 ab、abab 但是abab不满足条件 = 2当 j = 5:\t下标j-1=4 - c 可以找到 ababc 不满足条件 = 0哈哈 k x j 下标k 0 1 2 3 4 5 6 7 8 9 10 11 12 13数组p a b a b c a b a d a b c d enext数组 -1 0 0 1 2 0 1 2 3 0 1 2 0 0已知条件：以0下标(必须0下标)开始，以j-1下标结束的两个相同子串p[0]..p[k-1] = p[x]..p[j-1]得出：= k-1-0 = j-1-x = k = j-x= x = j-k== p[0]..p[k-1] = p[j-k]..p[j-1]假设：p[k] = p[j]= p[0]..p[k] = p[j-k]..p[j]所以 next[j] = k k-1 = next[j-1]p[0]..p[k-1] = p[x]..p[j-1]假设：p[k] = p[j]p[0]..p[k-1]p[k] = p[x]..p[j-1]p[j]p[0]..p[k] = p[j-k]..p[j]k = next[j] 数组优点： 空间效率高 支持随机访问 缓存局部性？缺点： 插入与删除效率低 长度不可变 空间浪费典型应用： 随机访问 排序、搜索 查找表 机器学习 数据结构实现 链表数组 vs 链表 存储方式 容量扩展 内存效率 访问元素 添加元素 删除元素","tags":["学习"]},{"title":"测试","path":"/2023/10/27/归档/文章名称/","content":"if(Objects.nonNull(prLine)Objects.nonNull(prLine.getPurchaseAgentId())) poHeaderDetailDTO.setAgentId(prLine.getPurchaseAgentId());"},{"title":"Git","path":"/2023/06/17/归档/GIT/","content":"Gitee Go流水线# 官方文档https://blog.gitee.com/2022/11/23/pipeline/ 前端CI手动创建流水线，选择部署分之，需要手动增加部署阶段 添加部署阶段 点击发布后面的＋ 添加新阶段 点击部署 点击主机部署 选择执行主机组（如果没有就先去添加主机，选择 填写部署脚本，前端项目把上游构建的包，解压到服务器指定路径即可 # 功能：部署脚本会在部署主机组的每台机器上执行# 使用场景：先将制品包解压缩到指定目录中，再执行启动脚本deploy.sh，脚本示例地址：https://gitee.com/gitee-go/spring-boot-maven-deploy-case/blob/master/deploy.sh# mkdir -p /home/admin/app# tar zxvf ~/gitee_go/deploy/output.tar.gz -C /home/admin/app# sh /home/admin/app/deploy.sh restart# 如果你是php之类的无需制品包的制品方式，可以使用 git clone 或者 git pull 将源代码更新到服务器，再执行其他命令# git clone ***@***.gittar zxvf ~/gitee_go/deploy/output.tar.gz -C /home/ubuntu 添加主机 点击新建主机组 选择新建类型（以腾讯云为例），填写基本信息（以Linux为例），点击确认 添加主机 点击添加Linux主机，选择通过命令行逐台添加， 复制命令到目标腾讯云主机命令行 刷新页面即可见关联服务器信息 后端CI部署脚本cd ~/gitee_go/deploy/lstar -zxf API.tar.gzcd targetpid=`ps -ef|grep smart-admin-api-1.0.0|grep -v grep|awk print $2`if [ $pid ]thensudo kill -15 $pid fisudo nohup /usr/lib/jvm/jdk1.8.0_341/bin/java -jar smart-admin-api-1.0.0.jar /home/ubuntu/log.log cd ~/gitee_go/deploy/lstar -zxf API.tar.gzcd targetpid=`ps -ef|grep smart-admin-api-1.0.0|grep -v grep|awk print $2`if [ $pid ]thensudo kill -15 $pid fisudo nohup /usr/lib/jvm/jdk1.8.0_341/bin/java -jar smart-admin-api-1.0.0.jar /home/ubuntu/log.log 21 开源项目AI PPT输入一句话，它就能让 AI 自动为你生成一款美观的 PPT。 开源地址：https://github.com/allweonedev/presentation-ai AI 提示词大合集*本周斩获 Star 数：1029* 这个开源项目没啥好说的，就是一箩筐好用的 AI 提示词合集，复制粘贴即用。 应该是 Github 上受关注程度最高的，目前已经获得了 122K+ 的 Star。 涵盖的场景很多，比如编程、教育、营销等等，而且有专为不同 AI 适配的更合适提示词（如 Claude、Gemini、GitHub Copliot 等） 开源地址：https://github.com/f/awesome-chatgpt-prompts Ventoy：Ventoy 是*一个「一劳永逸」的多系统启动U盘工具*，在 GitHub 上竟然获得了 67K 的 Star。 它的核心功能是将普通 U 盘变成“系统仓库”。用户只需首次安装 Ventoy，之后直接拖入多个系统镜像文件（如 Windows、Linux 的 ISO文件）即可。 而且你不需要反复格式化 U 盘，支持自由增删文件，且 U 盘仍可作为普通存储盘使用。 开源地址：https://github.com/ventoy/Ventoy moodiary：一款 Flutter 构建的开源跨平台日记应用。 这是一款完全开源、颜值在线的日记软件。它支持多种形式的文本编辑和多媒体附件，同时提供密码保护、生物识别解锁、足迹地图、智能助手、同步与备份等功能，兼容 Android、iOS、Windows、macOS 和 Linux 系统。来自 @云烨 的分享 地址：github.comZhuJHuamoodiary Pluvia：Android 上的非官方 Steam 客户端这是一款专为 Android 设计的轻量级、非官方 Steam 客户端，可以在移动设备上浏览、下载并运行无 DRM（数字版权管理）的 Steam 游戏，支持 Steam 云存档和好友列表等功能。 地址：github.comoxters168Pluvia 免费开源的 AI 图像增强神器 Upscayl 是免费开源的 AI 图像增强工具，能够利用先进的 AI 模型将低分辨率图像放大并提升质量，让你的老照片焕发新生。在如下场景做的很好： 放大老照片 提升图像质量 修复损坏的图像 它完全免费且开源，支持 Linux、macOS 和 Windows 系统，方便你在任何平台上使用。 开源地址：https://github.com/upscayl/upscayl 并且提供多种 AI 模型，包括 Real-ESRGAN、Waifu2x 和 SwinIR 等，可以根据不同的图像类型和需求选择合适的模型。支持批量处理，你可以一次性放大多个图像，节省时间和精力。 电子书转有声书的工具：ebook2audiobook 主语言：Python，Star：2.7k，周增长：1.4k 这款开源工具可以轻松将电子书转换为有声书，支持多种常见格式，如 EPUB、MOBI、PDF 等。它通过 calibre 提取电子书文本，并运用语音合成技术（Text-to-Speech），能够生成包含章节和元数据的有声书，支持包括中文在内的 1000 多种语言。 GitHub 地址→github.comDrewThomassonebook2audiobook MediaGo是一个用Electron+Antd+Vite打造的开源视频下载工具。专门针对m3u8格式的流媒体视频进行下载。这个工具不仅支持视频下载，还能处理B站视频下载，功能强大到让你惊呼“还有这种操作”！目前已经在GitHub上收获了超过4.7k的星星，可见其受欢迎程度。 高颜值 Windows 系统桌面Seelen UI 是一款专为 Windows 10 和 11 用户设计的桌面环境，旨在通过高度自定义和提升生产力来优化您的桌面体验。它无缝集成于系统，提供多种功能，允许您根据个人喜好定制桌面，并优化工作流程。 **个性化桌面：**Seelen UI 让您可以根据自己的风格和需求调整桌面。您可以自定义菜单、小部件等元素，打造最适合您的工作空间。 **平铺式窗口管理器：**Seelen UI 自动排列窗口，支持多任务处理，使工作流程更加流畅。 **音乐体验：**内置的媒体模块兼容大多数音乐播放器，您可以随时暂停、恢复和跳过曲目，而无需打开其他窗口。 开源地址：https://github.com/eythaann/Seelen-UI AI 驱动的简历匹配分析工具：Reactive-Resume 主语言：Python，Star：5.1k，周增长：100 这是一个基于 AI 的免费开源工具，可用于提升简历质量。它通过解析简历和职位描述，模拟求职者跟踪系统（ATS），并利用 FastEmbed 技术计算简历与职位描述的匹配程度，最后给出简历的修改建议，从而提高简历通过自动筛选系统的概率。 GitHub 地址→github.comsrbhrResume-Matcher 隐藏私人文件和应用的 Android 工具：Amarok-Hider 主语言：Java，Star：1.7k 这是一款用于隐藏文件和应用的隐私保护工具，简单易用且界面美观。它通过混淆文件名来实现文件隐藏，而非加密操作，支持免 Root 一键隐藏应用、浮动按钮和快捷开关等功能。 GitHub 地址→github.comdeltazefiroAmarok-Hider spotube：开源的 Spotify 客户端。该项目是基于 Flutter 开发的 Spotify 客户端，完全免费且无广告。它使用 Spotify、JioSaavn 和 YouTube 作为音乐源，用户无需登录即可自由下载音乐，支持桌面和移动设备。 地址：github.comKRTirthospotube frpc-desktop：跨平台的 frp 桌面客户端。该项目是内网穿透工具 frp 的桌面客户端，更方便地实现内网穿透。它开箱即用、界面清爽，支持开机启动、多用户、配置导入和导出等功能，适用于 Windows、Linux 和 macOS 平台。来自 @蠢🐷 的分享 地址：github.comluckjiaweifrpc-desktop 根据菜谱生成图片、根据毛坯设计房间开源地址：https://github.com/Nutlope/roomGPT开源地址：https://github.com/Nutlope/picMenu Rust 驱动的 HTTP 压测工具：oha 主语言：Rust 这是一个用 Rust 开发的 HTTP 请求压测工具，它操作简单、带 TUI 动画界面，支持生成请求延迟、吞吐量等指标的报告，以及动态 URL 和更灵活的请求间隔（burst-delay）等功能。 项目详情→hellogithub.comrepository98b46ea0d7d84f4c944d0a35a9d2d140 免费的 API 学习平台：apihub 主语言：JavaScript，Star：6.4k，周增长：1k 这是一个功能齐全的 API 学习平台，支持多种编程语言（Node.js、Python、Go 等）的 API 开发和学习。它免费提供丰富的 API 集合，涉及社交媒体集成、支付网关、物联网设备连接和机器学习等领域。你可以在该平台获取 API 开发的各类资源，包括详细教程、接口文档、代码示例和在线尝试。除了使用在线服务外，强烈推荐用户选择本地部署，以避免官网服务每两小时重置数据的限制。 GitHub 地址→github.comhiteshchoudharyapihub 轻松启动本地 HTTPS 代理的工具：ophiuchi-desktop 主语言：TypeScript，Star：928 这是一个本地 HTTPS 代理服务器管理工具，无需复杂配置即可轻松设置本地 HTTPS 代理。它使用 Docker 作为后端，并采用 Tauri 编写 GUI 界面，极大地简化了本地 HTTPS 代理的配置流程。不过，使用前需确保本机已安装 Docker。 GitHub 地址→github.comapilylabsophiuchi-desktop 一个鼠标操作多个电脑Deskflow 帮助用户在多台计算机（包括 Windows、macOS 和 Linux）之间共享键盘和鼠标，就像软件版的 KVM（但不包含视频功能）。 它支持 TLS 加密、Wayland 显示协议，并且具备剪贴板共享功能。作为社区驱动项目，Deskflow 鼓励用户参与开发和改进，同时与类似的开源项目合作，如 Synergy 和 Input Leap。用户可以通过安装包或源码编译来使用该软件。 开源地址：https://github.com/deskflow/deskflow beszel：轻量级高颜值的 Docker 监控平台。这是一个轻量级的服务器监控平台，包括 Docker 统计、历史数据和警报功能。它拥有友好的 Web 界面，配置简单、开箱即用，支持自动备份、多用户、OAuth 认证和 API 访问等功能。 地址：github.comhenrygdbeszel mame：开源的街机模拟器。这是一款支持海量街机游戏的模拟器。它通过模拟多种硬件平台，实现了在电脑上运行各种复古软件的功能。不仅支持街机，还有老式电脑和游戏机。 地址：github.commamedevmame shadPS4：开源的 PS4 模拟器。这是用 C++ 编写的 PlayStation 4（PS4）模拟器，支持在 Windows、Linux 和 macOS 系统上玩 PS4 游戏。虽然项目仍处于早期开发阶段，能运行的游戏有限，但最新版已经能够成功运行《血源诅咒》和《黑暗之魂II》等游戏。 地址：github.comshadps4-emushadPS4 索尼 PS1 模拟器“开源”项目Duckstation是由stenzek开发的索尼PS 模拟器，适用于 x86-64AArch32AArch64RV64。 这开源项目专注于可玩性，速度，目标是尽可能让相对低端的设备也能玩 PS 游戏。默认设置即可运行所有支持的游戏，仅有部分兼容性问题。 “开源”地址：https://github.com/stenzek/duckstation omakub：精美的 Ubuntu 配置方案。该项目可以将全新的 Ubuntu 24.04 系统配置成美观、功能齐全、适合 Web 开发的系统。只需简单的一条命令，即可拥有配置好的 GNOME 桌面环境、窗口管理工具、Alacritty 终端、Neovim 和 VSCode 编辑器等应用，还会将 Chrome 设置成默认浏览器。 地址：github.combasecampomakub Oshi获取操作系统和硬件信息的 Java 库。获取操作系统和硬件信息的 Java 库。这是一个基于 JNA 实现的获取本机操作系统和硬件信息的库，支持操作系统版本、进程、内存、 CPU 使用率、磁盘和分区、设备、传感器等信息。 PlayEdu一款 Java 写的内部培训系统。一款 Java 写的内部培训系统。这是一款基于 SpringBoot+React 开发而成的视频培训系统，它界面清爽、交互流畅，支持上传资源、创建部门、添加学员、指派课程等功能，可用于企业和机构搭建内部培训平台。 Holer 一个将局域网中的应用映射到公网访问的端口映射软件，支持转发基于 TCP 协议的报文。一个将局域网中的应用映射到公网访问的端口映射软件，支持转发基于 TCP 协议的报文。内网穿透工具，包含 Web 后台管理系统。用到的技术如下：- 服务端采用 SpringBoot 和 Netty 实现- 客户端采用 Java Netty 和 Go 语言实现 SoloPo一个不需要连接电脑、非侵入式的 Android 自动化工具。一个不需要连接电脑、非侵入式的 Android 自动化工具。公测版拥有录制回放、性能测试、一机多控三项主要功能，能为测试开发人员节省宝贵时间。安卓版本多、终端型号多，一个成熟安卓应用的上线需要进行大量测试，而很多测试都是属于重复操作，通过此工具可以极大简化测试人员的工作量 Hitomi Hitomi-Downloader 知名下载工具本周 star 增长数：400+，主语言：Python Hitomi-Downloader 知名下载工具，只需要一个 url 就能下载对应的图片、视频、音频。部分特性： 简洁的用户界面 支持下载加速，也支持限速 支持单任务由 24 个线程 支持多种下载方式 Python 搞定 UI：nicegui本周 star 增长数：850+，主语言：Python、JavaScript New 用 Python 搞定 Web UI，有了它，你可以用 Python 创建按钮、对话框、Markdown 文件、3D 场景。 GitHub 地址→https://github.com/zauberzeug/nicegui 炫酷的 Windows 终端软件：FluentTerminal主语言：C# 基于 UWP 的 Windows 终端应用，拥有强大的自定义主题模块，能够轻松定制出风格各异的主题。提供了中文选项，支持多窗口、SSH 和搜索等功能。 HG 评价地址→https://hellogithub.com/repository/352150f3034742cbbf67d301a86973ca AI 生图：ControlNet主语言：Python New 上周线稿上色的 style2paints 在 ControlNet 面前可能只是个弟弟。ControlNet 是一种通过添加额外条件来控制扩散模型的神经网络结构。为什么说 style2paints 是个弟弟呢？这是 ControlNet 的社生成效果图，从线稿到成品，一句话搞点。 GitHub 地址→https://github.com/lllyasviel/ControlNet 1Panel[1Panel Log]: 1Panel 服务启动成功![1Panel Log]:[1Panel Log]: =================感谢您的耐心等待，安装已经完成==================[1Panel Log]:[1Panel Log]: 请用浏览器访问面板:[1Panel Log]: 面板地址: http://$LOCAL_IP:29252/821d637d70[1Panel Log]: 用户名称: e0ae9ef986[1Panel Log]: 用户密码: zhang...1997[1Panel Log]:[1Panel Log]: 项目官网: https://1panel.cn[1Panel Log]: 项目文档: https://1panel.cn/docs[1Panel Log]: 代码仓库: https://github.com/1Panel-dev/1Panel[1Panel Log]:[1Panel Log]: 如果使用的是云服务器，请至安全组开放 29252 端口[1Panel Log]:[1Panel Log]: ================================================================ Nezha 国产的轻量级服务器监控工具。这是一款名为“哪吒”的服务器监控面板，它安装简单、开箱即用，支持监控多个服务器的系统状态、SSL 证书状态、报警通知、流量监控、设置定时任务等功能，适用于 Linux、Windows、macOS、OpenWRT 等主流系统。 Deskreen：将任何屏幕变成你的扩展显示器我们经常需要在多个设备之间切换工作，但有时候，如果能将手机或平板变成电脑的第二屏幕，那将大大提高工作效率。 Deskreen，一个开源项目，正是为此而生！这是一个简单而强大的工具，它允许你将任何带有网络浏览器的设备变成电脑的第二屏幕。 无论是为了扩展你的工作空间，还是为了在大屏幕上展示你的演示文稿，Deskreen 都能轻松实现。 开源地址：https://github.com/pavlobu/deskreen Etcher 简单易用的 USBSD 启动盘制作工具。该项目可以将操作系统镜像烧录进 SD 卡或 USB 设备，可用于制作可启动、便携式的操作系统。它拥有友好的操作界面，仅需 3 步就能完成 USB 启动盘制作，适用于 Linux、macOS 和 Windows 10 及更高版本。 MoneyPrinterTurbo：一键生成短视频的 AI 工具。该项目是基于大模型服务的 AI 视频生成工具，只需要提供一个主题或关键字，就可以自动生成高清的短视频。它拥有简单易用的 Web 界面，支持批量生成、设置视频时长和横竖屏尺寸等功能。来自 @jolahua 的分享 地址：github.comharry0703MoneyPrinterTurbo Omost ：极简提示词的文生图工具。该项目基于 LLM 的编程能力帮用户自动完善文生图的提示词，可以根据用户输入的简短提示词生成高质量的图片，还支持图片局部修改等功能，比如将图片中的龙变成恐龙，极大地降低了编写文生图的门槛，无需复杂的提示词即可生成满意的图片。 地址：github.comlllyasvielOmost Scrapegraph-ai ：基于 AI 的 Python 爬虫。这是一个由 AI 驱动的 Python 爬虫库，它借助 LLM 的能力，可以根据提示词自动抓取目标网站的数据。 smart_scraper_graph = SmartScraperGraph( prompt=List me all the projects with their descriptions, source=目标网站, config=graph_config ) result = smart_scraper_graph.run() print(result) 地址：github.comVinciGit00Scrapegraph-ai 全平台通用的换源工具：chsrc 主语言：C 该项目能够为常见的 Linux 发行版、编程语言和软件切换至国内镜像源，操作简单仅需一条命令。它采用 C 语言编写，具有高效和轻量级的特点，支持测速、多平台以及项目级换源等功能，适用于优化下载速度或解决源受限的场景。 项目详情→hellogithub.comrepository7666ba91e01e4a59be5809b02d9e8ff6 免费的可视化 Web 页面构建平台：GrapesJS 主语言：TypeScript 该项目通过直观的可视化界面，让用户能够通过拖拽的方式，快速设计和构建网站的 HTML 模板。它所见即所得、移动端适配，适用于官网、新闻和 CMS 等类型的网站。 项目详情→hellogithub.comrepository572e31f5fc7541efb19c16d331796edf 轻量级的 AI 证件照制作工具：HivisionIDPhotos 主语言：Python，Star：1.9k，周增长：1.5k 这是一款简单易用的 AI 证件照制作工具，能够生成标准证件照和六寸排版照。它提供了简洁的 Web 界面和 API 服务，即使在没有 GPU 的电脑上也能够运行，支持抠图、尺寸调整和自定义底色等功能。 GitHub 地址→github.comZeyi-LinHivisionIDPhotos Windows 激活：Microsoft-Activation-Scripts本周 star 增长数：1,100+ 有了 Microsoft-Activation-Scripts，激活 Windows 和 Office 不再是问题。它注重开源、减少反病毒软件的检测，这个用到 HWID、Ohook、KMS38、在线 KMS 激活方法的工具，一定能帮你解决 Windows 的激活问题。 GitHub 地址→github.commassgravelMicrosoft-Activation-Scripts source-code-hunter：Spring 全家桶源码解读。该项目提供了一系列互联网主流框架和中间件的源码讲解，包括 Spring 全家桶、Mybatis、Netty、Dubbo 等框架。 地址：https://github.com/doocs/source-code-hunter 免费的 AI 图像升级器：Upscaler 主语言：TypeScript，Star：25k，周增长：1k 这是一款通过 AI 算法提高图像分辨率（超级分辨率，简称超分）的桌面工具，它免费、开源、无需联网、开箱即用，安装包大概 200+MB，需要有 GPU 的机器才能运行，适用于 Windows、Linux 和 macOS 系统。 GitHub 地址→github.comupscaylupscayl 在线的数据库设计工具：DrawDB 主语言：JavaScript，Star：4.7k，周增长：3.8k 这个开源项目是一个免费、简单、强大的数据库实体关系（DBER）在线编辑器，无需注册即可直接在浏览器中使用。它提供了直观、可视化的操作界面，用户通过点击即可构建数据库表和导出建表语句，还可以导入建表语句，实现可视化编辑、错误检查等。支持 MySQL、PostgreSQL、SQLite、MariaDB、SQL Server 共 5 种常用的关系数据库。 GitHub 地址→github.comdrawdb-iodrawdb WingetUI：带界面的 Windows 包管理器。该项目是一个为 Windows 常用的命令行包管理工具设计的用户界面，如 Winget、Scoop、Pip、NPM、.NET Tool 等。它的界面友好、设计美观、支持中文，通过它你可以轻松下载、安装、更新和卸载包管理器上发布的任何软件以及其它日常应用，如浏览器、PDF 阅读器等。 地址：github.commarticlimentWingetUI freeze：生成代码图片的终端工具。该项目可以将代码片段和终端输出，转换成 PNG、SVG 和 WebP 格式的图片，它采用 Go 语言开发，特点是安装简单和易于使用，支持一条命令生成图片，也可以通过交互模式生成定制的图片。 # macOS or Linux brew install charmbracelet/tap/freeze # Arch Linux (btw) pacman -S freeze # Nix nix-env -iA nixpkgs.charm-freeze 地址：github.comcharmbraceletfreeze CompreFace：免费、开源的人脸识别系统。该项目提供了用于人脸识别、检测、验证、头部姿势检测、性别和年龄识别的 REST API 服务，不用懂机器学习就能轻松集成到任何系统中。它后端采用 Java 编写，人脸识别是基于 FaceNet 和 InsightFace 实现，同时支持 Docker 部署。 地址：github.comexadel-incCompreFace fdroidclient：免费、开源的 Android 应用商店。该项目是 F-Droid 的 Android 客户端，专门收集各类开源安卓软件（FOSS）的应用商店。它里面大部分是免费且无广告的应用，如遇到资源加载慢的情况，可通过设置镜像源解决。 地址：github.comf-droidfdroidclient tailwind-landing-page-template：免费、开源的落地页模板。该项目是基于 TailwindCSS、React 和 Next.js 构建的落地页模板，它界面美观、代码简单、设计在线，适用于快速制作公司主页、活动落地页等。 git clone 项目 yarn install yarn dev # http://localhost:3000 地址：github.comcruiptailwind-landing-page-template python-miio：用于控制小米智能家电的 Python 库。该项目提供了一个 Python 库和命令行工具，可以用来控制使用小米的 miIO 和 MIoT 协议的设备。借助它用户可以轻松地与小米智能设备进行通信和远程控制，包括扫地机器人、灯泡、空气净化器等，非常适合喜欢 DIY 智能家居系统的开发者。 地址：github.comrytilahtipython-miio undetected-chromedriver：绕过反爬检测的 Python 库。这是一个经过优化的 Selenium WebDriver 补丁，专门用于防止浏览器自动化过程中，触发反机器人机制。它能够隐藏浏览器特征（指纹），使用起来十分方便，就像一个 Python 的第三方库一样。 import undetected_chromedriver as uc driver = uc.Chrome(headless=True,use_subprocess=False) driver.get(https://nowsecure.nl) driver.save_screenshot(nowsecure.png) 地址：github.comultrafunkamsterdamundetected-chromedriver reminders-menubar：极简的 macOS 菜单栏提醒工具。这是一款使用 SwiftUI 开发的小工具，能够在 macOS 菜单栏查看提醒待办事项。它体积小、交互简单、界面清爽，支持开机启动、多语言（包括中文）、菜单栏显示计数、快捷键等功能。 地址：github.comDamascenoRafaelreminders-menubar ServiceLogos：超可爱的 Logo 集合。这里是用来存放 Sawaratsuki 制作的各种 logo 的仓库，这些 logo 制作精美、画风可爱，包括编程语言、框架、工具和各大社交媒体的商标™️。 地址：github.comSAWARATSUKIServiceLogos how-to-learn-robotics：机器人学自学指南。这本指南专为非科班的小伙伴而设计，旨在指导他们如何学习机器人学。它包含了必备知识、入门教材推荐、实践项目以及进阶方法等内容，帮助读者逐步成长为一名优秀的机器人工程师。 地址：github.comqqflyhow-to-learn-robotics 免费、开源的落地页模板：tailwind-landing-page-template 主语言：TypeScript 该项目是基于 TailwindCSS、React 和 Next.js 构建的落地页模板，它界面美观、代码简单、设计在线，适用于快速制作公司主页、活动落地页等。 项目详情→hellogithub.comrepository9f205fad64b241609ce3feec456ab818 RunCat_for_windows：在 Windows 任务栏飞奔的“小猫”。这是一个用 C# 写的小工具，它会在 Windows 任务栏显示一只奔跑的小猫动画，CPU 使用率越高它跑得越快。 地址：github.comKyome22RunCat_for_windows mactop：专为苹果芯片打造的 Mac 性能监控工具。该项目用不到 1k 行的 Go 代码，实现了一个类似 top 命令的工具。它可以实时显示 Apple M 系列芯片的性能指标，包括 CPU、GPU 使用率、内存、网络和硬盘等信息。 地址：github.comcontext-labsmactop superfile：非常漂亮的终端文件管理器。这是一个现代终端文件管理器，为命令行文件操作提供了一个直观且漂亮的界面。它默认采用 Vim 风格的快捷键操作，还支持插件和主题自定义。 地址：github.comyorukotsuperfile chsrc：全平台通用的换源工具。该项目能够为常见的 Linux 发行版、编程语言和软件切换至国内镜像源，操作简单仅需一条命令。它采用 C 语言编写，具有高效和轻量级的特点，支持测速、多平台以及项目级换源等功能，适用于优化下载速度或解决源受限的场景。来自 @ccmywish 的分享 #chsrc 地址：github.comRubyMetricchsrc lnav：强大的终端日志文件查看工具。这是一款用于查看和分析日志文件的轻量级工具。它无需配置、开箱即用，可自动识别日志格式并解压文件，支持同时处理多个文件和目录、实时更新、文本高亮、正则与 SQL 过滤日志等功能，特别适合在服务器和开发环境中使用。来自 @DeShuiYu 的分享 地址：github.comtstacklnav 登录页面HTMLhttps://mp.weixin.qq.com/s?__biz=MzkyOTY0MTc2Mw==mid=2247484615idx=1sn=ea7f0a83d59cbecd8d35bcc8593df965chksm=c379bfb1c9e47cd5f6cb9f2f1549b14c7e6ae9d5df148869070d42df10a94ff5fc731bc5ea2bscene=132exptype=timeline_recommend_article_extendread_extendread_interestshow_related_article=1subscene=132scene=132#wechat_redirect 在Master分之发生变化的时候，pull一下代码要在Git仓库的master分支发生变化时自动执行git pull操作，可以设置一个Git hook来触发这个动作。具体步骤如下： 安装Git： 确保系统上已经安装了Git。如果没有安装，可以运行以下命令： sudo yum install git 克隆仓库： 如果您还没有克隆仓库，请先克隆它： git clone https://github.com/username/repository.git /path/to/your/local/repo cd /path/to/your/local/repo 设置Git hook： Git hooks 是一些脚本，在Git仓库中的特定事件发生时执行。我们可以使用post-merge和post-receive hooks来实现这个功能。 创建一个钩子脚本： vi /path/to/your/local/repo/.git/hooks/post-merge 添加以下内容： #!/bin/bash # 切换到仓库目录 cd /path/to/your/local/repo # 执行 git pull git pull origin master 保存并关闭文件。 注意： 确保替换/path/to/your/local/repo为您的实际仓库路径。 为钩子脚本添加执行权限： chmod +x /path/to/your/local/repo/.git/hooks/post-merge Github HooksGitHooks Git技巧https://hellogithub.com/article/9aed28d4d64b4649bb364685ef557ae4","tags":["git"],"categories":["use"]},{"title":"算法","path":"/2023/02/13/归档/算法/","content":"LFU(最不经常使用缓存)import java.util.*;public class LFUCacheK, V private final int capacity; private MapK, V cache; private MapK, Integer freqMap; private MapInteger, LinkedHashSetK freqKeysMap; private int minFreq; public LFUCache(int capacity) this.capacity = capacity; cache = new HashMap(); freqMap = new HashMap(); freqKeysMap = new HashMap(); minFreq = 0; public V get(K key) if (!cache.containsKey(key)) return null; int freq = freqMap.get(key); freqMap.put(key, freq + 1); freqKeysMap.get(freq).remove(key); if (freq == minFreq freqKeysMap.get(freq).size() == 0) minFreq++; if (!freqKeysMap.containsKey(freq + 1)) freqKeysMap.put(freq + 1, new LinkedHashSet()); freqKeysMap.get(freq + 1).add(key); return cache.get(key); public void put(K key, V value) if (capacity = 0) return; if (cache.containsKey(key)) cache.put(key, value); get(key); return; if (cache.size() = capacity) K evictKey = freqKeysMap.get(minFreq).iterator().next(); freqKeysMap.get(minFreq).remove(evictKey); cache.remove(evictKey); freqMap.remove(evictKey); cache.put(key, value); freqMap.put(key, 1); minFreq = 1; if (!freqKeysMap.containsKey(1)) freqKeysMap.put(1, new LinkedHashSet()); freqKeysMap.get(1).add(key); LFU缓存在处理缓存置换的时候会考虑到访问频率的因素。如果缓存空间已满，那么就要淘汰掉一些数据，以腾出空间存放新的数据。常见的淘汰算法有：先进先出（First In First Out，FIFO）、最近最少使用（Least Recently Used，LRU）和最不经常使用（Least Frequently Used，LFU）等。 这里我们实现了一个 LFU Cache，使用三个 Map 来存储缓存数据，缓存键的访问频率，以及不同访问频率下对应的缓存键集合。具体实现中，我们使用一个 minFreq 变量来记录当前最小访问频率，并在每次访问或插入数据时更新 minFreq。当缓存空间已满时，我们根据 minFreq 和缓存键集合中的顺序来选择要淘汰的数据。 该实现中，get 和 put 操作的时间复杂度均为 O(1)。如果需要支持高并发操作，可以在实现中加入线程安全机制。","tags":["dairy"]},{"title":"搭建SSR服务器","path":"/2022/12/07/归档/搭建SSR服务器/","content":"apt install git 报错：Temporary failure resolving archive.ubuntu.com具体如下：Ign:1 http://archive.ubuntu.com/ubuntu xenial/main i386 liberror-perl all 0.17-1.2Ign:2 http://archive.ubuntu.com/ubuntu xenial/main i386 git-man all 1:2.7.4-0ubuntu1Err:3 http://archive.ubuntu.com/ubuntu xenial/main amd64 git amd64 1:2.7.4-0ubuntu1 Temporary failure resolving archive.ubuntu.comErr:1 http://archive.ubuntu.com/ubuntu xenial/main i386 liberror-perl all 0.17-1.2 Temporary failure resolving archive.ubuntu.comErr:2 http://archive.ubuntu.com/ubuntu xenial/main i386 git-man all 1:2.7.4-0ubuntu1 Temporary failure resolving archive.ubuntu.comE: Failed to fetch http://archive.ubuntu.com/ubuntu/pool/main/libe/liberror-perl/liberror-perl_0.17-1.2_all.deb Temporary failure resolving archive.ubuntu.comE: Failed to fetch http://archive.ubuntu.com/ubuntu/pool/main/g/git/git-man_2.7.4-0ubuntu1_all.deb Temporary failure resolving archive.ubuntu.comE: Failed to fetch http://archive.ubuntu.com/ubuntu/pool/main/g/git/git_2.7.4-0ubuntu1_amd64.deb Temporary failure resolving archive.ubuntu.comE: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?root@132157:~# apt-get updateErr:1 http://security.ubuntu.com/ubuntu xenial-security InRelease Temporary failure resolving security.ubuntu.comErr:2 http://archive.ubuntu.com/ubuntu xenial InRelease Temporary failure resolving archive.ubuntu.comErr:3 http://archive.ubuntu.com/ubuntu xenial-updates InRelease Temporary failure resolving archive.ubuntu.comErr:4 http://archive.ubuntu.com/ubuntu xenial-backports InRelease Temporary failure resolving archive.ubuntu.comReading package lists... DoneW: Failed to fetch http://archive.ubuntu.com/ubuntu/dists/xenial/InRelease Temporary failure resolving archive.ubuntu.comW: Failed to fetch http://archive.ubuntu.com/ubuntu/dists/xenial-updates/InRelease Temporary failure resolving archive.ubuntu.comW: Failed to fetch http://archive.ubuntu.com/ubuntu/dists/xenial-backports/InRelease Temporary failure resolving archive.ubuntu.comW: Failed to fetch http://security.ubuntu.com/ubuntu/dists/xenial-security/InRelease Temporary failure resolving security.ubuntu.comW: Some index files failed to download. They have been ignored, or old ones used instead. 原因是DNS未配置 sudo vi /etc/resolv.conf+ nameserver 202.96.134.133+ nameserver 8.8.8.8","tags":["others"],"categories":["杂项"]},{"title":"Redis笔记","path":"/2021/12/10/归档/Redis/","content":"201个线程 应该扣减201 - 库存不足","tags":["redis"],"categories":["中间件"]},{"title":"数据库时间存储","path":"/2020/04/29/归档/数据库时间存储/","content":"数据库如何存储时间？你真的知道吗？我们平时开发中不可避免的就是要存储时间，比如我们要记录操作表中这条记录的时间、记录转账的交易时间、记录出发时间等等。你会发现这个时间这个东西与我们开发的联系还是非常紧密的，用的好与不好会给我们的业务甚至功能带来很大的影响。所以，我们有必要重新出发，好好认识一下这个东西。 这是一篇短小精悍的文章，仔细阅读一定能学到不少东西！ 1.切记不要用字符串存储日期我记得我在大学的时候就这样干过，而且现在很多对数据库不太了解的新手也会这样干，可见，这种存储日期的方式的优点还是有的，就是简单直白，容易上手。 但是，这是不正确的做法，主要会有下面两个问题： 字符串占用的空间更大！ 字符串存储的日期比较效率比较低（逐个字符进行比对），无法用日期相关的 API 进行计算和比较。 2.Datetime 和 Timestamp 之间抉择Datetime 和 Timestamp 是 MySQL 提供的两种比较相似的保存时间的数据类型。他们两者究竟该如何选择呢？ 通常我们都会首选 Timestamp。 下面说一下为什么这样做! 2.1 DateTime 类型没有时区信息的DateTime 类型是没有时区信息的（时区无关） ，DateTime 类型保存的时间都是当前会话所设置的时区对应的时间。这样就会有什么问题呢？当你的时区更换之后，比如你的服务器更换地址或者更换客户端连接时区设置的话，就会导致你从数据库中读出的时间错误。不要小看这个问题，很多系统就是因为这个问题闹出了很多笑话。 Timestamp 和时区有关。Timestamp 类型字段的值会随着服务器时区的变化而变化，自动换算成相应的时间，说简单点就是在不同时区，查询到同一个条记录此字段的值会不一样。 下面实际演示一下！ 建表 SQL 语句： CREATE TABLE `time_zone_test` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `date_time` datetime DEFAULT NULL, `time_stamp` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8; 插入数据： INSERT INTO time_zone_test(date_time,time_stamp) VALUES(NOW(),NOW()); 查看数据： select date_time,time_stamp from time_zone_test; 结果： +---------------------+---------------------+| date_time | time_stamp |+---------------------+---------------------+| 2020-01-11 09:53:32 | 2020-01-11 09:53:32 |+---------------------+---------------------+ 现在我们运行 修改当前会话的时区: set time_zone=+8:00; 再次查看数据： +---------------------+---------------------+| date_time | time_stamp |+---------------------+---------------------+| 2020-01-11 09:53:32 | 2020-01-11 17:53:32 |+---------------------+---------------------+ 扩展：一些关于 MySQL 时区设置的一个常用 sql 命令 # 查看当前会话时区SELECT @@session.time_zone;# 设置当前会话时区SET time_zone = Europe/Helsinki;SET time_zone = +00:00;# 数据库全局时区设置SELECT @@global.time_zone;# 设置全局时区SET GLOBAL time_zone = +8:00;SET GLOBAL time_zone = Europe/Helsinki; 2.2 DateTime 类型耗费空间更大Timestamp 只需要使用 4 个字节的存储空间，但是 DateTime 需要耗费 8 个字节的存储空间。但是，这样同样造成了一个问题，Timestamp 表示的时间范围更小。 DateTime ：1000-01-01 00:00:00 ~ 9999-12-31 23:59:59 Timestamp： 1970-01-01 00:00:01 ~ 2037-12-31 23:59:59 Timestamp 在不同版本的 MySQL 中有细微差别。 3 再看 MySQL 日期类型存储空间下图是 MySQL 5.6 版本中日期类型所占的存储空间： 可以看出 5.6.4 之后的 MySQL 多出了一个需要 0 ～ 3 字节的小数位。Datatime 和 Timestamp 会有几种不同的存储空间占用。 为了方便，本文我们还是默认 Timestamp 只需要使用 4 个字节的存储空间，但是 DateTime 需要耗费 8 个字节的存储空间。 4.数值型时间戳是更好的选择吗？很多时候，我们也会使用 int 或者 bigint 类型的数值也就是时间戳来表示时间。 这种存储方式的具有 Timestamp 类型的所具有一些优点，并且使用它的进行日期排序以及对比等操作的效率会更高，跨系统也很方便，毕竟只是存放的数值。缺点也很明显，就是数据的可读性太差了，你无法直观的看到具体时间。 时间戳的定义如下： 时间戳的定义是从一个基准时间开始算起，这个基准时间是「1970-1-1 00:00:00 +0:00」，从这个时间开始，用整数表示，以秒计时，随着时间的流逝这个时间整数不断增加。这样一来，我只需要一个数值，就可以完美地表示时间了，而且这个数值是一个绝对数值，即无论的身处地球的任何角落，这个表示时间的时间戳，都是一样的，生成的数值都是一样的，并且没有时区的概念，所以在系统的中时间的传输中，都不需要进行额外的转换了，只有在显示给用户的时候，才转换为字符串格式的本地时间。 数据库中实际操作： mysql select UNIX_TIMESTAMP(2020-01-11 09:53:32);+---------------------------------------+| UNIX_TIMESTAMP(2020-01-11 09:53:32) |+---------------------------------------+| 1578707612 |+---------------------------------------+1 row in set (0.00 sec)mysql select FROM_UNIXTIME(1578707612);+---------------------------+| FROM_UNIXTIME(1578707612) |+---------------------------+| 2020-01-11 09:53:32 |+---------------------------+1 row in set (0.01 sec) 转载：https://juejin.im/post/5e1d494a5188254c45778a14","tags":["dairy"]},{"title":"Go笔记","path":"/2020/04/20/归档/Go笔记/","content":"// 当标识符（包括常量、变量、类型、函数名、结构字段等等）以一个大写字母开头，如：Group1，那么使用这种形式的标识符的对象就可以被外部包的代码所使用（客户端程序需要先导入这个包），这被称为导出（像面向对象语言中的 public）；标识符如果以小写字母开头，则对包外是不可见的，但是他们在整个包的内部是可见并且可用的（像面向对象语言中的 protected ）。 报错：The main file has the non-main package or does not contain the main function main函数需要再main包下","categories":["学习笔记"]},{"title":"IDEA","path":"/2020/04/20/归档/IDEA/","content":"1. Maven 设置 多module下，启动程序报错： 执行下，就可以了","categories":["工具使用"]},{"title":"阿里巴巴手册","path":"/2020/04/20/归档/阿里巴巴手册/","content":""},{"title":"设计模式笔记","path":"/2020/04/20/归档/设计模式笔记/","content":"设计模式遵循六⼤原则；单⼀职责( ⼀个类和⽅法只做⼀件事 )、⾥⽒替换( 多态，⼦类可扩展⽗类 )、依赖 倒置( 细节依赖抽象，下层依赖上层 )、接⼝隔离( 建⽴单⼀接⼝ )、迪⽶特原则( 最少知道，降低耦合 )、开闭 原则( 抽象架构，扩展实现 ）。 1. 工厂模式举个例子： 吃：南方人爱吃饭，北方人爱吃面 定义一个接口：吃 定义两个实现类继承吃：饭、面 定义一个工厂：饭店 饭店通过判断是南方人还是北方人返回不同的实现类，从而让不同的人吃到了不同的饭 2.抽象工厂模式3.建造者模式实体类的setXxx()方法，一般是返回void，可以改造为： public ObjectX setXxx(String xx) this.xxx = xx\treturn this; 4. 原型模式考卷题目和答案乱序。","categories":["学习笔记"]},{"title":"时间戳转换日期问题","path":"/2020/04/17/归档/时间戳转换日期问题/","content":"基础依赖后来发现是我拿到的时间戳是以 秒 为单位的，而转换时需要的是 毫秒。 Date date = new Date(1579676844); // 1970-01-19T14:47:56.844+0800 Date date = new Date(1579676844 * 1000L); // 2020-01-22T15:07:24.000+0800","tags":["basic"]},{"title":"Hexo","path":"/2020/04/15/归档/15/","content":"# hexo shokahttps://shoka.lostyu.me/computer-science/note/theme-shoka-doc/config/#%E6%96%87%E7%AB%A0%E8%AF%84%E8%AE%BA# 隐藏文章https://www.cnblogs.com/yangstar/articles/16690342.html","tags":["hexo,theme,shoka"]},{"title":"内部类问题","path":"/2020/04/14/归档/14/","content":"错误描述信息：org.fairy.eye.domin.entity.User is not an enclosing class ​ 在 new 一个内部类的对象时，idea 会生成如下的代码。 // Info 是User的内部类User.Info info = new User.Info(); ​ 然后会提示报错 org.fairy.eye.domin.entity.User is not an enclosing class ​ 如果内部类没有用 static 修饰的话，是不能这样 new 的。 ​ 需要有外部类实例对象来支持。 User user = new User();User.Info info = new user.Info();","tags":["dairy"]},{"title":"GIT代码无法合并+本地构建成功服务器构建失败","path":"/2020/04/13/归档/13/","content":"1.GIT相关场景：​ GIT版本出了点问题，无法正常合并代码 具体描述：​ 由于误操作，导致我的本地分支和dev分支不同，在GIT上对比的时候显示无差别，但是实际上最近一次的提交是没有合并的。 ​ 无奈之下，我选择回滚代码。 具体操作：第一种方法：注意：这种方法会把之后的代码完全覆盖掉，不建议使用，除非这个分支只有你自己操作，或者你回滚的版本之后没有别的人提交 首先要找到你要回滚的版本号。 ​ 在idea中操作：右键项目 - Git - Show History - 右键提交的版本 - Copy Revision Number。 ​ 在GIT中操作：找到提交的历史，SHA 值，即为版本号。 Git Bush 命令行idea TerMinal 命令行 ​ git reset --hard 版本号 第二种方法： 找到版本号，同上。 右键项目 - Git - Repository - Reset HEAD 在 To Commit 中输入版本号 最后：​ 记得一定要提交代码，即使看起来没有要 push 的东西，否则 git pull 之后等于没回滚。 2.构建相关场景：​ 回滚代码之后，本地可以成功构建，但服务器端无法正常构建。 具体描述：​ 服务器端构建一直失败，好像是拉取到了错误版本的代码。 具体操作：​ 暴脾气的我本来打算把项目删了重新拉一个下来，后来忍住了，在服务器端回滚了一下代码，然后手动构建了一下，居然成功了，完结。 最后：​ 虽然没什么有用的东西，不过思路还是有的。 ​ 首先你要确认本地构建的代码是否和服务器完全相同、服务器构建的时候是否pull了最新的代码… 随机限定皮肤礼:0.2%;碎月令:0.2%;随机传说皮肤:0.5%;随机皮肤:13.5%;剑意(8~68个):58.5%;皮肤碎片x8:15%;锦鲤纳福亲密度道具x8:12.1%;限定-288个、传说-120个、史诗-60个、勇者-40个、伴生-20个。其中，随机限定皮肤礼的奖励概率分布为:李白-碎月剑心:1%;甄姬-幽恒:33%;后羿-辉光之辰:33%;猪八戒-猪悟能:33%;随机皮肤的奖励概率分布为:史诗皮肤:10%，勇者皮肤:30%，伴生皮肤:60%;具体包含皮肤可见活动首页-【奖池】内信息;剑意的奖励概率分布为:剑意x8:37.6%;剑意x18:51.3%;剑意x28:9.4%A礼盒:0.2%; 1%：0个剑意 99%：288个剑意B礼盒:0.2%; 498个剑意C礼盒:0.5%; 120个剑意D礼盒:13.5%; 10%：60个剑意，30%：40个剑意，60%：20个剑意E礼盒(8~68个):58.5%; 37.6%：8个;51.3%:18个剑意;9.4%:28个剑意；12%:68个剑意F礼盒（皮肤碎片）0个:15%;G礼盒0个:12.1%;","tags":["dairy"]},{"path":"/404/404.html","content":""},{"path":"/404.html","content":""},{"title":"关于我","path":"/about/index.html","content":"👋 关于我你好！我是 li，一名热爱技术的开发者。 🛠️ 技术栈后端开发: Java Spring Boot Spring Cloud MySQL PostgreSQL Redis MyBatis JPA Maven Gradle 中间件: Redis Memcached RabbitMQ Kafka Nacos Sentinel Docker Kubernetes 开发工具: IntelliJ IDEA Git GitHub Postman Swagger Linux Shell 📚 学习历程从最初接触编程到现在，经历了从 Java 基础 到 分布式系统 的完整技术栈演进。热衷于研究开源项目源码，关注系统架构设计和性能优化。 🎯 兴趣爱好 📖 阅读技术书籍和文档 🔍 研究开源项目源码 ✍️ 记录技术笔记和心得 🏸 羽毛球运动 📫 联系方式 GitHub: @fairyeye Email: 发送邮件 Blog: fairyeye.github.io 💡 座右铭 “代码是写给人看的，只是顺便让机器执行。” 希望在这个博客中分享的技术内容能对你有所帮助。欢迎在文章下方留言交流！ .about-card { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 16px; padding: 32px; color: white; margin: 20px 0; } .about-card h2 { color: white; margin-top: 0; } .about-card h3 { color: rgba(255, 255, 255, 0.95); margin-top: 24px; margin-bottom: 12px; } .about-card ul { list-style: none; padding-left: 0; } .about-card li { margin: 8px 0; padding-left: 20px; position: relative; } .about-card li::before { content: \"▸\"; position: absolute; left: 0; color: rgba(255, 255, 255, 0.8); } .about-card a { color: white; text-decoration: underline; font-weight: 500; } .about-card blockquote { border-left: 4px solid rgba(255, 255, 255, 0.5); padding-left: 16px; margin: 16px 0; font-style: italic; color: rgba(255, 255, 255, 0.9); }"}]